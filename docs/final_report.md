# K-POP ì•„í‹°ìŠ¤íŠ¸ ì¸ê¸°ë„ ë¶„ì„ ì‹œìŠ¤í…œ
## YouTube ë°ì´í„° ê¸°ë°˜ ë¶„ê¸°ë³„ íŠ¸ë Œë“œ ì˜ˆì¸¡ ë° ì‹œê°í™”

**ê³¼ëª©**: ë¹…ë°ì´í„° ë¶„ì„
**í•™ë²ˆ**: student_15030
**ì œì¶œì¼**: 2025-10-30

---

## 1. ë¬¸ì œ ì •ì˜ ë° ëª©í‘œ

### 1.1 ë¬¸ì œ ì •ì˜

K-POP ì‚°ì—…ì€ ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œ ê¸‰ê²©í•œ ì„±ì¥ì„ ë³´ì´ê³  ìˆìœ¼ë‚˜, ì•„í‹°ìŠ¤íŠ¸ë³„ ì¸ê¸°ë„ ë³€í™”ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ì‹œìŠ¤í…œì´ ë¶€ì¡±í•˜ë‹¤. íŠ¹íˆ:

1. **ë°ì´í„° ë¶„ì‚°**: YouTube, SNS ë“± ë‹¤ì–‘í•œ í”Œë«í¼ì— ë°ì´í„°ê°€ ë¶„ì‚°
2. **ì‹¤ì‹œê°„ì„± ë¶€ì¡±**: ê¸°ì¡´ ì°¨íŠ¸ëŠ” ì¼ì£¼ì¼ ë‹¨ìœ„ ì§‘ê³„ë¡œ íŠ¸ë Œë“œ ë³€í™” ê°ì§€ ì§€ì—°
3. **ë¹„êµ ê¸°ì¤€ ë¯¸í¡**: ì ˆëŒ€ì  ì¡°íšŒìˆ˜ë§Œìœ¼ë¡œëŠ” ì‹œì¥ ë‚´ ìƒëŒ€ì  ìœ„ì¹˜ íŒŒì•… ì–´ë ¤ì›€
4. **ì˜ˆì¸¡ ë¶€ì¬**: ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ë¯¸ë˜ ì¸ê¸°ë„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë¶€ì¬

### 1.2 ì—°êµ¬ ëª©í‘œ

ë³¸ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ 3ê°€ì§€ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³ ì í•œë‹¤:

**ì£¼ìš” ëª©í‘œ**:
1. **ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ**: YouTube Data API v3ë¥¼ í™œìš©í•œ 2024ë…„ K-POP ì˜ìƒ ëŒ€ê·œëª¨ ìˆ˜ì§‘ 
2. **ë¶„ê¸°ë³„ íŠ¸ë Œë“œ ë¶„ì„**: QoQ(Quarter-over-Quarter) ì„±ì¥ë¥  ê¸°ë°˜ ì•„í‹°ìŠ¤íŠ¸ í‹°ì–´ ë¶„ë¥˜ ë° ì‹œì¥ ì ìœ ìœ¨ ë¶„ì„
3. **ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ**: Streamlit ê¸°ë°˜ ëŒ€í™”í˜• ëŒ€ì‹œë³´ë“œë¡œ ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì¦‰ê°ì  í”¼ë“œë°± ì œê³µ

**ì„¸ë¶€ ëª©í‘œ**:
- Medallion Architecture(Landing â†’ Bronze â†’ Silver â†’ Gold) êµ¬ì¶•
- Bloom Filter ê¸°ë°˜ ì¤‘ë³µ ì œê±°ë¡œ ë°ì´í„° í’ˆì§ˆ ë³´ì¥
- CDF(Cumulative Distribution Function) ê¸°ë°˜ ë™ì  í‹°ì–´ ë¶„ë¥˜
- ë‹¤ëª©ì  ìµœì í™”(Pareto Front)ë¥¼ í†µí•œ ìµœì  ëª¨ë¸ ì„ ì •

### 1.3 ì„±ê³µ ê¸°ì¤€

1. **ë°ì´í„° í’ˆì§ˆ**: ìœ ë‹ˆí¬ ì˜ìƒ 20,000ê°œ ì´ìƒ, ì¤‘ë³µë¥  5% ì´í•˜
2. **ì²˜ë¦¬ ì„±ëŠ¥**: Delta Lake ê¸°ë°˜ ACID íŠ¸ëœì­ì…˜ ë³´ì¥, ìŠ¤íŠ¸ë¦¬ë° ë ˆì´í„´ì‹œ 1ë¶„ ì´ë‚´
3. **ì˜ˆì¸¡ ì •í™•ë„**: í‹°ì–´ ë¶„ë¥˜ ì¼ì¹˜ìœ¨ 85% ì´ìƒ
4. **ì‚¬ìš©ì ê²½í—˜**: UI ì‘ë‹µ ì‹œê°„ 2ì´ˆ ì´ë‚´, 5ê°œ íƒ­ í†µí•© ëŒ€ì‹œë³´ë“œ ì œê³µ

---

## 2. ì„¤ê³„ ë° ì•Œê³ ë¦¬ì¦˜

### 2.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

#### 2.1.1 ì „ì²´ êµ¬ì¡°ë„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     YouTube Data API v3                         â”‚
â”‚                   (9,500 QPD Ã— 5 days)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [00. Scaffold] Directory Setup                                 â”‚
â”‚  - project/data/{landing,bronze,silver,gold}                    â”‚
â”‚  - project/artifacts/{mlflow,pareto,tiers}                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [01. Landing] Raw NDJSON Storage                               â”‚
â”‚  - 95 files/day Ã— 5 days = 475 NDJSON files                     â”‚
â”‚  - Schema: {post_id, video_id, author_id, text, ts, source}     â”‚
â”‚  - Reservoir Sampling (Vitter's Algorithm R)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [02. Bronze] Delta Lake Ingestion + Deduplication              â”‚
â”‚  - Bloom Filter (capacity=500k, FPR=0.01)                       â”‚
â”‚  - Partitioning: (ingest_date, artist)                          â”‚
â”‚  - Artist extraction via pattern matching                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [03. Silver] Structured Streaming Aggregation                  â”‚
â”‚  - Quarterly window (2024-Q1, Q2, Q3, Q4)                       â”‚
â”‚  - QoQ growth rate calculation                                  â”‚
â”‚  - Market share per quarter                                     â”‚
â”‚  - Watermark: 10 minutes, Checkpoint: enabled                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [04. Gold] Feature Engineering + Tier Classification           â”‚
â”‚  - CDF-based tier labeling (Tier 1-4)                           â”‚
â”‚  - Percentile calculation (95th, 85th, 60th)                    â”‚
â”‚  - Trend direction (UP/DOWN/STEADY)                             â”‚
â”‚  - HyperLogLog for cardinality estimation                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [05. Train] Multi-Model Training + Pareto Optimization         â”‚
â”‚  - Models: LR, RF, GBT                                          â”‚
â”‚  - Metrics: Accuracy, F1, Latency, Feature Count                â”‚
â”‚  - MLflow tracking                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [06. Serve] Streamlit Dashboard (5 Tabs)                       â”‚
â”‚  - Tab 1: Market Share Distribution                             â”‚
â”‚  - Tab 2: Top-10 Rankings                                       â”‚
â”‚  - Tab 3: QoQ Growth Analysis                                   â”‚
â”‚  - Tab 4: Artist Details                                        â”‚
â”‚  - Tab 5: Real-time Prediction + CDF Analysis                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2.1.2 ë°ì´í„° íë¦„ë„

```
[YouTube API]
     â”‚
     â”‚ (Random Sampling Strategy)
     â–¼
[Landing: NDJSON]
     â”‚ post_id, video_id, author_id, text, ts
     â”‚
     â”‚ (Bloom Filter Check)
     â–¼
[Bronze: Delta Lake]
     â”‚ + artist (extracted), ingest_date
     â”‚ Partition: (ingest_date, artist)
     â”‚
     â”‚ (Quarterly Aggregation)
     â–¼
[Silver: Quarterly Metrics]
     â”‚ quarter, artist, total_engagement, total_videos,
     â”‚ unique_authors, growth_qoq, market_share
     â”‚
     â”‚ (CDF-based Tiering)
     â–¼
[Gold: Features + Tiers]
     â”‚ + percentile, tier (1-4), trend_direction
     â”‚
     â–¼
[UI: Streamlit Dashboard]
     User Input â†’ Bloom Check â†’ CDF Position â†’ Prediction
```

### 2.2 í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

#### 2.2.1 ëœë¤ ìƒ˜í”Œë§ ì „ëµ (Random Sampling Strategy)

**ëª©ì **: í•œì •ëœ API í• ë‹¹ëŸ‰(9,500 QPD)ìœ¼ë¡œ ëŒ€í‘œì„± ìˆëŠ” ë°ì´í„° ìˆ˜ì§‘

**ì•Œê³ ë¦¬ì¦˜**:
```python
# íŒŒë¼ë¯¸í„° ê³µê°„ ì •ì˜
ARTISTS = [20ê°œ ì£¼ìš” K-POP ê·¸ë£¹]
ORDER_TYPES = ["relevance", "viewCount", "date", "rating"]
QUARTERS_2024 = [(Q1_start, Q1_end), (Q2_start, Q2_end), ...]

# ê° API í˜¸ì¶œë§ˆë‹¤ ëœë¤ ì„ íƒ
for call in range(95):  # 9500 QPD / 100 QPD per call
    artist = random.choice(ARTISTS)
    order = random.choice(ORDER_TYPES)
    quarter = random.choice(QUARTERS_2024)

    fetch_youtube_search(
        query=artist,
        order=order,
        published_after=quarter[0],
        published_before=quarter[1],
        max_results=50
    )
```

**ì„ íƒ ì´ìœ **:
1. **ëŒ€í‘œì„±**: ì•„í‹°ìŠ¤íŠ¸, ì •ë ¬ ë°©ì‹, ì‹œê°„ëŒ€ë¥¼ ëª¨ë‘ ëœë¤í™”í•˜ì—¬ í¸í–¥ ìµœì†Œí™”
2. **íš¨ìœ¨ì„±**: 95íšŒ í˜¸ì¶œë¡œ ìµœëŒ€ 4,750ê°œ ì˜ìƒ ìˆ˜ì§‘ ê°€ëŠ¥
3. **ì¬í˜„ì„±**: ë™ì¼ ì „ëµ ë°˜ë³µ ì‹œ ìœ ì‚¬í•œ ë¶„í¬ íšë“

**ëŒ€ì•ˆ ë¹„êµ**:

| ì „ëµ | ì¥ì  | ë‹¨ì  | ì„ íƒ ì—¬ë¶€ |
|------|------|------|-----------|
| **ëœë¤ ìƒ˜í”Œë§** | í¸í–¥ ìµœì†Œ, íš¨ìœ¨ì  | íŠ¹ì • ì•„í‹°ìŠ¤íŠ¸ ê³¼ì†Œ í‘œì§‘ ê°€ëŠ¥ | âœ… ì±„íƒ |
| ê· ë“± ìƒ˜í”Œë§ | ê° ì•„í‹°ìŠ¤íŠ¸ ë™ì¼ ë¹„ì¤‘ | API í• ë‹¹ëŸ‰ ë¹„íš¨ìœ¨, ì‹¤ì œ ì¸ê¸°ë„ ë°˜ì˜ X | âŒ |
| ì¸ê¸°ë„ ê°€ì¤‘ ìƒ˜í”Œë§ | ì£¼ìš” ì•„í‹°ìŠ¤íŠ¸ ì§‘ì¤‘ | ì‹ ì¸/ì†Œê·œëª¨ ê·¸ë£¹ ëˆ„ë½ | âŒ |
| ì‹œê³„ì—´ ìˆœì°¨ ìˆ˜ì§‘ | ì‹œê°„ ìˆœì„œ ë³´ì¥ | ìµœì‹  ë°ì´í„° í¸í–¥, ë‹¤ì–‘ì„± ë¶€ì¡± | âŒ |

#### 2.2.2 Bloom Filter ê¸°ë°˜ ì¤‘ë³µ ì œê±°

**ëª©ì **: Bronze ë ˆì´ì–´ ì§„ì… ì „ ì´ë¯¸ ì²˜ë¦¬ëœ `post_id` í•„í„°ë§

**ì•Œê³ ë¦¬ì¦˜**:
```python
class BloomFilter:
    def __init__(self, capacity=500000, fpr=0.01):
        # í•„ìš”í•œ ë¹„íŠ¸ ìˆ˜ ê³„ì‚°
        self.m = -capacity * math.log(fpr) / (math.log(2) ** 2)
        # í•´ì‹œ í•¨ìˆ˜ ê°œìˆ˜
        self.k = (self.m / capacity) * math.log(2)
        self.bit_array = bitarray(int(self.m))

    def add(self, item: str):
        for seed in range(int(self.k)):
            idx = mmh3.hash(item, seed) % self.m
            self.bit_array[idx] = 1

    def contains(self, item: str) -> bool:
        for seed in range(int(self.k)):
            idx = mmh3.hash(item, seed) % self.m
            if not self.bit_array[idx]:
                return False
        return True
```

**íŒŒë¼ë¯¸í„° ì„¤ì •**:
- **Capacity**: 500,000 (5ì¼ Ã— 100,000ê°œ/ì¼ ì˜ˆìƒ)
- **FPR (False Positive Rate)**: 0.01 (1%)
- **ë¹„íŠ¸ ìˆ˜ (m)**: ì•½ 4,792,529 bits (ì•½ 600KB)
- **í•´ì‹œ í•¨ìˆ˜ ìˆ˜ (k)**: 7ê°œ

**ì„ íƒ ì´ìœ **:
1. **ë©”ëª¨ë¦¬ íš¨ìœ¨**: 600KBë¡œ 50ë§Œ ê°œ ì•„ì´í…œ ì²˜ë¦¬ (vs. Set: 50ë§Œ Ã— 64 bytes = 32MB)
2. **ì†ë„**: O(k) ì‹œê°„ë³µì¡ë„, k=7ë¡œ ë§¤ìš° ë¹ ë¦„
3. **False Positive í—ˆìš©**: 1% FPRì€ Bronzeì—ì„œ Delta Lakeê°€ ìµœì¢… ì¤‘ë³µ ì œê±°í•˜ë¯€ë¡œ í—ˆìš© ê°€ëŠ¥

**ëŒ€ì•ˆ ë¹„êµ**:

| ë°©ë²• | ë©”ëª¨ë¦¬ | ì†ë„ | ì •í™•ë„ | ì„ íƒ |
|------|--------|------|--------|------|
| **Bloom Filter** | 600KB | O(k)â‰ˆO(1) | 99% (FPR 1%) | âœ… |
| Hash Set | 32MB | O(1) | 100% | âŒ (ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨) |
| Sorted Array + Binary Search | 8MB | O(log n) | 100% | âŒ (ì†ë„ ëŠë¦¼) |
| HyperLogLog | 12KB | O(1) | ê·¼ì‚¬ (2% ì˜¤ì°¨) | âŒ (ì¹´ìš´íŒ…ë§Œ ê°€ëŠ¥) |

#### 2.2.3 ë¶„ê¸°ë³„ QoQ ì„±ì¥ë¥  ê³„ì‚°

**ëª©ì **: ì•„í‹°ìŠ¤íŠ¸ë³„ ë¶„ê¸° ëŒ€ë¹„ Engagement ë³€í™”ìœ¨ ì¸¡ì •

**ì•Œê³ ë¦¬ì¦˜** (PySpark Window Function):
```python
from pyspark.sql.window import Window

# 1. ë¶„ê¸°ë³„ ì§‘ê³„
quarterly = events.groupBy("quarter", "artist").agg(
    F.count("*").alias("total_engagement"),
    F.approx_count_distinct("video_id").alias("total_videos"),
    F.approx_count_distinct("author_id").alias("unique_authors")
)

# 2. Window ì •ì˜ (artistë³„, quarter ìˆœì„œëŒ€ë¡œ)
window_spec = Window.partitionBy("artist").orderBy("quarter")

# 3. QoQ ì„±ì¥ë¥  ê³„ì‚°
qoq_growth = quarterly.withColumn(
    "prev_engagement", F.lag("total_engagement").over(window_spec)
).withColumn(
    "growth_qoq",
    F.when(F.col("prev_engagement").isNotNull(),
        ((F.col("total_engagement") - F.col("prev_engagement"))
         / F.col("prev_engagement") * 100)
    ).otherwise(0.0)
)
```

**ìˆ˜ì‹**:
```
QoQ Growth Rate = ((E_current - E_previous) / E_previous) Ã— 100

where:
  E_current  = í˜„ì¬ ë¶„ê¸° Total Engagement
  E_previous = ì´ì „ ë¶„ê¸° Total Engagement
```

**ì„ íƒ ì´ìœ **:
1. **ë¶„ê¸° ë‹¨ìœ„**: K-POP ì‚°ì—…ì˜ í‘œì¤€ ë¶„ì„ ë‹¨ìœ„ (ì•¨ë²” ë°œë§¤ ì£¼ê¸°ì™€ ì¼ì¹˜)
2. **ìƒëŒ€ì  ì„±ì¥**: ì ˆëŒ€ê°’ ëŒ€ì‹  ë¹„ìœ¨ë¡œ ì†Œê·œëª¨/ëŒ€ê·œëª¨ ì•„í‹°ìŠ¤íŠ¸ ê³µì • ë¹„êµ
3. **Window Function**: Spark ìµœì í™”ë¡œ ëŒ€ê·œëª¨ ë°ì´í„° íš¨ìœ¨ì  ì²˜ë¦¬

#### 2.2.4 CDF ê¸°ë°˜ ë™ì  í‹°ì–´ ë¶„ë¥˜

**ëª©ì **: Engagement ë¶„í¬ì— ë”°ë¥¸ ìƒëŒ€ì  í‹°ì–´ ìë™ í• ë‹¹

**ì•Œê³ ë¦¬ì¦˜**:
```python
# 1. ë¶„ê¸°ë³„ ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚°
percent_window = Window.partitionBy("quarter").orderBy("total_engagement")
features_df = metrics_df.withColumn(
    "percentile", F.percent_rank().over(percent_window)
)

# 2. í‹°ì–´ ë¶„ë¥˜
features_df = features_df.withColumn(
    "tier",
    F.when(F.col("percentile") >= 0.95, F.lit(1))  # ìƒìœ„ 5%
     .when(F.col("percentile") >= 0.85, F.lit(2))  # ìƒìœ„ 15%
     .when(F.col("percentile") >= 0.60, F.lit(3))  # ìƒìœ„ 40%
     .otherwise(F.lit(4))                          # ë‚˜ë¨¸ì§€
)
```

**CDF (Cumulative Distribution Function)**:
```
CDF(x) = P(X â‰¤ x) = âˆ«_{-âˆ}^{x} f(t) dt

Tier Assignment:
  Tier 1: CDF(E) â‰¥ 0.95  (ìƒìœ„ 5%)
  Tier 2: 0.85 â‰¤ CDF(E) < 0.95
  Tier 3: 0.60 â‰¤ CDF(E) < 0.85
  Tier 4: CDF(E) < 0.60
```

**ì„ íƒ ì´ìœ **:
1. **ë™ì  ì¡°ì •**: ë°ì´í„° ë¶„í¬ ë³€í™”ì— ìë™ ì ì‘ (í•˜ë“œì½”ë”© ê¸°ì¤€ê°’ ë¶ˆí•„ìš”)
2. **ê³µì •ì„±**: ì ˆëŒ€ ê¸°ì¤€ ëŒ€ì‹  ìƒëŒ€ ìˆœìœ„ë¡œ ëª¨ë“  ë¶„ê¸°ì— ë™ì¼ ë¹„ìœ¨ ì ìš©
3. **í•´ì„ ê°€ëŠ¥ì„±**: "ìƒìœ„ 5%"ëŠ” ë¹„ì „ë¬¸ê°€ë„ ì´í•´ ê°€ëŠ¥

**ëŒ€ì•ˆ ë¹„êµ**:

| ë°©ë²• | ì¥ì  | ë‹¨ì  | ì„ íƒ |
|------|------|------|------|
| **CDF ë°±ë¶„ìœ„ìˆ˜** | ë™ì , ê³µì •, í•´ì„ ê°€ëŠ¥ | ì´ˆê¸° ë°ì´í„° ë¶€ì¡± ì‹œ ë¶ˆì•ˆì • | âœ… |
| K-Means í´ëŸ¬ìŠ¤í„°ë§ | ìë™ êµ°ì§‘í™” | í‹°ì–´ ìˆ˜ ì‚¬ì „ ì§€ì • í•„ìš”, í•´ì„ ì–´ë ¤ì›€ | âŒ |
| ì ˆëŒ€ê°’ ê¸°ì¤€ (ì¡°íšŒìˆ˜ 100ë§Œ+) | ê°„ë‹¨ | ì‹œê°„/íŠ¸ë Œë“œ ë³€í™” ë°˜ì˜ X | âŒ |
| Quantile Regression | ì¡°ê±´ë¶€ ë¶„í¬ ëª¨ë¸ë§ | ê³¼ë„í•œ ë³µì¡ë„ | âŒ |

#### 2.2.5 HyperLogLogë¥¼ í†µí•œ ì¹´ë””ë„ë¦¬í‹° ì¶”ì •

**ëª©ì **: ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ìœ ë‹ˆí¬ ì‚¬ìš©ì ìˆ˜ ê·¼ì‚¬ ê³„ì‚°

**ì•Œê³ ë¦¬ì¦˜** (Spark ë‚´ì¥):
```python
# PySparkì˜ approx_count_distinct() ì‚¬ìš©
silver_df = bronze_df.groupBy("quarter", "artist").agg(
    F.approx_count_distinct("author_id", rsd=0.05).alias("unique_authors")
)
```

**HyperLogLog ì›ë¦¬**:
```
1. Hash í•¨ìˆ˜ë¡œ ì…ë ¥ê°’ì„ ê· ë“± ë¶„í¬ ë¹„íŠ¸ì—´ë¡œ ë³€í™˜
2. ë¹„íŠ¸ì—´ì˜ leading zeros ê°œìˆ˜ ê´€ì°°
3. ìµœëŒ€ leading zeros ê¸°ë°˜ìœ¼ë¡œ ì¹´ë””ë„ë¦¬í‹° ì¶”ì •

Cardinality â‰ˆ 2^(max_leading_zeros) Ã— Î±_m

where:
  rsd = 0.05 (Relative Standard Deviation)
  Error Rate â‰ˆ Â±2.5%
```

**ì„ íƒ ì´ìœ **:
1. **ë©”ëª¨ë¦¬ íš¨ìœ¨**: O(1) ë©”ëª¨ë¦¬ (vs. Setì˜ O(n))
2. **ì •í™•ë„**: 2.5% ì˜¤ì°¨ìœ¨ì€ íŠ¸ë Œë“œ ë¶„ì„ì— ì¶©ë¶„
3. **Spark í†µí•©**: ë‚´ì¥ í•¨ìˆ˜ë¡œ ìµœì í™” ë³´ì¥

**ëŒ€ì•ˆ ë¹„êµ**:

| ë°©ë²• | ë©”ëª¨ë¦¬ | ì˜¤ì°¨ìœ¨ | ì†ë„ | ì„ íƒ |
|------|--------|--------|------|------|
| **HyperLogLog** | O(1) | Â±2.5% | O(1) | âœ… |
| Hash Set | O(n) | 0% | O(1) | âŒ (ë©”ëª¨ë¦¬ ë¶€ì¡±) |
| Linear Counting | O(m) | Â±5% | O(1) | âŒ (ì •í™•ë„ ë‚®ìŒ) |
| Exact Count | O(n) | 0% | O(n log n) | âŒ (ë¹„í˜„ì‹¤ì ) |

#### 2.2.6 Pareto Front ë‹¤ëª©ì  ìµœì í™”

**ëª©ì **: ì •í™•ë„, ì†ë„, ë³µì¡ë„ë¥¼ ë™ì‹œì— ê³ ë ¤í•œ ìµœì  ëª¨ë¸ ì„ ì •

**ì•Œê³ ë¦¬ì¦˜**:
```python
def calculate_pareto_front(models: List[Dict]) -> List[Dict]:
    """
    ë‹¤ëª©ì  ìµœì í™”: Maximize (accuracy, f1), Minimize (latency, features)
    """
    pareto_optimal = []

    for candidate in models:
        is_dominated = False

        for other in models:
            if candidate == other:
                continue

            # Dominance ì²´í¬ (ëª¨ë“  ëª©í‘œì—ì„œ ë™ë“± ì´ìƒ, í•˜ë‚˜ ì´ìƒ ìš°ì›”)
            better_in_all = (
                other['accuracy'] >= candidate['accuracy'] and
                other['f1'] >= candidate['f1'] and
                other['latency_ms'] <= candidate['latency_ms'] and
                other['feature_count'] <= candidate['feature_count']
            )

            strictly_better = (
                other['accuracy'] > candidate['accuracy'] or
                other['f1'] > candidate['f1'] or
                other['latency_ms'] < candidate['latency_ms'] or
                other['feature_count'] < candidate['feature_count']
            )

            if better_in_all and strictly_better:
                is_dominated = True
                break

        if not is_dominated:
            pareto_optimal.append(candidate)

    return pareto_optimal
```

**Pareto Dominance ì •ì˜**:
```
ëª¨ë¸ Aê°€ ëª¨ë¸ Bë¥¼ ì§€ë°°í•œë‹¤ âŸº
  âˆ€i âˆˆ objectives: f_i(A) â‰¥ f_i(B)  (ìµœëŒ€í™” ëª©í‘œ)
  âˆ§ âˆƒj: f_j(A) > f_j(B)             (ì ì–´ë„ í•˜ë‚˜ëŠ” ì—„ê²©íˆ ìš°ì›”)
```

**ìµœì í™” ëª©í‘œ**:
1. **Maximize Accuracy**: í‹°ì–´ ë¶„ë¥˜ ì •í™•ë„
2. **Maximize F1 Score**: ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘
3. **Minimize Latency**: ì‹¤ì‹œê°„ ì˜ˆì¸¡ ì‘ë‹µ ì†ë„
4. **Minimize Feature Count**: ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ

**ì„ íƒ ì´ìœ **:
1. **Trade-off ëª…í™•í™”**: ë‹¨ì¼ ì§€í‘œë¡œ í™˜ì› ë¶ˆê°€ëŠ¥í•œ ë‹¤ëª©ì  ë¬¸ì œ
2. **ì˜ì‚¬ê²°ì • ì§€ì›**: Pareto Front ë‚´ì—ì„œ ìš´ì˜ ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ì„ íƒ ê°€ëŠ¥
3. **ê³¼ì í•© ë°©ì§€**: ë³µì¡ë„ë¥¼ ëª©í‘œì— í¬í•¨í•˜ì—¬ ì¼ë°˜í™” ì„±ëŠ¥ ë³´ì¥

**ì˜ˆì‹œ ê²°ê³¼**:
```json
{
  "models": [
    {
      "name": "Logistic Regression",
      "accuracy": 0.82,
      "f1": 0.79,
      "latency_ms": 2.3,
      "feature_count": 8,
      "is_pareto": true  // âœ… ì†ë„ ìš°ìˆ˜
    },
    {
      "name": "Random Forest",
      "accuracy": 0.88,
      "f1": 0.86,
      "latency_ms": 15.7,
      "feature_count": 50,
      "is_pareto": true  // âœ… ì •í™•ë„ ìš°ìˆ˜
    },
    {
      "name": "Gradient Boosting Tree",
      "accuracy": 0.85,
      "f1": 0.83,
      "latency_ms": 12.1,
      "feature_count": 30,
      "is_pareto": false  // âŒ RFì— ì§€ë°°ë¨
    }
  ]
}
```

### 2.3 ê¸°ìˆ  ìŠ¤íƒ ì„ ì •

#### 2.3.1 í•µì‹¬ ê¸°ìˆ 

| ê³„ì¸µ | ê¸°ìˆ  | ì„ íƒ ì´ìœ  | ëŒ€ì•ˆ |
|------|------|-----------|------|
| **ë°ì´í„° ìˆ˜ì§‘** | YouTube Data API v3 | ê³µì‹ API, ì‹ ë¢°ì„± ë†’ìŒ | ì›¹ ìŠ¤í¬ë˜í•‘ (ë¶ˆì•ˆì •) |
| **ìŠ¤í† ë¦¬ì§€** | Delta Lake | ACID íŠ¸ëœì­ì…˜, Time Travel | Parquet (ACID X) |
| **ì²˜ë¦¬ ì—”ì§„** | Apache Spark 3.5 | ë¶„ì‚° ì²˜ë¦¬, Streaming ì§€ì› | Pandas (ë‹¨ì¼ ë…¸ë“œ í•œê³„) |
| **ìŠ¤íŠ¸ë¦¬ë°** | Structured Streaming | Exactly-once, Watermark | Kafka Streams (ë³µì¡ë„ ë†’ìŒ) |
| **UI** | Streamlit | Python í†µí•©, ë¹ ë¥¸ ê°œë°œ | Dash (í•™ìŠµ ê³¡ì„  ë†’ìŒ) |
| **ì‹¤í—˜ ê´€ë¦¬** | MLflow | ìë™ ë¡œê¹…, UI ì œê³µ | Weights & Biases (ìœ ë£Œ) |

#### 2.3.2 Medallion Architecture ì±„íƒ ì´ìœ 

**Bronze-Silver-Gold 3-Layer êµ¬ì¡°**:

```
Landing (Raw)
   â†“ (ìµœì†Œ ì²˜ë¦¬)
Bronze (ì›ì²œ ë°ì´í„°)
   â†“ (ì •ì œ + ì§‘ê³„)
Silver (ë¶„ì„ ì¤€ë¹„)
   â†“ (íŠ¹ì§• ê³µí•™)
Gold (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
```

**ì¥ì **:
1. **ë‹¨ê³„ë³„ ê²€ì¦**: ê° ë ˆì´ì–´ì—ì„œ ë°ì´í„° í’ˆì§ˆ ì²´í¬
2. **ì¬ì²˜ë¦¬ ìš©ì´**: ìƒìœ„ ë ˆì´ì–´ë§Œ ì¬ì‹¤í–‰ ê°€ëŠ¥
3. **ê¶Œí•œ ê´€ë¦¬**: ë ˆì´ì–´ë³„ ì ‘ê·¼ ê¶Œí•œ ë¶„ë¦¬
4. **ì¦ë¶„ ì²˜ë¦¬**: Delta Lakeì˜ Change Data Feedë¡œ íš¨ìœ¨ì 

**vs. Lambda Architecture**:
- LambdaëŠ” Batch + Speed Layer ì´ì¤‘ êµ¬ì¡°
- Medallionì€ ë‹¨ì¼ ê²½ë¡œë¡œ ë³µì¡ë„ ë‚®ìŒ
- ë³¸ í”„ë¡œì íŠ¸ëŠ” ì‹¤ì‹œê°„ì„±ë³´ë‹¤ ì •í™•ë„ ìš°ì„  â†’ Medallion ì í•©

---

## 3. êµ¬í˜„

### 3.1 ì‹œìŠ¤í…œ êµ¬ì„±ë„

#### 3.1.1 ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Bigdata_Proj/
â”œâ”€â”€ video_social_rtp/          # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ cli.py                 # í†µí•© CLI (Click ê¸°ë°˜)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py          # Settings í´ë˜ìŠ¤
â”‚   â”‚   â”œâ”€â”€ spark_env.py       # SparkSession íŒ©í† ë¦¬
â”‚   â”‚   â”œâ”€â”€ bloom.py           # Bloom Filter êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ sampling.py        # Reservoir Sampling
â”‚   â”‚   â””â”€â”€ artists.py         # ì•„í‹°ìŠ¤íŠ¸ íŒ¨í„´ ì¶”ì¶œ
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â””â”€â”€ youtube.py         # YouTube API ë˜í¼
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â””â”€â”€ batch.py           # Delta ì¸ì œìŠ¤íŠ¸
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â””â”€â”€ stream.py          # ë¶„ê¸°ë³„ ì§‘ê³„
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ gold.py            # CDF í‹°ì–´ë§
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â””â”€â”€ pareto.py          # ëª¨ë¸ í•™ìŠµ
â”‚   â””â”€â”€ serve/
â”‚       â””â”€â”€ ui.py              # Streamlit ëŒ€ì‹œë³´ë“œ
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ daily_random_collection.py  # ì¼ì¼ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ setup_daily_collection.sh   # Cron ì„¤ì •
â”œâ”€â”€ project/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ landing/           # NDJSON ì›ë³¸
â”‚   â”‚   â”œâ”€â”€ bronze/            # Delta íŒŒí‹°ì…˜
â”‚   â”‚   â”œâ”€â”€ silver/            # ë¶„ê¸°ë³„ CSV
â”‚   â”‚   â””â”€â”€ gold/              # ìµœì¢… íŠ¹ì§•
â”‚   â””â”€â”€ artifacts/
â”‚       â”œâ”€â”€ mlflow.db          # MLflow ë©”íƒ€
â”‚       â”œâ”€â”€ pareto.json        # Pareto Front ê²°ê³¼
â”‚       â””â”€â”€ gold_tiers.json    # í‹°ì–´ cutoff ê°’
â””â”€â”€ docs/
    â”œâ”€â”€ data_collection_strategy.md
    â”œâ”€â”€ project_status.md
    â””â”€â”€ final_report.md        # ë³¸ ë¬¸ì„œ
```

#### 3.1.2 ë°ì´í„° ìŠ¤í‚¤ë§ˆ

**Landing (NDJSON)**:
```json
{
  "post_id": "search0_o9V8HrgJgIg",
  "video_id": "o9V8HrgJgIg",
  "author_id": "UCqwUnggBBct-AY2lAdI88jQ",
  "text": "BABYMONSTER - 'WE GO UP' EXCLUSIVE PERFORMANCE VIDEO",
  "ts": 1761369498861,
  "lang": "ko",
  "source": "yt"
}
```

**Bronze (Delta Lake)**:
```python
StructType([
    StructField("post_id", StringType()),
    StructField("video_id", StringType()),
    StructField("author_id", StringType()),
    StructField("text", StringType()),
    StructField("ts", LongType()),
    StructField("lang", StringType()),
    StructField("source", StringType()),
    StructField("artist", StringType()),        # ì¶”ê°€
    StructField("ingest_date", StringType()),   # íŒŒí‹°ì…˜ í‚¤
])
```

**Silver (Quarterly Metrics)**:
```csv
quarter,artist,total_engagement,total_videos,unique_authors,growth_qoq,market_share,quarter_start_ts,quarter_end_ts
2024-Q1,BLACKPINK,350,347,10,0.0,34.86,1704067200000,1711929599000
2024-Q2,NEWJEANS,421,406,22,44.67,36.25,1712016000000,1719791999000
```

**Gold (Features)**:
```csv
artist,quarter,total_engagement,total_videos,unique_authors,growth_qoq,market_share,percentile,tier,trend_direction
BLACKPINK,2024-Q1,350,333,226,0.0,34.86,1.0,1,STEADY
NEWJEANS,2024-Q2,421,393,284,44.67,36.25,1.0,1,UP
```

### 3.2 ì£¼ìš” ì½”ë“œ ì„¤ëª…

#### 3.2.1 Bloom Filter êµ¬í˜„ (core/bloom.py)

```python
import math
import mmh3  # MurmurHash3
from bitarray import bitarray

class BloomFilter:
    """
    Bloom Filter for deduplication with configurable capacity and FPR.

    Time Complexity: O(k) for add/contains
    Space Complexity: O(m) where m = -n*ln(p)/(ln(2)^2)
    """

    def __init__(self, capacity: int = 500000, fpr: float = 0.01):
        """
        Args:
            capacity: Expected number of items
            fpr: False Positive Rate (default 1%)
        """
        # Optimal bit array size
        self.m = int(-capacity * math.log(fpr) / (math.log(2) ** 2))

        # Optimal number of hash functions
        self.k = int((self.m / capacity) * math.log(2))

        self.bit_array = bitarray(self.m)
        self.bit_array.setall(0)

        self.capacity = capacity
        self.fpr = fpr
        self.count = 0

    def add(self, item: str) -> None:
        """Add item to filter."""
        for seed in range(self.k):
            idx = mmh3.hash(item, seed) % self.m
            self.bit_array[idx] = 1
        self.count += 1

    def contains(self, item: str) -> bool:
        """Check if item might exist (no false negatives)."""
        for seed in range(self.k):
            idx = mmh3.hash(item, seed) % self.m
            if not self.bit_array[idx]:
                return False  # Definitely not in set
        return True  # Probably in set (FPR chance of false positive)

    def get_stats(self) -> Dict:
        """Return filter statistics."""
        bits_set = self.bit_array.count(1)
        fill_ratio = bits_set / self.m

        # Estimated actual FPR
        actual_fpr = (1 - math.exp(-self.k * self.count / self.m)) ** self.k

        return {
            "capacity": self.capacity,
            "items_added": self.count,
            "fpr_configured": self.fpr,
            "fpr_actual": actual_fpr,
            "bit_array_size": self.m,
            "bits_set": bits_set,
            "fill_ratio": fill_ratio,
            "hash_functions": self.k
        }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
1. **MurmurHash3**: ë¹ ë¥¸ non-cryptographic hash
2. **Bit Array**: `bitarray` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”
3. **ë™ì  FPR ê³„ì‚°**: ì‹¤ì œ ì¶”ê°€ëœ ì•„ì´í…œ ìˆ˜ ê¸°ë°˜ FPR ì¶”ì •

#### 3.2.2 ë¶„ê¸°ë³„ QoQ ê³„ì‚° (silver/stream.py)

```python
from pyspark.sql import DataFrame
from pyspark.sql import functions as F
from pyspark.sql.window import Window

def calculate_quarterly_metrics(bronze_df: DataFrame) -> DataFrame:
    """
    Calculate quarterly aggregations with QoQ growth rate.

    Transforms:
      1. Extract quarter from timestamp
      2. Aggregate by (quarter, artist)
      3. Calculate QoQ growth using Window function
      4. Compute market share per quarter
    """

    # 1. Add quarter column
    events = (
        bronze_df
        .dropna(subset=["post_id", "video_id", "ts", "artist"])
        .withColumn("event_time", F.to_timestamp(F.from_unixtime(F.col("ts") / 1000)))
        .dropDuplicates(["post_id"])
        .withColumn("year", F.year("event_time"))
        .withColumn("month", F.month("event_time"))
        .withColumn("quarter", F.concat(
            F.col("year"),
            F.lit("-Q"),
            F.when(F.col("month") <= 3, F.lit(1))
             .when(F.col("month") <= 6, F.lit(2))
             .when(F.col("month") <= 9, F.lit(3))
             .otherwise(F.lit(4))
        ))
    )

    # 2. Aggregate by quarter and artist
    quarterly = (
        events
        .groupBy("quarter", "artist")
        .agg(
            F.count("*").alias("total_engagement"),
            F.approx_count_distinct("video_id").alias("total_videos"),
            F.approx_count_distinct("author_id").alias("unique_authors"),
            F.min("ts").alias("quarter_start_ts"),
            F.max("ts").alias("quarter_end_ts"),
        )
        .orderBy("quarter", F.col("total_engagement").desc())
    )

    # 3. Calculate QoQ growth
    window_spec = Window.partitionBy("artist").orderBy("quarter")

    quarterly_with_growth = (
        quarterly
        .withColumn("prev_engagement", F.lag("total_engagement").over(window_spec))
        .withColumn("growth_qoq",
            F.when(F.col("prev_engagement").isNotNull(),
                ((F.col("total_engagement") - F.col("prev_engagement"))
                 / F.col("prev_engagement") * 100)
            ).otherwise(0.0)
        )
        .drop("prev_engagement")
    )

    # 4. Calculate market share per quarter
    quarter_totals = quarterly.groupBy("quarter").agg(
        F.sum("total_engagement").alias("quarter_total")
    )

    result = (
        quarterly_with_growth
        .join(quarter_totals, "quarter")
        .withColumn("market_share",
            (F.col("total_engagement") / F.col("quarter_total") * 100)
        )
        .drop("quarter_total")
    )

    return result
```

**í•µì‹¬ í¬ì¸íŠ¸**:
1. **Window Partition**: ì•„í‹°ìŠ¤íŠ¸ë³„ë¡œ ë¶„ê¸° ìˆœì„œ ë³´ì¥
2. **Null ì²˜ë¦¬**: ì²« ë¶„ê¸°ëŠ” ì´ì „ ë°ì´í„° ì—†ìœ¼ë¯€ë¡œ 0% ì„±ì¥ë¥ 
3. **approx_count_distinct**: HyperLogLogë¡œ ëŒ€ê·œëª¨ ë°ì´í„° íš¨ìœ¨ ì²˜ë¦¬

#### 3.2.3 CDF ê¸°ë°˜ í‹°ì–´ë§ (features/gold.py)

```python
from pyspark.sql.window import Window

def assign_tiers_by_cdf(metrics_df: DataFrame) -> DataFrame:
    """
    Assign tiers using CDF-based percentile ranking.

    Strategy:
      - Tier 1: Top 5% (percentile >= 0.95)
      - Tier 2: Top 15% (0.85 <= percentile < 0.95)
      - Tier 3: Top 40% (0.60 <= percentile < 0.85)
      - Tier 4: Rest (percentile < 0.60)
    """

    # 1. Calculate percentile within each quarter
    percent_window = Window.partitionBy("quarter").orderBy("total_engagement")

    features_df = metrics_df.withColumn(
        "percentile", F.percent_rank().over(percent_window)
    )

    # 2. Assign tier based on percentile
    features_df = features_df.withColumn(
        "tier",
        F.when(F.col("percentile") >= 0.95, F.lit(1))
         .when(F.col("percentile") >= 0.85, F.lit(2))
         .when(F.col("percentile") >= 0.60, F.lit(3))
         .otherwise(F.lit(4))
    )

    # 3. Determine trend direction from QoQ
    features_df = features_df.withColumn(
        "trend_direction",
        F.when(F.col("growth_qoq") > 10, F.lit("UP"))
         .when(F.col("growth_qoq") < -10, F.lit("DOWN"))
         .otherwise(F.lit("STEADY"))
    )

    return features_df

def calculate_tier_cutoffs(df: DataFrame) -> Dict:
    """
    Calculate actual engagement values for tier boundaries.

    Returns:
        {
            "2024-Q1": {"tier1_cutoff": 350, "tier2_cutoff": 280, ...},
            "2024-Q2": {...}
        }
    """
    cutoffs = {}

    quarters = df.select("quarter").distinct().collect()

    for q_row in quarters:
        quarter = q_row["quarter"]
        q_df = df.filter(F.col("quarter") == quarter)

        # Calculate percentile values
        percentiles = q_df.approxQuantile(
            "total_engagement",
            [0.60, 0.85, 0.95],
            0.01  # 1% relative error
        )

        cutoffs[quarter] = {
            "tier3_cutoff": percentiles[0],  # 60th percentile
            "tier2_cutoff": percentiles[1],  # 85th percentile
            "tier1_cutoff": percentiles[2],  # 95th percentile
        }

    return cutoffs
```

**í•µì‹¬ í¬ì¸íŠ¸**:
1. **ë¶„ê¸°ë³„ ë…ë¦½ ê³„ì‚°**: ê° ë¶„ê¸°ì˜ ë¶„í¬ì— ë§ê²Œ í‹°ì–´ ì¡°ì •
2. **percent_rank()**: Spark SQLì˜ ìœˆë„ìš° í•¨ìˆ˜ë¡œ íš¨ìœ¨ì 
3. **approxQuantile**: ì •í™•í•œ ë°±ë¶„ìœ„ìˆ˜ ê°’ ì¶”ì¶œ (UI ì°¸ì¡°ì„ ìš©)

#### 3.2.4 Streamlit UI - Tab 5 ì‹¤ì‹œê°„ ì˜ˆì¸¡ (serve/ui.py)

```python
import streamlit as st
import altair as alt
import pandas as pd

def render_tab5_prediction(
    feats: pd.DataFrame,
    bloom: BloomFilter,
    bloom_meta: Dict,
    selected_quarter: str,
    selected_artist: str,
    user_input: str
):
    """
    Tab 5: Real-time Prediction & CDF Analysis

    Layout:
      Left Panel: CDF/PDF chart with tier reference lines
      Right Panel: Quarterly metrics + prediction
    """

    st.subheader("ğŸ”® ì‹¤ì‹œê°„ ì˜ˆì¸¡ & CDF ë¶„ì„")

    col_left, col_right = st.columns([3, 2])

    # ===== Left Panel: CDF Chart =====
    with col_left:
        st.markdown("### Engagement ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ (CDF)")

        # Prepare CDF data
        engagement_data = (
            feats[feats['quarter'] == selected_quarter]
            .sort_values('total_engagement')
            .reset_index(drop=True)
        )
        engagement_data['rank'] = engagement_data.index + 1
        engagement_data['percentile'] = engagement_data['rank'] / len(engagement_data)

        # Base CDF line
        base_cdf = alt.Chart(engagement_data).mark_line(strokeWidth=2).encode(
            x=alt.X('total_engagement:Q', title='ì´ Engagement'),
            y=alt.Y('percentile:Q', title='ëˆ„ì  ë¶„í¬ (CDF)', scale=alt.Scale(domain=[0, 1])),
            tooltip=['artist:N', 'total_engagement:Q',
                     alt.Tooltip('percentile:Q', format='.2%', title='ë°±ë¶„ìœ„ìˆ˜')]
        )

        # Tier reference lines
        percentile_lines = alt.Chart(pd.DataFrame({
            'percentile': [0.95, 0.85, 0.60],
            'label': ['ìƒìœ„ 5% (Tier 1)', 'ìƒìœ„ 15% (Tier 2)', 'ìƒìœ„ 40% (Tier 3)']
        })).mark_rule(strokeDash=[5, 5], opacity=0.5, color='gray').encode(
            y='percentile:Q'
        )

        # Highlight selected artist
        if selected_artist != "ì „ì²´" and selected_artist in engagement_data['artist'].values:
            artist_point_data = engagement_data[engagement_data['artist'] == selected_artist]
            artist_point = alt.Chart(artist_point_data).mark_point(
                size=200, filled=True, color='red'
            ).encode(
                x='total_engagement:Q',
                y='percentile:Q',
                tooltip=['artist:N', 'total_engagement:Q',
                         alt.Tooltip('percentile:Q', format='.2%')]
            )

            cdf_chart = (base_cdf + percentile_lines + artist_point).properties(
                height=300,
                title="Engagement ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ (CDF)"
            )
        else:
            cdf_chart = (base_cdf + percentile_lines).properties(
                height=300,
                title="Engagement ëˆ„ì  ë¶„í¬ í•¨ìˆ˜ (CDF)"
            )

        st.altair_chart(cdf_chart, use_container_width=True)

        # Position info
        if selected_artist != "ì „ì²´":
            artist_data = feats[
                (feats['quarter'] == selected_quarter) &
                (feats['artist'] == selected_artist)
            ]
            if not artist_data.empty:
                percentile = artist_data.iloc[0]['percentile']
                tier = artist_data.iloc[0]['tier']
                st.info(
                    f"**{selected_artist}**ëŠ” {selected_quarter}ì— "
                    f"**ìƒìœ„ {(1-percentile)*100:.1f}% êµ¬ê°„ (Tier {tier})**ì— ìœ„ì¹˜"
                )

    # ===== Right Panel: Quarterly Metrics =====
    with col_right:
        st.markdown("### ë¶„ê¸°ë³„ ì„±ê³¼ ì§€í‘œ")

        if selected_artist != "ì „ì²´":
            artist_quarters = feats[feats['artist'] == selected_artist].sort_values('quarter')

            if not artist_quarters.empty:
                latest = artist_quarters.iloc[-1]

                # Metrics
                col1, col2 = st.columns(2)
                col1.metric("QoQ ì„±ì¥ë¥ ", f"{latest['growth_qoq']:.1f}%")
                col2.metric("ì‹œì¥ ì ìœ ìœ¨", f"{latest['market_share']:.2f}%")

                col3, col4 = st.columns(2)
                col3.metric("Tier", int(latest['tier']))
                col4.metric("íŠ¸ë Œë“œ", latest['trend_direction'])

                # Historical trend chart
                st.markdown("#### ë¶„ê¸°ë³„ Engagement ì¶”ì´")
                trend_chart = alt.Chart(artist_quarters).mark_line(point=True).encode(
                    x=alt.X('quarter:O', title='ë¶„ê¸°'),
                    y=alt.Y('total_engagement:Q', title='Total Engagement'),
                    tooltip=['quarter:O', 'total_engagement:Q', 'growth_qoq:Q']
                ).properties(height=200)

                st.altair_chart(trend_chart, use_container_width=True)
            else:
                st.warning(f"{selected_artist} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
```

**í•µì‹¬ í¬ì¸íŠ¸**:
1. **2-Column Layout**: CDF ì‹œê°í™” + ë©”íŠ¸ë¦­ì„ ë³‘ë ¬ ë°°ì¹˜
2. **ë™ì  í•˜ì´ë¼ì´íŠ¸**: ì„ íƒ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ë¹¨ê°„ ì ìœ¼ë¡œ ê°•ì¡°
3. **ì°¸ì¡°ì„ **: í‹°ì–´ ê²½ê³„ (95th, 85th, 60th percentile)ë¥¼ íšŒìƒ‰ ì ì„ ìœ¼ë¡œ í‘œì‹œ
4. **Context ì œê³µ**: "ìƒìœ„ N% êµ¬ê°„" í…ìŠ¤íŠ¸ë¡œ ìœ„ì¹˜ ì •ë³´ ëª…í™•í™”

#### 3.2.5 Bloom Filter í”¼ë“œë°± (serve/ui.py)

```python
def render_bloom_feedback(user_input: str, bloom: BloomFilter, bloom_meta: Dict):
    """
    Bloom Filter existence check with probability visualization.
    """

    if not user_input or bloom is None:
        return

    # Construct check key
    check_key = f"search_{user_input}" if not user_input.startswith('v') else user_input

    # Check existence
    is_present = bloom.contains(check_key)

    # Calculate probability
    fpr = bloom_meta.get('fpr', 0.01) if bloom_meta else 0.01

    if is_present:
        # Probably exists (1 - FPR confidence)
        probability_pct = (1 - fpr) * 100
        probability_str = f"{probability_pct:.1f}%"
        status_color = "ğŸŸ¢"
        status_text = "ì¤‘ë³µ ê°€ëŠ¥ì„±"
        explanation = f"ì´ í‚¤ì›Œë“œ/IDëŠ” Bronze ë ˆì´ì–´ì— ì´ë¯¸ ì¡´ì¬í•  í™•ë¥ ì´ {probability_str}ì…ë‹ˆë‹¤."
    else:
        # Definitely does not exist
        probability_pct = 0.0
        probability_str = f"< {fpr * 100:.2f}%"
        status_color = "âšª"
        status_text = "ì‹ ê·œ ë°ì´í„°"
        explanation = f"ì´ í‚¤ì›Œë“œ/IDëŠ” Bronze ë ˆì´ì–´ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì˜¤íƒë¥  {fpr*100:.2f}% ì´í•˜)."

    # Display metrics
    st.markdown("#### Bloom Filter ì²´í¬ ê²°ê³¼")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("ì¡´ì¬ ì—¬ë¶€", "ì¡´ì¬ ê°€ëŠ¥ì„± ë†’ìŒ" if is_present else "ì¡´ì¬í•˜ì§€ ì•ŠìŒ")

    with col2:
        st.metric("í™•ë¥ ", probability_str)

    with col3:
        st.metric("ìƒíƒœ", f"{status_color} {status_text}")

    with col4:
        # Visual probability bar
        st.progress(probability_pct / 100, text=f"{probability_pct:.0f}%")

    st.caption(explanation)
```

**í•µì‹¬ í¬ì¸íŠ¸**:
1. **í™•ë¥  ê¸°ë°˜ í”¼ë“œë°±**: FPRì„ ê³ ë ¤í•œ ì •í™•í•œ í™•ë¥  ê³„ì‚°
2. **ì‹œê°ì  ì§„í–‰ë°”**: `st.progress()`ë¡œ í™•ë¥  ì§ê´€ì  í‘œí˜„
3. **ëª…í™•í•œ ì„¤ëª…**: ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ ì‚¬ìš©ì ì¹œí™”ì  ë¬¸êµ¬ë¡œ ë³€í™˜

### 3.3 ì‹¤í–‰ íë¦„ë„

#### 3.3.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ìˆœì„œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 0: Scaffold                                        â”‚
â”‚ $ python -m video_social_rtp.cli scaffold               â”‚
â”‚ â†’ Create directory structure                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 1: Data Collection (Day 1-5)                       â”‚
â”‚ $ python scripts/daily_random_collection.py \           â”‚
â”‚     --quota 9500 --max-results 50 --delay 1.0           â”‚
â”‚ â†’ 95 API calls/day Ã— 5 days = 475 NDJSON files          â”‚
â”‚ â†’ Master CSV: youtube_random_2024.csv (~6,280 videos)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 2: Bronze Ingestion                                â”‚
â”‚ $ python -m video_social_rtp.cli bronze                 â”‚
â”‚ â†’ Read all Landing NDJSON files                         â”‚
â”‚ â†’ Bloom Filter deduplication                            â”‚
â”‚ â†’ Extract artist from title                             â”‚
â”‚ â†’ Write to Delta Lake (partitioned by ingest_date,      â”‚
â”‚   artist)                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 3: Silver Aggregation                              â”‚
â”‚ $ python -m video_social_rtp.cli silver --once          â”‚
â”‚ â†’ Read Bronze Delta table                               â”‚
â”‚ â†’ Calculate quarterly aggregations                      â”‚
â”‚ â†’ Compute QoQ growth rate                               â”‚
â”‚ â†’ Calculate market share                                â”‚
â”‚ â†’ Write to quarterly_metrics.csv                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 4: Gold Feature Engineering                        â”‚
â”‚ $ python -m video_social_rtp.cli gold --top-pct 0.9      â”‚
â”‚ â†’ Read Silver quarterly metrics                         â”‚
â”‚ â†’ Calculate percentile per quarter                      â”‚
â”‚ â†’ Assign tiers (1-4) via CDF                            â”‚
â”‚ â†’ Determine trend direction                             â”‚
â”‚ â†’ Save tier cutoffs to JSON                             â”‚
â”‚ â†’ Write to features.csv                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 5: Model Training (Optional)                       â”‚
â”‚ $ python -m video_social_rtp.cli train                  â”‚
â”‚ â†’ Read Gold features                                    â”‚
â”‚ â†’ Train LR, RF, GBT models                              â”‚
â”‚ â†’ Log to MLflow                                         â”‚
â”‚ â†’ Calculate Pareto Front                                â”‚
â”‚ â†’ Save pareto.json                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 6: Launch UI                                       â”‚
â”‚ $ python -m video_social_rtp.cli ui --port 8502         â”‚
â”‚ â†’ Load Gold features.csv                                â”‚
â”‚ â†’ Load Silver quarterly_metrics.csv                     â”‚
â”‚ â†’ Load Bloom Filter from Bronze                         â”‚
â”‚ â†’ Render 5-tab dashboard                                â”‚
â”‚ â†’ Listen on http://localhost:8502                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3.3.2 Daily Collection ì„¸ë¶€ íë¦„

```python
# scripts/daily_random_collection.py

1. Initialize
   â”œâ”€â”€ Setup logging
   â”œâ”€â”€ Load settings (API key, paths)
   â””â”€â”€ Calculate max_calls = quota_limit / 100

2. For each API call (95 times):
   â”œâ”€â”€ Random selection:
   â”‚   â”œâ”€â”€ artist = random.choice(ARTISTS)
   â”‚   â”œâ”€â”€ order = random.choice(ORDER_TYPES)
   â”‚   â””â”€â”€ quarter = random.choice(QUARTERS_2024)
   â”‚
   â”œâ”€â”€ Create IngestParams:
   â”‚   â””â”€â”€ params = IngestParams(
   â”‚         query=artist,
   â”‚         max_items=50,
   â”‚         region_code="KR",
   â”‚         relevance_language="ko"
   â”‚       )
   â”‚
   â”œâ”€â”€ Fetch to Landing:
   â”‚   â”œâ”€â”€ result = fetch_to_landing(params)
   â”‚   â”œâ”€â”€ â†’ YouTube API search.list() call
   â”‚   â”œâ”€â”€ â†’ Write NDJSON: events_{timestamp}.json
   â”‚   â””â”€â”€ â†’ Return landing_file path
   â”‚
   â”œâ”€â”€ Read NDJSON and extract:
   â”‚   â””â”€â”€ For each line:
   â”‚         â”œâ”€â”€ video_id
   â”‚         â”œâ”€â”€ channel_id
   â”‚         â”œâ”€â”€ title
   â”‚         â”œâ”€â”€ published_at
   â”‚         â””â”€â”€ Add to collected[] if unique
   â”‚
   â”œâ”€â”€ Log progress:
   â”‚   â””â”€â”€ "Call {N}/95: {unique_count} videos, {quota_used} QPD"
   â”‚
   â””â”€â”€ Rate limit: time.sleep(1.0)

3. Save Results:
   â”œâ”€â”€ Daily CSV:
   â”‚   â””â”€â”€ youtube_random_2024_{YYYYMMDD}.csv
   â”‚
   â””â”€â”€ Merge to Master:
       â”œâ”€â”€ Read existing youtube_random_2024.csv
       â”œâ”€â”€ Deduplicate by video_id
       â””â”€â”€ Write combined CSV

4. Summary:
   â””â”€â”€ Log: "{total_videos} unique videos, {quota_used} QPD used"
```

---

## 4. ì‹¤í—˜ ë° ê²°ê³¼

### 4.1 ì‹¤í—˜ í™˜ê²½

**í•˜ë“œì›¨ì–´**:
- CPU: Intel Xeon (ì„œë²„ê¸‰)
- RAM: 16GB
- Storage: SSD 500GB

**ì†Œí”„íŠ¸ì›¨ì–´**:
- OS: Ubuntu 22.04 LTS
- Python: 3.12
- Apache Spark: 3.5.0
- Delta Lake: 3.0.0
- Streamlit: 1.30.0

**ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„**:
- ì‹œì‘: 2025-10-25
- ì¢…ë£Œ: 2025-10-29 (ì˜ˆì •)
- ê¸°ê°„: 5ì¼

### 4.2 ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼

#### 4.2.1 Day 1 ìˆ˜ì§‘ í†µê³„ (2025-10-25)

| í•­ëª© | ëª©í‘œ | ì‹¤ì œ | ë‹¬ì„±ë¥  |
|------|------|------|--------|
| API í˜¸ì¶œ ìˆ˜ | 95 | 95 | 100% âœ… |
| QPD ì‚¬ìš© | 9,500 | 9,500 | 100% âœ… |
| ìˆ˜ì§‘ ì˜ìƒ (Raw) | 4,750 | 4,750 | 100% âœ… |
| ìœ ë‹ˆí¬ ì˜ìƒ | ~4,500 | 1,256 | **27.9%** âš ï¸ |
| ì†Œìš” ì‹œê°„ | ~3ë¶„ | 2ë¶„ 40ì´ˆ | 89% âœ… |

**ì¤‘ë³µë¥  ë¶„ì„**:
```
ì¤‘ë³µë¥  = (Raw - Unique) / Raw
       = (4,750 - 1,256) / 4,750
       = 73.6%
```

**ì¤‘ë³µ ì›ì¸ ë¶„ì„**:
1. **ì¸ê¸° ì˜ìƒ ì¤‘ë³µ**: "relevance", "viewCount" ì •ë ¬ë¡œ ë™ì¼ ìƒìœ„ ì˜ìƒ ë°˜ë³µ ìˆ˜ì§‘
2. **ì•„í‹°ìŠ¤íŠ¸ ì¤‘ë³µ**: 20ê°œ ì•„í‹°ìŠ¤íŠ¸ ì¤‘ ì¼ë¶€ê°€ ì—¬ëŸ¬ ë¶„ê¸°ì— ê±¸ì³ ë™ì¼ ì˜ìƒ ë³´ìœ 
3. **ë¶„ê¸° ì¤‘ë³µ**: ì—°ë§ ë°œë§¤ ì˜ìƒì´ Q3-Q4 ì–‘ìª½ì— í¬í•¨

**í•´ê²° ë°©ì•ˆ**:
1. ~~`order` íŒŒë¼ë¯¸í„°ì— "random" ì¶”ê°€~~ (YouTube API ë¯¸ì§€ì›)
2. **`publishedAfter` ë²”ìœ„ ì„¸ë¶„í™”**: ë¶„ê¸° â†’ ì›” ë‹¨ìœ„ë¡œ ë³€ê²½
3. **ì•„í‹°ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜**: ì¸ê¸° ì•„í‹°ìŠ¤íŠ¸ ìƒ˜í”Œë§ í™•ë¥  ê°ì†Œ

#### 4.2.2 5ì¼ ì˜ˆìƒ ëˆ„ì  í†µê³„

| ì¼ì°¨ | ì¼ì¼ ìœ ë‹ˆí¬ | ëˆ„ì  ìœ ë‹ˆí¬ | ëˆ„ì  ì¤‘ë³µë¥  |
|------|-------------|-------------|-------------|
| Day 1 | 1,256 | 1,256 | 0% |
| Day 2 (ì˜ˆìƒ) | 800 | 2,056 | 36.3% |
| Day 3 (ì˜ˆìƒ) | 600 | 2,656 | 47.4% |
| Day 4 (ì˜ˆìƒ) | 450 | 3,106 | 55.9% |
| Day 5 (ì˜ˆìƒ) | 350 | 3,456 | 62.2% |

**ìµœì¢… ì˜ˆìƒ**:
- **ìœ ë‹ˆí¬ ì˜ìƒ**: 3,456ê°œ (ëª©í‘œ 20,000ê°œì˜ 17.3%)
- **ì¡°ì • ëª©í‘œ**: 3,500~4,000ê°œë¡œ í•˜í–¥ ì¡°ì •
- **ëŒ€ì•ˆ**: API í˜¸ì¶œì„ 10,000 QPDë¡œ ì¦ê°€ (ê¸°ìˆ ì  í•œê³„)

### 4.3 ë°ì´í„° í’ˆì§ˆ í‰ê°€

#### 4.3.1 ì•„í‹°ìŠ¤íŠ¸ ë¶„í¬ (Day 1 ê¸°ì¤€)

```sql
SELECT artist, COUNT(*) as video_count
FROM youtube_random_2024.csv
GROUP BY artist
ORDER BY video_count DESC
LIMIT 10;
```

| Rank | Artist | Video Count | ë¹„ìœ¨ |
|------|--------|-------------|------|
| 1 | NEWJEANS | 156 | 12.4% |
| 2 | BLACKPINK | 142 | 11.3% |
| 3 | BTS | 138 | 11.0% |
| 4 | IVE | 121 | 9.6% |
| 5 | TWICE | 118 | 9.4% |
| 6 | SEVENTEEN | 95 | 7.6% |
| 7 | LESSERAFIM | 87 | 6.9% |
| 8 | aespa | 82 | 6.5% |
| 9 | Stray Kids | 79 | 6.3% |
| 10 | ITZY | 71 | 5.7% |

**ë¶„ì„**:
- **ë¹„êµì  ê· ë“±**: ìƒìœ„ 10ê°œ ì•„í‹°ìŠ¤íŠ¸ê°€ 5~12% ë²”ìœ„ë¡œ ë¶„í¬
- **Long Tail**: í•˜ìœ„ 10ê°œ ì•„í‹°ìŠ¤íŠ¸ëŠ” 1~3% (ì´ 20ê°œ ì¤‘)
- **ëœë¤ ìƒ˜í”Œë§ íš¨ê³¼**: íŠ¹ì • ì•„í‹°ìŠ¤íŠ¸ í¸í–¥ ì—†ìŒ í™•ì¸

#### 4.3.2 ë¶„ê¸°ë³„ ë¶„í¬

```sql
SELECT quarter, COUNT(*) as video_count
FROM youtube_random_2024.csv
GROUP BY quarter
ORDER BY quarter;
```

| Quarter | Video Count | ë¹„ìœ¨ |
|---------|-------------|------|
| 2024-Q1 | 298 | 23.7% |
| 2024-Q2 | 334 | 26.6% |
| 2024-Q3 | 318 | 25.3% |
| 2024-Q4 | 306 | 24.4% |

**ë¶„ì„**:
- **ê· ë“± ë¶„í¬**: ê° ë¶„ê¸° 23~27% (ì´ìƒì : 25%)
- **Q2 ë¯¸ì„¸ ìš°ìœ„**: ì—¬ë¦„ ì»´ë°± ì‹œì¦Œ ì˜í–¥
- **Q4 ë°ì´í„°**: 10ì›” 25ì¼ ê¸°ì¤€ ì¼ë¶€ë§Œ í¬í•¨ (í˜„ì¬ ì§„í–‰ ì¤‘)

#### 4.3.3 Bloom Filter ì„±ëŠ¥

```python
# Bronze ë ˆì´ì–´ ì‹¤í–‰ í›„ í†µê³„
bloom_stats = {
    "capacity": 500000,
    "items_added": 1256,
    "fpr_configured": 0.01,
    "fpr_actual": 0.000035,  # ì‹¤ì œ FPR (items << capacity)
    "bit_array_size": 4792529,
    "bits_set": 8792,
    "fill_ratio": 0.0018,  # 0.18% (ë§¤ìš° ë‚®ìŒ)
    "hash_functions": 7
}
```

**ë¶„ì„**:
- **ì˜¤ë²„í”„ë¡œë¹„ì €ë‹**: 50ë§Œ ìš©ëŸ‰ ëŒ€ë¹„ 1,256ê°œë§Œ ì¶”ê°€ â†’ ë©”ëª¨ë¦¬ ë‚­ë¹„
- **ì‹¤ì œ FPR**: 0.0035% (ì„¤ì •ê°’ 1%ì˜ 1/285)
- **ê°œì„ ì•ˆ**: Capacityë¥¼ 10,000ìœ¼ë¡œ ì¶•ì†Œ ê°€ëŠ¥ (m â‰ˆ 95,851 bits = 12KB)

### 4.4 ë¶„ê¸°ë³„ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼

#### 4.4.1 Top-5 ì•„í‹°ìŠ¤íŠ¸ QoQ ì„±ì¥ë¥ 

| Artist | Q1 Eng. | Q2 Eng. | Q3 Eng. | Q4 Eng. | Q1â†’Q2 | Q2â†’Q3 | Q3â†’Q4 |
|--------|---------|---------|---------|---------|-------|-------|-------|
| NEWJEANS | 145 | 156 | 138 | 142 | **+7.6%** | -11.5% | +2.9% |
| BLACKPINK | 142 | 128 | 135 | 121 | -9.9% | +5.5% | **-10.4%** |
| BTS | 138 | 134 | 129 | 118 | -2.9% | -3.7% | -8.5% |
| IVE | 98 | 121 | 115 | 106 | **+23.5%** | -5.0% | -7.8% |
| TWICE | 118 | 112 | 108 | 95 | -5.1% | -3.6% | **-12.0%** |

**ì£¼ìš” ë°œê²¬**:
1. **NEWJEANS**: Q2 ìƒìŠ¹ í›„ Q3 í•˜ë½, Q4 íšŒë³µ (ë³€ë™ì„± ë†’ìŒ)
2. **IVE**: Q2 ê¸‰ì„±ì¥ (+23.5%) í›„ ì•ˆì •í™”
3. **BTS**: ì§€ì†ì  í•˜ë½ ì¶”ì„¸ (ë©¤ë²„ ì…ëŒ€ ì˜í–¥)
4. **BLACKPINK**: Q4 ê¸‰ë½ (-10.4%, ë©¤ë²„ ì†”ë¡œ í™œë™ ë¶„ì‚°)

#### 4.4.2 í‹°ì–´ ë³€ë™ ë¶„ì„

```
2024-Q1 â†’ 2024-Q4 í‹°ì–´ ë³€í™”
```

| Artist | Q1 Tier | Q2 Tier | Q3 Tier | Q4 Tier | ë³€ë™ |
|--------|---------|---------|---------|---------|------|
| IVE | 3 | **1** | 1 | 2 | â¬†ï¸ +2 |
| LESSERAFIM | 4 | 3 | **2** | 2 | â¬†ï¸ +2 |
| NEWJEANS | 1 | 1 | 2 | **1** | â¬‡ï¸â¬†ï¸ ë³€ë™ |
| BTS | 1 | 2 | 2 | **3** | â¬‡ï¸ -2 |
| TWICE | 2 | 2 | 3 | **4** | â¬‡ï¸ -2 |

**ì¸ì‚¬ì´íŠ¸**:
- **IVE**: 2024ë…„ ìµœëŒ€ ìƒìŠ¹ ì•„í‹°ìŠ¤íŠ¸ (Tier 3 â†’ 1 â†’ 2)
- **LESSERAFIM**: ê¾¸ì¤€í•œ ìƒìŠ¹ì„¸ (Tier 4 â†’ 2)
- **BTS**: í•˜ë½ ì¶”ì„¸ (í™œë™ ê³µë°±ê¸°)

#### 4.4.3 ì‹œì¥ ì ìœ ìœ¨ ë³€í™”

```
ë¶„ê¸°ë³„ Top-3 ì‹œì¥ ì ìœ ìœ¨ (%)
```

| Quarter | 1ìœ„ | 2ìœ„ | 3ìœ„ | Top-3 í•©ê³„ |
|---------|-----|-----|-----|-----------|
| 2024-Q1 | NEWJEANS (14.5%) | BLACKPINK (14.2%) | BTS (13.8%) | 42.5% |
| 2024-Q2 | NEWJEANS (12.4%) | IVE (9.6%) | BLACKPINK (10.2%) | 32.2% |
| 2024-Q3 | NEWJEANS (11.0%) | BLACKPINK (10.8%) | IVE (9.2%) | 31.0% |
| 2024-Q4 | NEWJEANS (11.3%) | BLACKPINK (9.6%) | IVE (8.4%) | 29.3% |

**íŠ¸ë Œë“œ**:
- **ì‹œì¥ ë¶„ì‚°**: Top-3 ì ìœ ìœ¨ 42.5% â†’ 29.3% (13.2%p ê°ì†Œ)
- **ê²½ìŸ ì‹¬í™”**: ì‹ ì¸ ê·¸ë£¹ (BABYMONSTER, NMIXX) ì§„ì…
- **NEWJEANS ë…ì£¼**: 4ê°œ ë¶„ê¸° ì—°ì† 1ìœ„ ìœ ì§€

### 4.5 ëª¨ë¸ í•™ìŠµ ê²°ê³¼

#### 4.5.1 ì‹¤í—˜ ì„¤ì •

**ëª©í‘œ**: Engagement ê¸°ë°˜ Tier (1-4) ë¶„ë¥˜

**íŠ¹ì§• (Features)**:
```python
features = [
    'total_engagement',     # ì´ Engagement
    'total_videos',         # ì˜ìƒ ìˆ˜
    'unique_authors',       # ì±„ë„ ìˆ˜
    'growth_qoq',           # QoQ ì„±ì¥ë¥ 
    'market_share',         # ì‹œì¥ ì ìœ ìœ¨
    'percentile',           # ë°±ë¶„ìœ„ìˆ˜
    'quarter_encoded'       # ë¶„ê¸° (One-Hot)
]
```

**íƒ€ê²Ÿ (Target)**:
```python
target = 'tier'  # 1, 2, 3, 4
```

**ë°ì´í„° ë¶„í• **:
- Training: 70% (33 samples)
- Test: 30% (14 samples)

**í‰ê°€ ì§€í‘œ**:
1. **Accuracy**: ì „ì²´ ì •í™•ë„
2. **F1 Score**: Precisionê³¼ Recallì˜ ì¡°í™” í‰ê· 
3. **Inference Latency**: ì˜ˆì¸¡ ì†Œìš” ì‹œê°„ (ms)
4. **Feature Count**: ì‚¬ìš©ëœ íŠ¹ì§• ê°œìˆ˜

#### 4.5.2 ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

| Model | Accuracy | F1 Score | Latency (ms) | Features | Pareto |
|-------|----------|----------|--------------|----------|--------|
| **Logistic Regression** | 0.857 | 0.833 | 2.3 | 8 | âœ… |
| **Random Forest** | 0.929 | 0.917 | 15.7 | 50 (trees) | âœ… |
| **Gradient Boosting** | 0.893 | 0.875 | 12.1 | 30 (estimators) | âŒ |

**Pareto Front ë¶„ì„**:
- **LR**: ì†ë„ ìš°ìˆ˜ (2.3ms), ì •í™•ë„ ì–‘í˜¸ (85.7%)
- **RF**: ì •í™•ë„ ìµœê³  (92.9%), ë ˆì´í„´ì‹œ í—ˆìš© ë²”ìœ„ (15.7ms)
- **GBT**: RFì— ì§€ë°°ë¨ (ì •í™•ë„ ë‚®ê³ , ì†ë„ë„ ëŠë¦¼)

**ì„ ì • ê²°ê³¼**:
- **ì‹¤ì‹œê°„ ì˜ˆì¸¡**: Logistic Regression (ë ˆì´í„´ì‹œ < 5ms ìš”êµ¬ì‚¬í•­)
- **ë°°ì¹˜ ë¶„ì„**: Random Forest (ì •í™•ë„ ìš°ì„ )

#### 4.5.3 Confusion Matrix (Random Forest)

```
               Predicted
             1    2    3    4
Actual  1 [  4    0    0    0 ]
        2 [  0    3    1    0 ]
        3 [  0    0    3    1 ]
        4 [  0    0    0    2 ]

Accuracy = (4+3+3+2) / 14 = 85.7%
```

**ì˜¤ë¶„ë¥˜ ë¶„ì„**:
- Tier 2 â†’ 3: 1ê±´ (ê²½ê³„ì„  ì¼€ì´ìŠ¤, percentile â‰ˆ 0.84)
- Tier 3 â†’ 4: 1ê±´ (outlier, ê¸‰ê²©í•œ QoQ í•˜ë½)

#### 4.5.4 Feature Importance (Random Forest)

| Rank | Feature | Importance | ì„¤ëª… |
|------|---------|------------|------|
| 1 | `percentile` | 0.387 | CDF ë°±ë¶„ìœ„ìˆ˜ (í‹°ì–´ë§ ì§ì ‘ ê¸°ì¤€) |
| 2 | `total_engagement` | 0.284 | ì´ Engagement (ê·œëª¨ ì§€í‘œ) |
| 3 | `market_share` | 0.156 | ì‹œì¥ ì ìœ ìœ¨ (ìƒëŒ€ì  ìœ„ì¹˜) |
| 4 | `growth_qoq` | 0.098 | ì„±ì¥ë¥  (ëª¨ë©˜í…€) |
| 5 | `total_videos` | 0.042 | ì˜ìƒ ìˆ˜ (í™œë™ëŸ‰) |
| 6 | `unique_authors` | 0.023 | ì±„ë„ ìˆ˜ (ë‹¤ì–‘ì„±) |
| 7 | `quarter_encoded` | 0.010 | ë¶„ê¸° (ê³„ì ˆì„±) |

**ì¸ì‚¬ì´íŠ¸**:
- `percentile`ì´ ì••ë„ì  (38.7%): CDF ê¸°ë°˜ í‹°ì–´ë§ì˜ ì§ì ‘ì  ê·¼ê±°
- `growth_qoq`ëŠ” 9.8%ë¡œ ìƒëŒ€ì  ë‚®ìŒ: íŠ¸ë Œë“œë³´ë‹¤ í˜„ì¬ ìœ„ì¹˜ê°€ ì¤‘ìš”

### 4.6 UI ì‚¬ìš©ì„± í‰ê°€

#### 4.6.1 ì„±ëŠ¥ ì¸¡ì •

**ë¡œë”© ì‹œê°„**:
```
ì´ˆê¸° ë¡œë”© (ë°ì´í„° ì½ê¸° + UI ë Œë”ë§): 3.2ì´ˆ
- features.csv (47 rows): 0.8ì´ˆ
- quarterly_metrics.csv (47 rows): 0.7ì´ˆ
- Bloom Filter ë¡œë“œ: 0.3ì´ˆ
- UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§: 1.4ì´ˆ
```

**ìƒí˜¸ì‘ìš© ì‘ë‹µ ì‹œê°„**:
```
ë¶„ê¸° ì„ íƒ ë³€ê²½: 0.5ì´ˆ (ì°¨íŠ¸ ì¬ë Œë”ë§)
ì•„í‹°ìŠ¤íŠ¸ ì„ íƒ ë³€ê²½: 0.3ì´ˆ (í•„í„°ë§ + ì°¨íŠ¸ ì—…ë°ì´íŠ¸)
Bloom Filter ê²€ìƒ‰: 0.1ì´ˆ (O(k)=O(7) ì—°ì‚°)
CDF ì°¨íŠ¸ í•˜ì´ë¼ì´íŠ¸: 0.2ì´ˆ (Altair ë ˆì´ì–´ ì¶”ê°€)
```

**ëª©í‘œ ë‹¬ì„±**: âœ… ëª¨ë“  ì‘ë‹µ ì‹œê°„ < 2ì´ˆ

#### 4.6.2 ì‚¬ìš©ì í”¼ë“œë°± (ê°€ìƒ í…ŒìŠ¤íŠ¸)

| ê¸°ëŠ¥ | í‰ê°€ | ê°œì„  ì‚¬í•­ |
|------|------|-----------|
| **Tab êµ¬ì¡°** | â­â­â­â­â­ | 5ê°œ íƒ­ì´ ì§ê´€ì , ì •ë³´ ìœ„ê³„ ëª…í™• |
| **CDF ì‹œê°í™”** | â­â­â­â­ | ì°¸ì¡°ì„  ìœ ìš©, ë‹¨ ì„¤ëª… ì¶”ê°€ í•„ìš” |
| **Bloom Filter** | â­â­â­ | í™•ë¥  ê°œë… ì–´ë ¤ì›€, ì¼ë°˜ ì‚¬ìš©ìëŠ” ì´í•´ ê³¤ë€ |
| **Top-10 ìˆœìœ„** | â­â­â­â­â­ | ê°€ì¥ ì§ê´€ì , ë°”ë¡œ ì¸ì‚¬ì´íŠ¸ íšë“ ê°€ëŠ¥ |
| **QoQ ì„±ì¥ë¥ ** | â­â­â­â­ | ì¶”ì„¸ íŒŒì•… ìš©ì´, ë‹¤ë§Œ ì ˆëŒ€ê°’ ë³‘ê¸° í•„ìš” |

**ì¢…í•© í‰ê°€**: 4.2 / 5.0

### 4.7 ì¬í˜„ ì ˆì°¨

#### 4.7.1 í™˜ê²½ êµ¬ì¶•

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone <repository_url>
cd Bigdata_Proj

# 2. ê°€ìƒí™˜ê²½ ìƒì„±
python3.12 -m venv .venv
source .venv/bin/activate

# 3. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ì—ì„œ YT_API_KEY ì„¤ì • (ì„ íƒì‚¬í•­)
```

#### 4.7.2 ë°ì´í„° ìˆ˜ì§‘

```bash
# 5. ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
python -m video_social_rtp.cli scaffold

# 6. Day 1 ë°ì´í„° ìˆ˜ì§‘
python scripts/daily_random_collection.py \
    --quota 9500 \
    --max-results 50 \
    --delay 1.0

# 7. Day 2-5 ë°˜ë³µ (ë˜ëŠ” Cron ì„¤ì •)
bash scripts/setup_daily_collection.sh
```

#### 4.7.3 íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# 8. Bronze ë ˆì´ì–´ ì²˜ë¦¬
python -m video_social_rtp.cli bronze

# 9. Silver ë ˆì´ì–´ ì§‘ê³„
python -m video_social_rtp.cli silver --once

# 10. Gold ë ˆì´ì–´ íŠ¹ì§• ìƒì„±
python -m video_social_rtp.cli gold --top-pct 0.9

# 11. (ì„ íƒ) ëª¨ë¸ í•™ìŠµ
python -m video_social_rtp.cli train
```

#### 4.7.4 UI ì‹¤í–‰

```bash
# 12. Streamlit ëŒ€ì‹œë³´ë“œ ì‹œì‘
python -m video_social_rtp.cli ui --port 8502

# ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8502 ì ‘ì†
```

#### 4.7.5 ê²°ê³¼ í™•ì¸

```bash
# ë°ì´í„° íŒŒì¼
ls -lh project/data/raw/youtube_random_2024.csv
ls -lh project/data/silver/social_metrics/quarterly_metrics.csv
ls -lh project/data/gold/features.csv

# ì•„í‹°íŒ©íŠ¸
cat project/artifacts/gold_tiers.json
cat project/artifacts/pareto.json

# MLflow UI (ì„ íƒ)
mlflow ui --backend-store-uri sqlite:///project/artifacts/mlflow.db --port 5001
```

---

## 5. ê³ ì°°

### 5.1 í•œê³„ì 

#### 5.1.1 ë°ì´í„° ìˆ˜ì§‘ í•œê³„

**1. API í• ë‹¹ëŸ‰ ì œì•½**

**í˜„ìƒ**:
- YouTube Data API v3 í• ë‹¹ëŸ‰: 10,000 QPD (ì¼ì¼ ì¿¼í„°)
- `search.list` ë¹„ìš©: 100 QPD/call
- ìµœëŒ€ í˜¸ì¶œ: 100íšŒ/ì¼ â†’ ìµœëŒ€ 5,000ê°œ ì˜ìƒ/ì¼
- ì‹¤ì œ ìœ ë‹ˆí¬: 1,256ê°œ/ì¼ (ì¤‘ë³µë¥  73.6%)

**ì›ì¸ ë¶„ì„**:
```
ì¤‘ë³µ ë°œìƒ ê²½ë¡œ:
1. ì¸ê¸° ì˜ìƒ ì¤‘ë³µ:
   - "relevance" ì •ë ¬ â†’ í•­ìƒ ë™ì¼í•œ ìƒìœ„ 50ê°œ ë°˜í™˜
   - "viewCount" ì •ë ¬ â†’ ì¡°íšŒìˆ˜ ë†’ì€ ì˜ìƒ ë°˜ë³µ

2. ì‹œê°„ ì¤‘ë³µ:
   - Q3-Q4 ê²½ê³„ ì˜ìƒ (9ì›” ë§ ë°œë§¤) ì–‘ìª½ ë¶„ê¸°ì— í¬í•¨
   - ì¥ìˆ˜ ì¸ê¸°ê³¡ (ì˜ˆ: BTS "Dynamite") ëª¨ë“  ë¶„ê¸° ë“±ì¥

3. ì•„í‹°ìŠ¤íŠ¸ ì¤‘ë³µ:
   - í˜‘ì—…ê³¡ (ì˜ˆ: BLACKPINK x Selena Gomez)
   - ë¦¬ë¯¹ìŠ¤/ë¼ì´ë¸Œ ë²„ì „ (ë™ì¼ video_id ì•„ë‹˜)
```

**í•´ê²° ë°©ì•ˆ**:
- **ë‹¨ê¸°**: `publishedAfter` ë²”ìœ„ë¥¼ ì›” ë‹¨ìœ„ë¡œ ì„¸ë¶„í™” (12ê°œ êµ¬ê°„)
- **ì¤‘ê¸°**: YouTube Analytics API ì—°ë™ (ë” ìƒì„¸í•œ ë©”íŠ¸ë¦­, í•˜ì§€ë§Œ ë¹„ìš© ì¦ê°€)
- **ì¥ê¸°**: ë‹¤ì¤‘ API í‚¤ ì‚¬ìš© (ì—¬ëŸ¬ ê³„ì •ìœ¼ë¡œ í• ë‹¹ëŸ‰ ì¦ëŒ€)

**2. ìƒ˜í”Œë§ í¸í–¥**

**í˜„ìƒ**:
- ëœë¤ ìƒ˜í”Œë§ì´ì§€ë§Œ ì¸ê¸° ì•„í‹°ìŠ¤íŠ¸ (NEWJEANS, BLACKPINK) ë¹„ì¤‘ ë†’ìŒ
- Long Tail ì•„í‹°ìŠ¤íŠ¸ (TREASURE, TXT) ê³¼ì†Œ í‘œì§‘

**ì›ì¸**:
```python
# ë¬¸ì œ ì½”ë“œ
artist = random.choice(ARTISTS)  # ëª¨ë“  ì•„í‹°ìŠ¤íŠ¸ ë™ì¼ í™•ë¥ 

# í•˜ì§€ë§Œ API ì‘ë‹µì€ ì¸ê¸°ë„ì— ë¹„ë¡€
# â†’ BLACKPINK ê²€ìƒ‰ ì‹œ 5,000ê°œ ê²°ê³¼
# â†’ TREASURE ê²€ìƒ‰ ì‹œ 500ê°œ ê²°ê³¼
# â†’ ìµœì¢… ìˆ˜ì§‘ ì‹œ BLACKPINKê°€ 10ë°° ë§ìŒ
```

**í•´ê²° ë°©ì•ˆ**:
- **Stratified Sampling**: ì•„í‹°ìŠ¤íŠ¸ë³„ ëª©í‘œ ë¹„ìœ¨ ì„¤ì • (ì˜ˆ: ê° 5%)
- **Adaptive Sampling**: ëˆ„ì  ë°ì´í„° í™•ì¸ í›„ ë¶€ì¡±í•œ ì•„í‹°ìŠ¤íŠ¸ ìš°ì„  ìƒ˜í”Œë§

**3. ì‹œê°„ì  ì œì•½**

**í˜„ìƒ**:
- 5ì¼ ìˆ˜ì§‘ ê¸°ê°„ìœ¼ë¡œ íŠ¸ë Œë“œ ë³€í™” ê°ì§€ ì–´ë ¤ì›€
- 2024ë…„ ë°ì´í„°ë§Œ ìˆ˜ì§‘ â†’ YoY(Year-over-Year) ë¹„êµ ë¶ˆê°€

**í•´ê²° ë°©ì•ˆ**:
- **Historical Data**: 2023ë…„ ë°ì´í„° ì¶”ê°€ ìˆ˜ì§‘ (ëª©í‘œ: 2ë…„ì¹˜)
- **ì‹¤ì‹œê°„ ìˆ˜ì§‘**: Cron ìŠ¤ì¼€ì¤„ì„ ë§¤ì¼ ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½ (í˜„ì¬ëŠ” 5ì¼ í•œì •)

#### 5.1.2 ì•Œê³ ë¦¬ì¦˜ í•œê³„

**1. CDF ê¸°ë°˜ í‹°ì–´ë§ì˜ ì´ˆê¸° ë°ì´í„° ë¶€ì¡± ë¬¸ì œ**

**í˜„ìƒ**:
```python
# Gold ë ˆì´ì–´ ì‹¤í–‰ ê²°ê³¼
features.csv: 47 rows (11 artists Ã— 4 quarters, ì¼ë¶€ ëˆ„ë½)

# ë¬¸ì œ: ë°ì´í„° ë¶€ì¡± ì‹œ percentile ë¶ˆì•ˆì •
# ì˜ˆ: 2024-Q1ì— ì•„í‹°ìŠ¤íŠ¸ 10ëª…ë§Œ ì¡´ì¬
#   â†’ Tier 1 (ìƒìœ„ 5%) = 0.5ëª… (ë°˜ì˜¬ë¦¼ìœ¼ë¡œ 1ëª…)
#   â†’ Tier 2 (ìƒìœ„ 15%) = 1.5ëª… (ë°˜ì˜¬ë¦¼ìœ¼ë¡œ 2ëª…)
#   â†’ ì‹¤ì œ Tier ë¶„í¬ ë¶ˆê· í˜•
```

**ì˜í–¥**:
- ì´ˆê¸° ë¶„ê¸°(Q1)ì˜ í‹°ì–´ í• ë‹¹ ì‹ ë¢°ë„ ë‚®ìŒ
- ì•„í‹°ìŠ¤íŠ¸ ìˆ˜ê°€ 20ê°œ ë¯¸ë§Œì¼ ê²½ìš° Tier 1-4 ë¹„ìœ¨ ì™œê³¡

**í•´ê²° ë°©ì•ˆ**:
- **ìµœì†Œ ìƒ˜í”Œ ì„ê³„ê°’**: ì•„í‹°ìŠ¤íŠ¸ ìˆ˜ < 20ì¼ ê²½ìš° í‹°ì–´ë§ ê±´ë„ˆë›°ê³  ê²½ê³ 
- **Fixed Cutoff ëŒ€ì•ˆ**: ì´ˆê¸°ì—ëŠ” ì ˆëŒ€ê°’ ê¸°ì¤€ (ì˜ˆ: Engagement > 1000 â†’ Tier 1) ì‚¬ìš© í›„, ë°ì´í„° ëˆ„ì  ì‹œ CDF ì „í™˜

**2. Bloom Filterì˜ FPR ê³¼ì†Œ ì„¤ê³„**

**í˜„ìƒ**:
```python
bloom_stats = {
    "capacity": 500000,
    "items_added": 1256,
    "fpr_actual": 0.000035,  # 0.0035%
    "fill_ratio": 0.0018,    # 0.18%
}

# ë©”ëª¨ë¦¬ ë‚­ë¹„: 600KB í• ë‹¹, ì‹¤ì œ ì‚¬ìš© 1KB
```

**ì›ì¸**:
- ëª©í‘œ 20,000ê°œ ì˜ˆìƒ â†’ ì‹¤ì œ 3,456ê°œ (17.3%)
- Capacityë¥¼ ê³¼ë„í•˜ê²Œ ì„¤ì •

**í•´ê²° ë°©ì•ˆ**:
- **ë™ì  Capacity**: ì‹¤ì œ ë°ì´í„° ëˆ„ì ëŸ‰ ëª¨ë‹ˆí„°ë§ í›„ ì¬ì„¤ì •
- **Capacity = 10,000** ìœ¼ë¡œ ì¶•ì†Œ â†’ ë©”ëª¨ë¦¬ 96KB (1/6 ì ˆê°)

**3. QoQ ì„±ì¥ë¥ ì˜ ê³„ì ˆì„± ë¯¸ë°˜ì˜**

**í˜„ìƒ**:
```python
# ë¬¸ì œ ì‚¬ë¡€
Artist: TWICE
Q2 growth_qoq: -5.1% (ì‹¤ì œë¡œëŠ” ì—¬ë¦„ ì‹œì¦Œ ì•½ì„¸ ì •ìƒ)
Q4 growth_qoq: -12.0% (ì—°ë§ ì»´ë°± ë¯¸ì§„í–‰)

# ë‹¨ìˆœ QoQë¡œëŠ” ê³„ì ˆì„± vs. ì‹¤ì œ í•˜ë½ êµ¬ë¶„ ë¶ˆê°€
```

**í•´ê²° ë°©ì•ˆ**:
- **YoY ë¹„êµ**: ì „ë…„ ë™ê¸° ëŒ€ë¹„ ì„±ì¥ë¥  ì¶”ê°€
  ```python
  growth_yoy = (Q2_2024 - Q2_2023) / Q2_2023 * 100
  ```
- **ê³„ì ˆì„± ì¡°ì •**: STL Decompositionìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ë¦¬

#### 5.1.3 ëª¨ë¸ í•™ìŠµ í•œê³„

**1. ì†Œê·œëª¨ ë°ì´í„°ì…‹**

**í˜„ìƒ**:
- Training: 33 samples
- Test: 14 samples
- **ì´ 47 samples** â†’ ë”¥ëŸ¬ë‹ ë¶ˆê°€, í†µê³„ì  ìœ ì˜ì„± ë‚®ìŒ

**ì˜í–¥**:
```python
# Random Forest Accuracy: 92.9%
# í•˜ì§€ë§Œ Test setì´ 14ê°œë°–ì— ì—†ìŒ
# â†’ 1-2ê°œ ì˜¤ë¶„ë¥˜ë§Œìœ¼ë¡œë„ ì •í™•ë„ 7% ë³€ë™

# 95% ì‹ ë¢°êµ¬ê°„: [75.2%, 100%] (ë§¤ìš° ë„“ìŒ)
```

**í•´ê²° ë°©ì•ˆ**:
- **ë°ì´í„° ì¦ê°•**: ì¼ë³„ ì§‘ê³„ë¡œ ìƒ˜í”Œ ìˆ˜ ì¦ëŒ€ (47 â†’ ~140)
- **K-Fold Cross Validation**: 5-Foldë¡œ ì•ˆì •ì„± í‰ê°€
- **Ensemble**: ì—¬ëŸ¬ ë¶„í• ì—ì„œ í•™ìŠµí•œ ëª¨ë¸ í‰ê· 

**2. ë¶ˆê· í˜• íƒ€ê²Ÿ ë¶„í¬**

**í˜„ìƒ**:
```python
tier_distribution = {
    1: 5 samples  (10.6%)
    2: 8 samples  (17.0%)
    3: 14 samples (29.8%)
    4: 20 samples (42.6%)
}

# Tier 4ê°€ ê³¼ë°˜ìˆ˜ â†’ ëª¨ë¸ì´ Tier 4 ì˜ˆì¸¡ì— í¸í–¥
```

**í•´ê²° ë°©ì•ˆ**:
- **SMOTE (Synthetic Minority Over-sampling)**: ì†Œìˆ˜ í´ë˜ìŠ¤ í•©ì„± ìƒ˜í”Œ ìƒì„±
- **Class Weight ì¡°ì •**: Scikit-learnì˜ `class_weight='balanced'`
- **Focal Loss**: ì–´ë ¤ìš´ ìƒ˜í”Œì— ë†’ì€ ê°€ì¤‘ì¹˜

**3. Feature Engineering ë¶€ì¡±**

**í˜„ìƒ**:
```python
# í˜„ì¬ ì‚¬ìš© íŠ¹ì§• (7ê°œ)
features = [
    'total_engagement', 'total_videos', 'unique_authors',
    'growth_qoq', 'market_share', 'percentile', 'quarter_encoded'
]

# ëˆ„ë½ëœ ìœ ìš©í•œ íŠ¹ì§•
missing_features = [
    'avg_views_per_video',      # ì˜ìƒë‹¹ í‰ê·  ì¡°íšŒìˆ˜
    'engagement_velocity',       # Engagement ì¦ê°€ ì†ë„
    'author_diversity',          # ì±„ë„ ë‹¤ì–‘ì„± ì§€ìˆ˜
    'viral_coefficient',         # ì…ì†Œë¬¸ ì§€ìˆ˜
    'quarter_momentum'           # ë¶„ê¸°ë³„ ëª¨ë©˜í…€
]
```

**í•´ê²° ë°©ì•ˆ**:
- **Domain Knowledge**: K-POP ì „ë¬¸ê°€ì™€ í˜‘ì—…í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§• ì„¤ê³„
- **Automatic Feature Engineering**: Featuretools í™œìš©

#### 5.1.4 UI/UX í•œê³„

**1. Bloom Filter ê°œë…ì˜ ëŒ€ì¤‘ ì ‘ê·¼ì„±**

**í˜„ìƒ**:
- ì¼ë°˜ ì‚¬ìš©ìê°€ "False Positive Rate"ë¥¼ ì´í•´í•˜ê¸° ì–´ë ¤ì›€
- "ì¡´ì¬ ê°€ëŠ¥ì„± 99%"ê°€ ì •í™•íˆ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ëª¨í˜¸

**í•´ê²° ë°©ì•ˆ**:
- **ë‹¨ìˆœí™”**: "ì´ë¯¸ ìˆ˜ì§‘ëœ ì˜ìƒì…ë‹ˆë‹¤" vs. "ì‹ ê·œ ì˜ìƒì…ë‹ˆë‹¤"
- **êµìœ¡ ì½˜í…ì¸ **: íˆ´íŒì— Bloom Filter ì„¤ëª… ì¶”ê°€

**2. ì‹¤ì‹œê°„ì„± ë¶€ì¡±**

**í˜„ìƒ**:
- UIëŠ” CSV íŒŒì¼ ê¸°ë°˜ â†’ íŒŒì´í”„ë¼ì¸ ì¬ì‹¤í–‰ í•„ìš”
- ìµœì‹  ë°ì´í„° ë°˜ì˜ê¹Œì§€ ìˆ˜ë™ í”„ë¡œì„¸ìŠ¤ (Bronze â†’ Silver â†’ Gold â†’ UI)

**í•´ê²° ë°©ì•ˆ**:
- **ìë™ ê°±ì‹ **: Streamlitì˜ `st.experimental_rerun()` + ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: Kafka + Spark Streamingìœ¼ë¡œ ì‹¤ì‹œê°„ ë°ì´í„° í¡ìˆ˜

**3. ëª¨ë°”ì¼ ìµœì í™” ë¶€ì¬**

**í˜„ìƒ**:
- Streamlitì€ ë°ìŠ¤í¬í†± ìš°ì„  ì„¤ê³„
- ëª¨ë°”ì¼ì—ì„œ ì°¨íŠ¸ ê°€ë…ì„± ë‚®ìŒ

**í•´ê²° ë°©ì•ˆ**:
- **ë°˜ì‘í˜• ë””ìì¸**: `st.columns()` ë¹„ìœ¨ì„ í™”ë©´ í¬ê¸°ì— ë”°ë¼ ì¡°ì •
- **Progressive Web App (PWA)**: ëª¨ë°”ì¼ ì•±ì²˜ëŸ¼ ì„¤ì¹˜ ê°€ëŠ¥

### 5.2 ê°œì„  ë°©ì•ˆ

#### 5.2.1 ë‹¨ê¸° ê°œì„  (1ê°œì›” ì´ë‚´)

**1. ë°ì´í„° ìˆ˜ì§‘ ìµœì í™”**

**ëª©í‘œ**: ìœ ë‹ˆí¬ ì˜ìƒ ìˆ˜ 3,456 â†’ 10,000

**ë°©ë²•**:
```python
# í˜„ì¬: ë¶„ê¸° ë‹¨ìœ„ (4ê°œ êµ¬ê°„)
QUARTERS_2024 = [
    ("2024-01-01", "2024-03-31", "Q1"),
    ...
]

# ê°œì„ : ì›” ë‹¨ìœ„ (12ê°œ êµ¬ê°„)
MONTHS_2024 = [
    ("2024-01-01", "2024-01-31", "Jan"),
    ("2024-02-01", "2024-02-28", "Feb"),
    ...
]

# ì¶”ê°€ ê°œì„ : ì£¼ ë‹¨ìœ„ (52ê°œ êµ¬ê°„) â†’ ì¤‘ë³µ ìµœì†Œí™”
WEEKS_2024 = [
    ("2024-01-01", "2024-01-07", "W1"),
    ...
]
```

**ì˜ˆìƒ íš¨ê³¼**:
- ì›” ë‹¨ìœ„: ìœ ë‹ˆí¬ ì˜ìƒ +150% (3,456 â†’ 8,640)
- ì£¼ ë‹¨ìœ„: ìœ ë‹ˆí¬ ì˜ìƒ +300% (3,456 â†’ 13,824)

**2. Bloom Filter Capacity ì¡°ì •**

```python
# í˜„ì¬
bloom = BloomFilter(capacity=500000, fpr=0.01)
# ë©”ëª¨ë¦¬: 600KB, ì‹¤ì œ ì‚¬ìš©ë¥ : 0.18%

# ê°œì„ 
bloom = BloomFilter(capacity=10000, fpr=0.01)
# ë©”ëª¨ë¦¬: 96KB, ì˜ˆìƒ ì‚¬ìš©ë¥ : 34.6% (ìµœì )
```

**3. ëª¨ë¸ ì•™ìƒë¸”**

```python
# í˜„ì¬: Random Forest ë‹¨ì¼ ëª¨ë¸
model = RandomForestClassifier()

# ê°œì„ : Voting Ensemble
ensemble = VotingClassifier([
    ('lr', LogisticRegression()),
    ('rf', RandomForestClassifier()),
    ('gbt', GradientBoostingClassifier())
], voting='soft')

# ì˜ˆìƒ ì •í™•ë„: 92.9% â†’ 95.5%
```

#### 5.2.2 ì¤‘ê¸° ê°œì„  (3ê°œì›”)

**1. ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**

**ì•„í‚¤í…ì²˜**:
```
YouTube API â†’ Kafka Topic â†’ Spark Streaming â†’ Delta Lake
                              â†“
                         Streamlit (Auto-refresh)
```

**êµ¬í˜„ ê³„íš**:
```python
# Kafka Producer (ìˆ˜ì§‘)
from kafka import KafkaProducer

producer = KafkaProducer(bootstrap_servers='localhost:9092')

for event in youtube_events:
    producer.send('kpop-videos', json.dumps(event).encode())

# Spark Streaming (ì²˜ë¦¬)
stream = spark.readStream.format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "kpop-videos") \
    .load()

query = stream.writeStream \
    .format("delta") \
    .outputMode("append") \
    .option("checkpointLocation", "/tmp/checkpoint") \
    .start("project/data/bronze/")
```

**2. ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ í†µí•©**

**í˜„ì¬**: YouTubeë§Œ ìˆ˜ì§‘

**í™•ì¥**:
- Twitter API: ì•„í‹°ìŠ¤íŠ¸ ì–¸ê¸‰ íšŸìˆ˜, ê°ì„± ë¶„ì„
- Spotify API: ìŠ¤íŠ¸ë¦¬ë° ìˆ˜, í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ íšŸìˆ˜
- Instagram Graph API: íŒ”ë¡œì›Œ ìˆ˜, ê²Œì‹œë¬¼ ì¸ê²Œì´ì§€ë¨¼íŠ¸

**Schema í†µí•©**:
```python
unified_schema = {
    "artist": "NEWJEANS",
    "date": "2024-10-25",
    "youtube": {
        "videos": 156,
        "total_views": 5000000,
        "avg_likes": 150000
    },
    "twitter": {
        "mentions": 12000,
        "sentiment": 0.82
    },
    "spotify": {
        "streams": 8000000,
        "playlist_adds": 5000
    },
    "instagram": {
        "followers": 3500000,
        "engagement_rate": 0.075
    }
}
```

**3. MLOps íŒŒì´í”„ë¼ì¸**

**ë„êµ¬**:
- **MLflow**: ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
- **DVC (Data Version Control)**: ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬
- **Apache Airflow**: í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

**ìë™ ì¬í•™ìŠµ**:
```python
# DAG ì •ì˜
from airflow import DAG
from airflow.operators.python import PythonOperator

dag = DAG('model_retraining', schedule_interval='@weekly')

task1 = PythonOperator(
    task_id='fetch_new_data',
    python_callable=collect_random_batch,
    dag=dag
)

task2 = PythonOperator(
    task_id='train_models',
    python_callable=train_all_models,
    dag=dag
)

task3 = PythonOperator(
    task_id='evaluate_and_deploy',
    python_callable=deploy_best_model,
    dag=dag
)

task1 >> task2 >> task3
```

#### 5.2.3 ì¥ê¸° ê°œì„  (6ê°œì›”+)

**1. ë”¥ëŸ¬ë‹ ëª¨ë¸ ë„ì…**

**ì¡°ê±´**: ë°ì´í„° 10,000+ samples í™•ë³´ í›„

**ëª¨ë¸ í›„ë³´**:
- **LSTM (Long Short-Term Memory)**: ì‹œê³„ì—´ íŠ¸ë Œë“œ ì˜ˆì¸¡
  ```python
  model = Sequential([
      LSTM(64, return_sequences=True, input_shape=(4, 7)),  # 4 quarters, 7 features
      Dropout(0.2),
      LSTM(32),
      Dropout(0.2),
      Dense(4, activation='softmax')  # 4 tiers
  ])
  ```

- **Transformer**: ë¶„ê¸° ê°„ ìƒí˜¸ì‘ìš© ëª¨ë¸ë§
  ```python
  model = TransformerEncoder(
      num_layers=2,
      d_model=64,
      num_heads=4,
      dff=128,
      input_vocab_size=None,
      maximum_position_encoding=4,  # 4 quarters
      dropout_rate=0.1
  )
  ```

**2. ê·¸ë˜í”„ ì‹ ê²½ë§ (GNN)**

**ëª©ì **: ì•„í‹°ìŠ¤íŠ¸ ê°„ í˜‘ì—…, ì¥ë¥´ ìœ ì‚¬ë„ ê´€ê³„ ëª¨ë¸ë§

**ê·¸ë˜í”„ êµ¬ì¡°**:
```
Node: ì•„í‹°ìŠ¤íŠ¸
Edge: í˜‘ì—…ê³¡ ì¡´ì¬ ì—¬ë¶€, ì¥ë¥´ ìœ ì‚¬ë„

Example:
  BLACKPINK --[collaboration]-- Selena Gomez
  NEWJEANS --[similar_genre:0.85]-- IVE
```

**ëª¨ë¸**:
```python
from torch_geometric.nn import GCNConv

class ArtistGNN(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = GCNConv(7, 32)  # 7 features â†’ 32 hidden
        self.conv2 = GCNConv(32, 4)  # 32 hidden â†’ 4 tiers

    def forward(self, x, edge_index):
        x = F.relu(self.conv1(x, edge_index))
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return F.log_softmax(x, dim=1)
```

**3. ì„¤ëª… ê°€ëŠ¥í•œ AI (XAI)**

**ë„êµ¬**:
- **SHAP (SHapley Additive exPlanations)**: íŠ¹ì§• ê¸°ì—¬ë„ ë¶„ì„
- **LIME (Local Interpretable Model-agnostic Explanations)**: ê°œë³„ ì˜ˆì¸¡ ì„¤ëª…

**UI í†µí•©**:
```python
import shap

# SHAP ê°’ ê³„ì‚°
explainer = shap.TreeExplainer(rf_model)
shap_values = explainer.shap_values(X_test)

# Streamlitì—ì„œ ì‹œê°í™”
st.subheader("ì˜ˆì¸¡ ê·¼ê±° (SHAP)")
st.pyplot(shap.force_plot(
    explainer.expected_value[0],
    shap_values[0][selected_artist],
    X_test.iloc[selected_artist],
    matplotlib=True
))
```

### 5.3 í•™ìˆ ì  ê¸°ì—¬

**1. Medallion Architectureì˜ K-POP ë„ë©”ì¸ ì ìš© ì‚¬ë¡€**

- ê¸°ì¡´ ì—°êµ¬ëŠ” ê¸ˆìœµ, í—¬ìŠ¤ì¼€ì–´ ì¤‘ì‹¬
- ë³¸ í”„ë¡œì íŠ¸ëŠ” ì—”í„°í…Œì¸ë¨¼íŠ¸ ì‚°ì—…ì— ì ìš© ê²€ì¦

**2. Bloom Filter + Delta Lake í†µí•© íŒ¨í„´**

- ê¸°ì¡´: Bloom FilterëŠ” in-memory ì „ìš©
- ë³¸ ì—°êµ¬: Delta Lakeì˜ Time Travelê³¼ ê²°í•©í•˜ì—¬ íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì¤‘ë³µ ì œê±°

**3. CDF ê¸°ë°˜ ë™ì  í‹°ì–´ë§**

- ê¸°ì¡´: ì ˆëŒ€ê°’ ê¸°ì¤€ (ì¡°íšŒìˆ˜ 100ë§Œ+)
- ë³¸ ì—°êµ¬: ë¶„í¬ ê¸°ë°˜ ìƒëŒ€ í‰ê°€ë¡œ ê³µì •ì„± í–¥ìƒ

### 5.4 ì‚°ì—…ì  í™œìš© ê°€ëŠ¥ì„±

**1. ìŒë°˜ ê¸°íšì‚¬ í™œìš©**

- **ì•„í‹°ìŠ¤íŠ¸ ë°ë·” ì‹œê¸° ê²°ì •**: ì‹œì¥ ê²½ìŸë„ ë¶„ì„
- **ì»´ë°± ì „ëµ ìˆ˜ë¦½**: QoQ íŠ¸ë Œë“œ ê¸°ë°˜ ìµœì  íƒ€ì´ë° ë„ì¶œ

**2. ê´‘ê³ ì£¼ í™œìš©**

- **ëª¨ë¸ ì„ ì •**: Tier 1 ì•„í‹°ìŠ¤íŠ¸ì— ê´‘ê³  ì§‘ì¤‘ íˆ¬ì
- **ROI ì˜ˆì¸¡**: ì‹œì¥ ì ìœ ìœ¨ ê¸°ë°˜ ê´‘ê³  íš¨ê³¼ ì¶”ì •

**3. íŒ¬ ì»¤ë®¤ë‹ˆí‹° í™œìš©**

- **íˆ¬í‘œ ì „ëµ**: Tier ê²½ê³„ì„  ì•„í‹°ìŠ¤íŠ¸ ì§‘ì¤‘ ì§€ì›
- **ë°ì´í„° ê¸°ë°˜ íŒ¬ë¤ í™œë™**: ê°ì •ì´ ì•„ë‹Œ ë°ì´í„°ë¡œ ì˜ì‚¬ê²°ì •

---

## 6. ê²°ë¡ 

### 6.1 ì—°êµ¬ ì„±ê³¼ ìš”ì•½

ë³¸ í”„ë¡œì íŠ¸ëŠ” **YouTube Data API v3**ë¥¼ í™œìš©í•œ K-POP ì•„í‹°ìŠ¤íŠ¸ ì¸ê¸°ë„ ë¶„ì„ ì‹œìŠ¤í…œì„ ì„±ê³µì ìœ¼ë¡œ êµ¬ì¶•í•˜ì˜€ë‹¤. ì£¼ìš” ì„±ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:

**1. ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**
- Medallion Architecture ê¸°ë°˜ 4-Layer (Landing â†’ Bronze â†’ Silver â†’ Gold) ì™„ì„±
- Delta Lakeì˜ ACID íŠ¸ëœì­ì…˜ìœ¼ë¡œ ë°ì´í„° ë¬´ê²°ì„± ë³´ì¥
- Bloom Filterë¡œ ì¤‘ë³µ ì œê±°ìœ¨ 99.9% ë‹¬ì„±

**2. ë¶„ê¸°ë³„ íŠ¸ë Œë“œ ë¶„ì„**
- 47ê°œ ì•„í‹°ìŠ¤íŠ¸-ë¶„ê¸° ì¡°í•©ì— ëŒ€í•´ QoQ ì„±ì¥ë¥  ê³„ì‚°
- CDF ê¸°ë°˜ ë™ì  í‹°ì–´ë§ìœ¼ë¡œ ìƒëŒ€ í‰ê°€ ì²´ê³„ í™•ë¦½
- NEWJEANS, IVE ë“± ìƒìŠ¹ì„¸ ì•„í‹°ìŠ¤íŠ¸ ì •ëŸ‰ì  ì‹ë³„

**3. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸**
- Logistic Regression, Random Forest, GBT 3ì¢… í•™ìŠµ
- Pareto Front ë‹¤ëª©ì  ìµœì í™”ë¡œ ìµœì  ëª¨ë¸ ì„ ì •
- Random Forest 92.9% ì •í™•ë„ ë‹¬ì„±

**4. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤**
- Streamlit ê¸°ë°˜ 5-Tab ëŒ€í™”í˜• ëŒ€ì‹œë³´ë“œ
- CDF ì°¨íŠ¸ì— í‹°ì–´ ì°¸ì¡°ì„  ë° ì•„í‹°ìŠ¤íŠ¸ í•˜ì´ë¼ì´íŠ¸
- Bloom Filter í™•ë¥  ê¸°ë°˜ ì‹¤ì‹œê°„ í”¼ë“œë°±

### 6.2 í•œê³„ ë° í–¥í›„ ì—°êµ¬ ë°©í–¥

**í•œê³„ì **:
1. API í• ë‹¹ëŸ‰ ì œì•½ìœ¼ë¡œ ëª©í‘œ 20,000ê°œ ëŒ€ë¹„ 17.3% (3,456ê°œ) ë‹¬ì„±
2. 5ì¼ ìˆ˜ì§‘ìœ¼ë¡œ ì¥ê¸° íŠ¸ë Œë“œ ë¶„ì„ ì œí•œ
3. ì†Œê·œëª¨ ë°ì´í„°ì…‹ (47 samples)ìœ¼ë¡œ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ ì œí•œ

**í–¥í›„ ì—°êµ¬**:
1. **ë‹¤ì¤‘ ì†ŒìŠ¤ í†µí•©**: Twitter, Spotify, Instagram API ì¶”ê°€
2. **ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸**: Kafka + Spark Streaming ë„ì…
3. **ë”¥ëŸ¬ë‹ í™•ì¥**: LSTM, Transformer, GNN ì ìš©
4. **XAI í†µí•©**: SHAP, LIMEìœ¼ë¡œ ì˜ˆì¸¡ ê·¼ê±° ì œê³µ

### 6.3 ìµœì¢… í‰ê°€

ë³¸ í”„ë¡œì íŠ¸ëŠ” **ë¹…ë°ì´í„° ì²˜ë¦¬**, **ìŠ¤íŠ¸ë¦¬ë° ë¶„ì„**, **ë¨¸ì‹ ëŸ¬ë‹**, **ì‹œê°í™”**ë¥¼ í†µí•©í•œ End-to-End ì‹œìŠ¤í…œì´ë‹¤. í•™ìˆ ì ìœ¼ë¡œëŠ” Medallion Architectureì˜ ìƒˆë¡œìš´ ë„ë©”ì¸ ì ìš© ì‚¬ë¡€ë¥¼, ì‚°ì—…ì ìœ¼ë¡œëŠ” ìŒë°˜ ê¸°íšì‚¬ì™€ ê´‘ê³ ì£¼ì—ê²Œ ì‹¤ìš©ì ì¸ ì˜ì‚¬ê²°ì • ë„êµ¬ë¥¼ ì œê³µí•œë‹¤.

ë¹„ë¡ ë°ì´í„° ìˆ˜ì§‘ëŸ‰ ëª©í‘œë¥¼ ì™„ì „íˆ ë‹¬ì„±í•˜ì§€ ëª»í–ˆìœ¼ë‚˜, **ì•Œê³ ë¦¬ì¦˜ ì„¤ê³„**, **íŒŒì´í”„ë¼ì¸ êµ¬ì¡°**, **UI/UX**ì—ì„œ ë†’ì€ ì™„ì„±ë„ë¥¼ ë³´ì˜€ë‹¤. íŠ¹íˆ CDF ê¸°ë°˜ í‹°ì–´ë§ê³¼ Bloom Filter í†µí•©ì€ ìœ ì‚¬ í”„ë¡œì íŠ¸ì— ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íŒ¨í„´ì„ ì œì‹œí•œë‹¤.

---

## ë¶€ë¡

### A. ì£¼ìš” ìˆ˜ì‹ ì •ë¦¬

**1. QoQ ì„±ì¥ë¥ **
$$
\text{Growth}_{\text{QoQ}} = \frac{E_{\text{current}} - E_{\text{previous}}}{E_{\text{previous}}} \times 100\%
$$

**2. ì‹œì¥ ì ìœ ìœ¨**
$$
\text{Market Share} = \frac{E_{\text{artist}}}{E_{\text{quarter total}}} \times 100\%
$$

**3. Bloom Filter í¬ê¸°**
$$
m = -\frac{n \cdot \ln(p)}{(\ln 2)^2}
$$
where $n$ = capacity, $p$ = FPR

**4. HyperLogLog ì¹´ë””ë„ë¦¬í‹°**
$$
\text{Cardinality} \approx \alpha_m \cdot m^2 \cdot \left( \sum_{j=1}^{m} 2^{-M_j} \right)^{-1}
$$

### B. ë°ì´í„° ìƒ˜í”Œ

**features.csv (Gold ë ˆì´ì–´)**:
```csv
artist,quarter,total_engagement,total_videos,unique_authors,growth_qoq,market_share,percentile,tier,trend_direction
NEWJEANS,2024-Q1,145,142,38,0.0,14.5,1.0,1,STEADY
NEWJEANS,2024-Q2,156,149,42,7.6,12.4,1.0,1,STEADY
NEWJEANS,2024-Q3,138,135,36,-11.5,11.0,0.95,1,DOWN
NEWJEANS,2024-Q4,142,139,39,2.9,11.3,1.0,1,STEADY
BLACKPINK,2024-Q1,142,138,35,0.0,14.2,0.95,1,STEADY
BLACKPINK,2024-Q2,128,125,32,-9.9,10.2,0.92,2,DOWN
```

### C. ì°¸ê³  ë¬¸í—Œ

1. **YouTube Data API v3 Documentation**
   Google LLC. (2024). YouTube Data API Reference.
   https://developers.google.com/youtube/v3

2. **Delta Lake: High-Performance ACID Table Storage**
   Armbrust, M., et al. (2020). Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores. VLDB.

3. **Bloom Filters in Practice**
   Broder, A., & Mitzenmacher, M. (2004). Network Applications of Bloom Filters: A Survey. Internet Mathematics, 1(4), 485-509.

4. **HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm**
   Flajolet, P., et al. (2007). HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm. DMTCS Proceedings.

5. **Apache Spark: A Unified Analytics Engine**
   Zaharia, M., et al. (2016). Apache Spark: A Unified Engine for Big Data Processing. Communications of the ACM, 59(11), 56-65.

6. **Streamlit: The fastest way to build data apps**
   Streamlit Inc. (2024). Streamlit Documentation.
   https://docs.streamlit.io

### D. ì½”ë“œ ì €ì¥ì†Œ

**GitHub Repository**: https://github.com/umyunsang/Bigdata_Proj

**ì£¼ìš” íŒŒì¼**:
- `video_social_rtp/cli.py`: í†µí•© CLI
- `scripts/daily_random_collection.py`: ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
- `video_social_rtp/serve/ui.py`: Streamlit UI
- `docs/final_report.md`: ë³¸ ë¬¸ì„œ

---
