# K-POP 아티스트 인기도 분석 시스템 실행 결과

**실행 일시**: 2025-10-14  
**환경**: Spark 3.5.0, Python 3.12.3, Delta Lake 3.2.0  
**데이터 소스**: YouTube Data API v3 (실제 데이터)

---

## 1. 데이터 수집 (Landing Layer)

### 수집 아티스트 (9개)
```
1. NewJeans (뉴진스)
2. aespa (에스파)
3. IVE (아이브)
4. BLACKPINK (블랙핑크)
5. BTS (방탄소년단)
6. TWICE (트와이스)
7. ITZY (있지)
8. LE SSERAFIM (르세라핌)
9. NMIXX (엔믹스)
```

### 수집 결과
- **총 파일 수**: 9개
- **각 검색당 아이템**: 30개
- **총 원본 이벤트**: 약 270개
- **저장 형식**: NDJSON (Newline Delimited JSON)
- **저장 경로**: `project/data/landing/events_*.json`

### 샘플 데이터
```json
{
  "post_id": "search1_G8GEpK7YDl4",
  "text": "NewJeans 'New Jeans (ft. The Powerpuff Girls)' Lyrics",
  "lang": "en",
  "ts": 1760429759395,
  "author_id": "UCmth4hMyizG-_W9jidBqs_A",
  "video_id": "G8GEpK7YDl4",
  "source": "yt"
}
```

---

## 2. 데이터 정제 (Bronze Layer)

### Spark 실행
- **사용 기술**: PySpark + Delta Lake
- **처리 방식**: Batch Processing
- **중복 제거**: Bloom Filter 적용

### 처리 결과
- **입력 이벤트**: 270개
- **출력 행(Row)**: 262개
- **중복 제거**: 8개 (3%)
- **저장 형식**: Delta Lake (Parquet)
- **파티션 전략**: `ingest_date` + `artist` (2단계)

### 아티스트 추출 결과
Bronze 레이어에서 10개의 아티스트 파티션 생성:

```
📂 ingest_date=2025-10-14/
  ├── artist=AESPA/           (에스파)
  ├── artist=BLACKPINK/       (블랙핑크)
  ├── artist=BTS/             (방탄소년단)
  ├── artist=ITZY/            (있지)
  ├── artist=IVE/             (아이브)
  ├── artist=LESSERAFIM/      (르세라핌)
  ├── artist=NEWJEANS/        (뉴진스)
  ├── artist=NMIXX/           (엔믹스)
  ├── artist=OTHER/           (기타)
  └── artist=TWICE/           (트와이스)
```

### 아티스트 추출 로직
- **제목 기반 패턴 매칭**: `video_social_rtp/core/artists.py`
- **채널 ID 매핑**: 공식 채널 자동 인식
- **정규화**: 영문, 한글, 일본어 등 다양한 표기 통합

---

## 3. 실시간 집계 (Silver Layer)

### Structured Streaming 설정
- **실행 모드**: `--once` (Batch 모드)
- **윈도우 크기**: 1시간 (Sliding Window)
- **Watermark**: 10분 (지연 이벤트 허용)
- **집계 기준**: `artist` × `window`

### 처리 결과
- **입력 행**: 262개 (Bronze)
- **출력 그룹**: 120개 (아티스트별 시간창)
- **저장 형식**: Delta Lake (Parquet, Snappy 압축)
- **파일 수**: 9개 Parquet 파일

### 집계 메트릭
각 아티스트×시간창별로 계산:
- `video_count`: 비디오 수
- `unique_videos`: 고유 비디오 수 (중복 제거)
- `total_engagement`: 총 참여도 (조회수, 댓글, 좋아요 등)
- `unique_authors`: 고유 작성자 수 (HyperLogLog 추정)

---

## 4. 피처 엔지니어링 (Gold Layer)

### 생성 피처 (13개)

#### 기본 집계 피처
1. **total_engagement**: 총 참여도 (24시간 기준)
2. **avg_engagement**: 평균 참여도
3. **max_engagement**: 최대 참여도
4. **total_videos**: 총 비디오 수
5. **unique_viewers_est**: HyperLogLog 고유 시청자 추정

#### 트렌드 피처
6. **growth_rate_7d**: 7일 대비 성장률 (%) - 현재 0% (첫 수집)
7. **growth_rate_30d**: 30일 대비 성장률 (%) - 현재 0%
8. **momentum**: 가속도 (2차 미분) - 현재 0
9. **volatility**: 변동성 (표준편차)

#### 상대적 지표
10. **market_share**: 전체 대비 시장 점유율 (%)
11. **percentile**: 상위 몇 % (CDF 기반)
12. **tier**: Tier 분류 (1~4)
13. **trend_direction**: 트렌드 방향 (STEADY/상승/하락)

### CDF 기반 Tier Cutoff 계산

```json
{
  "tier_cutoffs": {
    "tier_1": 768.0,   // 상위 5% (초대형)
    "tier_2": 360.0,   // 상위 15% (대형)
    "tier_3": 336.0    // 상위 40% (중형)
  }
}
```

### 아티스트별 Tier 분류 결과

| 순위 | 아티스트 | Tier | 참여도 | 시장점유율 | 상위% | 트렌드 |
|------|----------|------|--------|-----------|-------|--------|
| 1 | **BLACKPINK** | **Tier 1 (초대형)** | 768 | 24.4% | 100% | STEADY |
| 2 | **AESPA** | **Tier 2 (대형)** | 360 | 11.5% | 88.9% | STEADY |
| 3 | IVE | Tier 3 (중형) | 348 | 11.1% | 66.7% | STEADY |
| 4 | NMIXX | Tier 3 (중형) | 348 | 11.1% | 66.7% | STEADY |
| 5 | ITZY | Tier 4 (소형) | 336 | 10.7% | 44.4% | STEADY |
| 6 | TWICE | Tier 4 (소형) | 336 | 10.7% | 44.4% | STEADY |
| 7 | BTS | Tier 4 (소형) | 240 | 7.6% | 33.3% | STEADY |
| 8 | NEWJEANS | Tier 4 (소형) | 168 | 5.3% | 22.2% | STEADY |
| 9 | LESSERAFIM | Tier 4 (소형) | 156 | 5.0% | 11.1% | STEADY |
| 10 | OTHER | Tier 4 (소형) | 84 | 2.7% | 0% | STEADY |

### 주요 인사이트

1. **BLACKPINK 압도적 1위**
   - 참여도 768로 2위 AESPA(360) 대비 **2.1배 높음**
   - 전체 시장의 **24.4%** 독점
   - 명실상부한 **Tier 1 (초대형)** 그룹

2. **AESPA 단독 Tier 2**
   - 3위 IVE(348)와 근소한 차이 (3.4%)
   - 신흥 강자로 부상

3. **중위권 경쟁 치열**
   - IVE, NMIXX, ITZY, TWICE가 336~348 범위에 밀집
   - 향후 30일 트렌드 추적 시 순위 변동 예상

4. **BTS 의외의 7위**
   - 글로벌 인지도 대비 낮은 순위
   - 최근 활동 공백 또는 검색어 특성 영향 추정

5. **신인 그룹 성장 가능성**
   - NEWJEANS, LESSERAFIM도 유의미한 참여도 기록
   - 향후 growth_rate 추적 필요

---

## 5. 모델 학습 (Train Layer)

### 학습 설정
- **입력 피처**: 8개
  - `total_engagement`, `avg_engagement`, `max_engagement`
  - `total_videos`, `unique_viewers_est`
  - `growth_rate_7d`, `growth_rate_30d`, `momentum`
- **타겟 레이블**: `tier` (1, 2, 3, 4) - **다중 클래스 분류**
- **학습/테스트 분할**: 80% / 20%

### 모델 비교

| 모델 | Accuracy | F1 Score | 추론 속도 (ms) | 학습 시간 (ms) |
|------|----------|----------|----------------|----------------|
| **Logistic Regression** | **1.0** | **1.0** | **18.93** ⭐ | 1849 |
| Random Forest | 1.0 | 1.0 | 22.00 | 1009 |

### Pareto Front 선택
- **최적 모델**: **Logistic Regression** 
- **선택 이유**: 
  - 동일한 F1 Score (1.0)
  - **더 빠른 추론 속도** (18.93ms < 22.00ms)
  - 단순성 (해석 가능성)

### 모델 성능 분석

#### ✅ 완벽한 분류 성능
- **Accuracy**: 1.0 (100%)
- **F1 Score**: 1.0 (100%)
- **오분류**: 0건

#### 🤔 주의사항
현재 데이터셋이 작아(10개 아티스트) 과적합(Overfitting) 가능성 있음.  
**향후 30일 데이터 축적 시 재검증 필요**:
- 100+ 아티스트 데이터로 재학습
- Cross-Validation 적용
- 실제 F1 Score 0.65-0.80 예상

---

## 6. 기술 스택 검증

### ✅ 성공적으로 활용된 빅데이터 기술

#### Delta Lake (ACID 트랜잭션)
- Bronze/Silver/Gold 레이어 모두 Delta Lake로 저장
- Schema Evolution 지원
- Time Travel 가능 (`_delta_log` 디렉터리)

#### PySpark (분산 처리)
- 262개 행을 9개 파티션으로 병렬 처리
- Stage별 작업 분산 (Stage 0~9 확인)
- Adaptive Query Execution 활용

#### Structured Streaming
- Sliding Window (1시간)
- Watermark (10분 지연 허용)
- 아티스트별 실시간 집계

#### HyperLogLog (근사 계산)
- 고유 시청자 수 추정
- 메모리 효율적 Cardinality Estimation

#### Pareto Front (다목적 최적화)
- Accuracy, Latency, Complexity 동시 고려
- 최적 모델 자동 선택

#### Parquet + Snappy 압축
- 컬럼 기반 저장 형식
- 효율적인 압축 및 쿼리 성능

---

## 7. 데이터 흐름 검증

### 전체 파이프라인 요약

```
YouTube API (9 queries × 30 items)
         ↓
Landing: 270 events (NDJSON)
         ↓
Bronze: 262 rows (Delta, 10 artists)
         ↓
Silver: 120 groups (Streaming, artist×window)
         ↓
Gold: 10 rows (Features + Tier)
         ↓
Train: 2 models → Pareto → 1 best
         ↓
Predict: Ready for new artist inference
```

### 각 단계 검증 체크리스트

- [x] **Landing**: 9개 파일, NDJSON 형식 ✅
- [x] **Bronze**: 10개 아티스트 파티션, Delta Lake ✅
- [x] **Silver**: 120개 집계 그룹, Parquet ✅
- [x] **Gold**: 10개 아티스트 피처, Tier 1~4 모두 존재 ✅
- [x] **Train**: 2개 모델 학습, Pareto Front 선택 ✅
- [x] **Artifacts**: `gold_tiers.json`, `pareto.json` 생성 ✅

---

## 8. 향후 개선 계획

### 8.1 데이터 축적 (30일)

#### 목표
- **일일 수집**: 2,000개 비디오 (50 queries × 40 items)
- **30일 후**: 60,000개 비디오
- **고유 아티스트**: 100-150명 예상

#### 자동화
```bash
# Cron 설정 (하루 2회 실행)
0 9,15 * * * /home/student_15030/Bigdata_Proj/scripts/daily_pipeline.sh
```

### 8.2 트렌드 피처 활성화

현재 `growth_rate_7d`, `growth_rate_30d`, `momentum`이 모두 0인 이유:
- 첫 수집이라 과거 데이터 없음

**7일 후**:
- `growth_rate_7d` 계산 가능
- 급상승/하락 그룹 식별

**30일 후**:
- `growth_rate_30d` 계산 가능
- 장기 트렌드 분석

### 8.3 모델 재학습

**현재 한계**:
- 10개 아티스트 → 과적합 위험
- Tier 4가 6개 (60%) → 클래스 불균형

**30일 후 개선**:
- 100+ 아티스트 → 일반화 성능 향상
- Tier별 균형 (1: 5%, 2: 10%, 3: 25%, 4: 60%)
- Cross-Validation 적용
- 실제 F1 Score 0.65-0.80 예상

### 8.4 예측 시스템

**신규 아티스트 입력 예시**:
```python
new_artist = {
    "artist": "RIIZE",
    "total_engagement": 1250.0,
    "avg_engagement": 62.5,
    "growth_rate_7d": 45.2,  # 30일 후 계산 가능
    "growth_rate_30d": 120.5,
    "momentum": 15.3
}

# 예측 결과
prediction = {
    "predicted_tier": 2,  # 대형
    "probability": {
        "tier_1": 0.15,
        "tier_2": 0.65,  # 가장 높은 확률
        "tier_3": 0.18,
        "tier_4": 0.02
    },
    "trend": "급상승",
    "recommendation": "주목할 만한 신인 그룹"
}
```

### 8.5 Streamlit UI 개선

**현재 UI 구조**:
- 기본 설정 완료 (`~/.streamlit/config.toml`)
- 포트 8501 바인딩

**향후 추가 기능**:
1. **실시간 대시보드**
   - 아티스트별 인기도 순위 테이블
   - CDF/PDF 분포 차트
   - 시계열 트렌드 그래프

2. **예측 인터페이스**
   - 신규 아티스트 데이터 입력
   - Tier 예측 결과 표시
   - 확률 분포 시각화

3. **비교 분석**
   - 아티스트 간 벤치마킹
   - 성장률 TOP 10
   - 하락 위험군 알림

---

## 9. 결론

### ✅ 성공 요소

1. **실제 데이터 사용**
   - YouTube Data API v3로 실제 K-POP 데이터 수집
   - Mock 데이터 의존성 제거

2. **명확한 목적**
   - "아티스트 인기도 트렌드 분석"이라는 구체적 주제
   - 실용적 활용 시나리오 (기획사, 마케터)

3. **완전한 파이프라인**
   - Landing → Bronze → Silver → Gold → Train
   - 모든 단계에서 Spark + Delta Lake 활용

4. **빅데이터 기술 검증**
   - Reservoir Sampling, Bloom Filter, HyperLogLog
   - Sliding Window, Watermark, Pareto Front
   - 학술적 가치 확보

5. **계층적 분류**
   - Tier 1~4 (초대형/대형/중형/소형)
   - Binary 분류보다 실용적

### 📊 현재 데이터 현황

- **수집 완료**: 9개 아티스트, 270개 이벤트
- **처리 완료**: Bronze(262행) → Silver(120그룹) → Gold(10행)
- **모델 학습**: Logistic Regression (F1=1.0, 18.93ms)
- **Tier 분포**: 1(1명), 2(1명), 3(2명), 4(6명)

### 🚀 다음 단계

1. **30일 자동 수집** 시작 (cron 설정)
2. **트렌드 피처** 활성화 (7일/30일 후)
3. **모델 재학습** (100+ 아티스트)
4. **Streamlit UI** 완성 및 배포
5. **최종 보고서** 작성 (실험 결과 포함)

---

**실행 완료 일시**: 2025-10-14 17:19:00 KST  
**다음 체크포인트**: 2025-10-21 (7일 후 첫 트렌드 계산)

