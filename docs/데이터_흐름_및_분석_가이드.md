# K-POP 아티스트 인기도 분석 파이프라인: 데이터 흐름 가이드

> **작성일**: 2025-10-24
> **프로젝트**: Bigdata_Proj - Video/Social Real-Time Pipeline
> **목적**: YouTube K-POP 데이터 수집 → 분석 → ML 예측 → 시각화 전체 흐름 설명

---

## 📋 목차

1. [프로젝트 개요](#1-프로젝트-개요)
2. [데이터 수집 (Landing)](#2-데이터-수집-landing)
3. [데이터 분석 (Bronze → Silver → Gold)](#3-데이터-분석-bronze--silver--gold)
4. [모델 학습 (Train)](#4-모델-학습-train)
5. [예측 및 시각화 (UI)](#5-예측-및-시각화-ui)
6. [실행 예시](#6-실행-예시)
7. [비즈니스 활용](#7-비즈니스-활용)

---

## 1. 프로젝트 개요

### 🎯 핵심 질문
**"어떤 K-POP 아티스트가 다음 바이럴 스타가 될까?"**

### 📊 데이터 파이프라인 아키텍처

```
YouTube Data API v3
        ↓
[Landing] Raw JSON (NDJSON)
        ↓ (Reservoir Sampling, Bloom Filter)
[Bronze] Delta Lake + Artist Extraction
        ↓
[Silver] Streaming Aggregation (Window + Watermark)
        ↓
[Gold] Feature Engineering + CDF Tier Labeling
        ↓ (HyperLogLog)
[Train] ML Model Training + Pareto Front Optimization
        ↓
[UI] Streamlit Dashboard (실시간 예측)
```

### 🔧 기술 스택
- **빅데이터 처리**: Apache Spark 3.5.1, Delta Lake 3.2.0
- **스트리밍**: Structured Streaming (Sliding Window + Watermark)
- **머신러닝**: PySpark ML (Logistic Regression, Random Forest)
- **실험 추적**: MLflow 3.4.0
- **시각화**: Streamlit
- **데이터 소스**: YouTube Data API v3

---

## 2. 데이터 수집 (Landing)

### 📥 무엇을 수집하나?

**YouTube에서 K-POP 관련 영상 메타데이터 수집**

#### 수집 명령어
```bash
python -m video_social_rtp.cli fetch \
    --query "NewJeans" \
    --max-items 50 \
    --reservoir-k 64 \
    --region-code KR \
    --relevance-language ko
```

#### 수집 데이터 구조 (NDJSON)
```json
{
  "post_id": "search1_dQw4w9WgXcQ",
  "text": "NewJeans (뉴진스) 'Ditto' Official MV",
  "video_id": "dQw4w9WgXcQ",
  "author_id": "UC2eCJnq0L3cEGAy9d2kWcww",
  "lang": "ko",
  "ts": 1729756800000,
  "source": "yt"
}
```

#### 주요 필드
| 필드 | 설명 | 예시 |
|------|------|------|
| `post_id` | 검색 결과 고유 ID | `search1_dQw4w9WgXcQ` |
| `text` | 영상 제목 | `NewJeans 'Ditto' MV` |
| `video_id` | YouTube 영상 ID | `dQw4w9WgXcQ` |
| `author_id` | 채널 ID | `UC2eCJnq...` |
| `lang` | 언어 코드 | `ko`, `en` |
| `ts` | 타임스탬프 (ms) | `1729756800000` |

#### 핵심 기술: Reservoir Sampling
- **목적**: 대량 데이터에서 균등 확률로 K개 샘플 추출
- **알고리즘**: Vitter's Algorithm R
- **파라미터**: `--reservoir-k 64` (64개 샘플 유지)
- **장점**: 메모리 효율적 (O(k) 공간 복잡도)

#### 저장 위치
```
project/data/landing/events_1729756800.json
```

---

## 3. 데이터 분석 (Bronze → Silver → Gold)

### 🥉 Bronze Layer: 중복 제거 + 아티스트 추출

#### 실행 명령어
```bash
python -m video_social_rtp.cli bronze
```

#### 처리 과정

**1단계: Bloom Filter 중복 제거**
- **목적**: 지난 7일간 이미 수집한 `video_id` 필터링
- **파라미터**:
  - Capacity: 500,000
  - False Positive Rate: 0.01 (1%)
  - Lookback: 7일
- **저장 위치**:
  - Binary: `project/artifacts/bronze_bloom.bin`
  - Metadata: `project/artifacts/bronze_bloom.json`

**2단계: 아티스트 추출**
```python
# core/artists.py 로직
title = "NewJeans (뉴진스) 'Ditto' Official MV"
channel_id = "UC2eCJnq0L3cEGAy9d2kWcww"

# 1. 채널 ID 우선 매칭
if channel_id in OFFICIAL_CHANNELS:
    artist = OFFICIAL_CHANNELS[channel_id]  # "NEWJEANS"

# 2. 제목 패턴 매칭 (30+ 아티스트)
else:
    for canonical, patterns in ARTIST_PATTERNS.items():
        if any(pattern in title.lower() for pattern in patterns):
            artist = canonical  # "NEWJEANS"

# 3. 기본값
else:
    artist = "OTHER"
```

**지원 아티스트 (30+)**:
- BTS, BLACKPINK, TWICE, NEWJEANS, AESPA
- LESSERAFIM, IVE, ITZY, NMIXX, SEVENTEEN
- NCT, STRAYKIDS, ATEEZ, ENHYPEN, RIIZE
- ZEROBASEONE, KEPLER, BABYMONSTER 등

#### Bronze 스키마
| 컬럼 | 타입 | 설명 |
|------|------|------|
| `post_id` | String | 고유 ID |
| `text` | String | 영상 제목 |
| `video_id` | String | YouTube ID |
| `author_id` | String | 채널 ID |
| `lang` | String | 언어 |
| `ts` | Long | 타임스탬프 (ms) |
| `source` | String | 데이터 소스 (`yt`) |
| `artist` | String | **추출된 아티스트명** |
| `ingest_date` | String | **파티션 키** (YYYY-MM-DD) |

#### 저장 위치 (Delta Lake)
```
project/data/bronze/
  ├── ingest_date=2025-10-16/
  │   ├── artist=NEWJEANS/
  │   ├── artist=BTS/
  │   └── artist=BLACKPINK/
  └── ingest_date=2025-10-17/
      └── artist=NEWJEANS/
```

---

### 🥈 Silver Layer: 스트리밍 윈도우 집계

#### 실행 명령어
```bash
python -m video_social_rtp.cli silver --once
```

#### Structured Streaming 설정
- **윈도우**: 1시간 (Window: 1 hour)
- **슬라이드**: 5분 (Slide: 5 minutes)
- **워터마크**: 10분 (Watermark: 10 minutes)
- **트리거**: `availableNow` (배치 모드)

#### 윈도우 집계 로직
```python
# silver/stream.py 핵심 로직
df = (
    bronze_stream
    .withWatermark("event_time", "10 minutes")
    .groupBy(
        window(col("event_time"), "1 hour", "5 minutes"),
        col("artist")
    )
    .agg(
        count("*").alias("video_count"),
        countDistinct("video_id").alias("unique_videos"),
        sum("engagement_score").alias("total_engagement"),
        approx_count_distinct("author_id").alias("unique_authors")  # HyperLogLog
    )
)
```

#### HyperLogLog 근사 카운팅
- **목적**: 메모리 효율적으로 고유 값 개수 추정
- **함수**: `approx_count_distinct()`
- **정확도**: ±2% 오차 (기본값)
- **메모리**: O(log log n) vs O(n) for exact count

#### Silver 스키마
| 컬럼 | 타입 | 설명 |
|------|------|------|
| `window` | Struct | `{start, end}` 타임스탬프 |
| `artist` | String | 아티스트명 |
| `video_count` | Long | 윈도우 내 이벤트 수 |
| `unique_videos` | Long | 고유 영상 수 |
| `total_engagement` | Double | 총 참여도 점수 |
| `unique_authors` | Long | HLL 추정 고유 채널 수 |

#### 윈도우 예시
```
Window 1: 09:00-10:00 → NEWJEANS: 15 videos, engagement 450
Window 2: 09:05-10:05 → NEWJEANS: 16 videos, engagement 480
Window 3: 09:10-10:10 → NEWJEANS: 14 videos, engagement 420
```

#### 저장 위치
- **Delta Table**: `project/data/silver/`
- **Checkpoint**: `project/chk/silver/`

---

### 🥇 Gold Layer: 피처 엔지니어링 + Tier 분류

#### 실행 명령어
```bash
python -m video_social_rtp.cli gold --top-pct 0.9
```

#### 피처 엔지니어링

**1. 기본 통계 피처**
```python
# features/gold.py 집계 로직
artist_features = (
    silver_df
    .groupBy("artist")
    .agg(
        sum("total_engagement").alias("total_engagement"),
        avg("total_engagement").alias("avg_engagement"),
        max("total_engagement").alias("max_engagement"),
        sum("unique_videos").alias("total_videos"),
        sum("unique_authors").alias("unique_viewers_est")
    )
)
```

**2. 트렌드 피처** (30일 데이터 필요)
```python
# 7일 vs 30일 성장률
growth_rate_7d = (recent_7d - prev_7d) / prev_7d * 100
growth_rate_30d = (recent_30d - prev_30d) / prev_30d * 100

# 가속도 (momentum)
momentum = growth_rate_7d - growth_rate_30d

# 변동성 (volatility)
volatility = stddev(daily_engagement)
```

**3. 시장 지표**
```python
# 시장 점유율
market_share = artist_engagement / total_market_engagement * 100

# CDF 백분위수
percentile = cdf(artist_engagement)
```

#### CDF 기반 Tier 분류

**누적 분포 함수 (CDF) 계산**
```python
from pyspark.sql.window import Window

# Engagement 기준 정렬
window_spec = Window.orderBy("total_engagement")

# CDF 계산
gold_df = gold_df.withColumn(
    "percentile",
    percent_rank().over(window_spec)
)

# Tier 할당 (--top-pct 0.9 = 상위 10%가 Tier 1)
gold_df = gold_df.withColumn(
    "tier",
    when(col("percentile") >= 0.90, 1)  # 상위 10%
    .when(col("percentile") >= 0.75, 2)  # 상위 10~25%
    .when(col("percentile") >= 0.40, 3)  # 상위 25~60%
    .otherwise(4)                         # 하위 40%
)
```

**Tier 의미**:
- **Tier 1**: 초대형 바이럴 아티스트 (상위 10%)
- **Tier 2**: 대형 인기 아티스트 (상위 10~25%)
- **Tier 3**: 중견 아티스트 (상위 25~60%)
- **Tier 4**: 신인/소규모 아티스트 (하위 40%)

#### Trend Direction 분류
```python
trend_direction = (
    when(col("growth_rate_7d") > 10, "RISING")      # 성장 중
    .when(col("growth_rate_7d") < -10, "FALLING")   # 하락 중
    .otherwise("STEADY")                             # 안정적
)
```

#### Gold 스키마
| 컬럼 | 타입 | 설명 |
|------|------|------|
| `artist` | String | 아티스트명 |
| `total_engagement` | Double | 총 참여도 |
| `avg_engagement` | Double | 평균 참여도 |
| `max_engagement` | Double | 최대 참여도 |
| `total_videos` | Double | 총 영상 수 |
| `unique_viewers_est` | Double | HLL 추정 시청자 수 |
| `growth_rate_7d` | Double | 7일 성장률 (%) |
| `growth_rate_30d` | Double | 30일 성장률 (%) |
| `momentum` | Double | 가속도 |
| `volatility` | Double | 변동성 |
| `market_share` | Double | 시장 점유율 (%) |
| `percentile` | Double | CDF 백분위수 (0~1) |
| `tier` | Integer | Tier 등급 (1~4) |
| `trend_direction` | String | 추세 (RISING/STEADY/FALLING) |

#### 실제 데이터 예시 (2025-10-16 실행 결과)
```csv
artist,total_engagement,total_videos,percentile,tier,trend_direction
BLACKPINK,926,37,1.0,1,STEADY
BTS,281,15,0.5,4,STEADY
OTHER,71,4,0.0,4,STEADY
```

#### 저장 위치
- **Delta Table**: `project/data/gold/features/`
- **CSV Export**: `project/data/gold/features.csv`
- **Tier Cutoffs**: `project/artifacts/gold_tiers.json`

---

## 4. 모델 학습 (Train)

### 🤖 ML 목표: Tier 등급 예측

#### 실행 명령어 (MLflow 활성화)
```bash
python -m video_social_rtp.cli train
```

**중요**: `--no-mlflow` 플래그를 **사용하지 마세요**! MLflow로 실험 추적이 필요합니다.

#### 학습 데이터 준비

**피처 (X)**:
```python
feature_cols = [
    "total_engagement",
    "avg_engagement",
    "total_videos",
    "unique_viewers_est",
    "growth_rate_7d",
    "growth_rate_30d",
    "momentum",
    "volatility"
]
```

**레이블 (y)**:
```python
# Tier (1~4) → 0-indexed label
dataset = dataset.withColumn(
    "tier_idx",
    (col("tier") - 1).cast("double")
)
# tier_idx: 0 (Tier 1), 1 (Tier 2), 2 (Tier 3), 3 (Tier 4)
```

**Train/Test Split**:
- Train: 80% (random split, seed=42)
- Test: 20%

#### 모델 학습 (Multinomial Classification)

**Model 1: Logistic Regression**
```python
logreg = LogisticRegression(
    featuresCol="features",
    labelCol="tier_idx",
    maxIter=120,
    regParam=0.01,
    family="multinomial"  # 4-class classification
)
```

**Model 2: Random Forest**
```python
rf = RandomForestClassifier(
    featuresCol="features",
    labelCol="tier_idx",
    numTrees=250,
    maxDepth=12,
    seed=42
)
```

#### 평가 지표

```python
metrics = {
    "accuracy": MulticlassClassificationEvaluator(
        labelCol="tier_idx",
        metricName="accuracy"
    ),
    "f1": MulticlassClassificationEvaluator(
        labelCol="tier_idx",
        metricName="f1"
    )
}
```

추가 계산:
- **Inference Latency**: 1000건 예측 평균 시간 (ms)
- **Feature Count**: 사용된 피처 개수

#### MLflow 실험 추적

```python
import mlflow

mlflow.set_tracking_uri("file://project/artifacts/mlruns")
mlflow.set_experiment("train_pareto")

with mlflow.start_run(run_name="LogisticRegression"):
    mlflow.log_param("model_type", "logreg")
    mlflow.log_param("max_iter", 120)
    mlflow.log_param("reg_param", 0.01)

    mlflow.log_metric("accuracy", 0.85)
    mlflow.log_metric("f1", 0.83)
    mlflow.log_metric("latency_ms", 5.2)

    mlflow.spark.log_model(model, "model")
```

#### MLflow UI 접속
```bash
cd project/artifacts
mlflow ui --port 5000
```
브라우저에서 `http://localhost:5000` 접속

#### Pareto Front 최적화

**다목적 최적화 목표**:
- **Maximize**: accuracy, f1
- **Minimize**: latency_ms, feat_count

**Dominance 판정**:
```python
def dominates(model_a, model_b):
    # A가 B를 지배하려면:
    # 1. 모든 지표에서 A ≥ B (accuracy, f1 높고 latency, feat_count 낮음)
    # 2. 최소 하나의 지표에서 A > B (strictly better)
    better_or_equal = (
        a["f1"] >= b["f1"] and
        a["accuracy"] >= b["accuracy"] and
        a["latency_ms"] <= b["latency_ms"] and
        a["feat_count"] <= b["feat_count"]
    )
    strictly_better = (
        a["f1"] > b["f1"] or
        a["accuracy"] > b["accuracy"] or
        a["latency_ms"] < b["latency_ms"] or
        a["feat_count"] < b["feat_count"]
    )
    return better_or_equal and strictly_better
```

**Pareto Front 선택**:
```python
pareto_models = [
    model for model in all_models
    if not any(dominates(other, model) for other in all_models)
]
```

#### 결과 저장 (pareto.json)
```json
{
  "results": [
    {
      "model": "LogisticRegression",
      "accuracy": 0.85,
      "f1": 0.83,
      "latency_ms": 5.2,
      "feat_count": 8,
      "train_count": 240,
      "test_count": 60
    },
    {
      "model": "RandomForest",
      "accuracy": 0.92,
      "f1": 0.90,
      "latency_ms": 15.3,
      "feat_count": 8,
      "train_count": 240,
      "test_count": 60
    }
  ],
  "pareto": [
    {
      "model": "RandomForest",
      "is_pareto": true,
      "reason": "Highest accuracy/f1, acceptable latency"
    }
  ]
}
```

#### 저장 위치
- **Pareto 결과**: `project/artifacts/pareto.json`
- **MLflow Runs**: `project/artifacts/mlruns/`
- **모델 아티팩트**: MLflow tracking (Spark ML Pipeline)

---

## 5. 예측 및 시각화 (UI)

### 📊 Streamlit 대시보드

#### 실행 명령어
```bash
python -m video_social_rtp.cli ui --port 8501
```

브라우저에서 `http://localhost:8501` 접속

---

### 대시보드 주요 기능

#### 1️⃣ Top-K 아티스트 랭킹

**데이터 소스**: `project/data/gold/features.csv`

**시각화**:
```python
import streamlit as st
import pandas as pd

df = pd.read_csv("project/data/gold/features.csv")
top10 = df.nlargest(10, "total_engagement")

# Tier별 색상 매핑
tier_colors = {1: "🥇", 2: "🥈", 3: "🥉", 4: "⚪"}

for idx, row in top10.iterrows():
    st.write(f"{tier_colors[row['tier']]} {row['artist']}")
    st.progress(row['total_engagement'] / df['total_engagement'].max())
```

**출력 예시**:
```
🥇 BLACKPINK        ███████████░ 926
🥉 NEWJEANS        █████░░░░░░░ 450
⚪ BTS             ███░░░░░░░░░ 281
```

---

#### 2️⃣ CDF/PDF 분포 차트

**CDF (Cumulative Distribution Function)**:
```python
import matplotlib.pyplot as plt
import numpy as np

engagements = df['total_engagement'].sort_values()
cdf = np.arange(1, len(engagements) + 1) / len(engagements)

fig, ax = plt.subplots()
ax.plot(engagements, cdf, label='CDF')
ax.axhline(y=0.90, color='gold', linestyle='--', label='Tier 1 cutoff')
ax.axhline(y=0.75, color='silver', linestyle='--', label='Tier 2 cutoff')
ax.axhline(y=0.40, color='brown', linestyle='--', label='Tier 3 cutoff')
ax.set_xlabel('Total Engagement')
ax.set_ylabel('Cumulative Probability')
st.pyplot(fig)
```

**PDF (Probability Density Function)**:
```python
hist, bins = np.histogram(engagements, bins=30, density=True)
ax.bar(bins[:-1], hist, width=np.diff(bins), alpha=0.6, label='PDF')
```

---

#### 3️⃣ Bloom Filter 중복 체크

**입력 폼**:
```python
video_id = st.text_input("Video ID 입력:", "dQw4w9WgXcQ")

if st.button("중복 확인"):
    bloom = BloomFilter.from_file("project/artifacts/bronze_bloom.bin")

    if video_id in bloom:
        st.warning("⚠️ 이미 수집된 영상입니다 (지난 7일 내)")
        st.caption(f"False Positive Rate: {bloom.error_rate:.2%}")
    else:
        st.success("✅ 새로운 영상입니다")
```

**Bloom Filter 통계**:
- Capacity: 500,000
- Current Count: 12,450
- FPR: 0.01 (1%)
- Size: 2.4 MB

---

#### 4️⃣ 아티스트 트렌드 분석

**성장률 차트**:
```python
trend_df = df[df['artist'].isin(['NEWJEANS', 'BLACKPINK', 'BTS'])]

fig, ax = plt.subplots()
for artist in trend_df['artist'].unique():
    artist_data = trend_df[trend_df['artist'] == artist]
    ax.plot(
        ['7d', '30d'],
        [artist_data['growth_rate_7d'].values[0],
         artist_data['growth_rate_30d'].values[0]],
        marker='o',
        label=artist
    )

ax.set_ylabel('Growth Rate (%)')
ax.set_title('아티스트별 성장률 추이')
ax.legend()
st.pyplot(fig)
```

**Momentum 지표**:
```python
momentum_df = df[['artist', 'momentum', 'trend_direction']]

# Momentum > 5: 🚀 급성장
# -5 < Momentum < 5: ⏸️ 안정
# Momentum < -5: 📉 하락
```

---

#### 5️⃣ Tier 예측 시뮬레이터

**입력 폼**:
```python
st.subheader("🔮 새 아티스트 Tier 예측")

col1, col2 = st.columns(2)
with col1:
    total_engagement = st.number_input("Total Engagement", 0, 2000, 500)
    total_videos = st.number_input("Total Videos", 0, 100, 20)
    growth_7d = st.slider("Growth Rate 7d (%)", -50, 100, 10)
    growth_30d = st.slider("Growth Rate 30d (%)", -50, 100, 15)

with col2:
    avg_engagement = total_engagement / total_videos
    momentum = growth_7d - growth_30d
    volatility = st.number_input("Volatility", 0.0, 100.0, 10.0)
    unique_viewers = st.number_input("Unique Viewers", 0, 500, 100)
```

**예측 실행**:
```python
if st.button("예측하기"):
    # Load Pareto-optimal model from MLflow
    import mlflow.spark

    model_uri = "runs:/<run_id>/model"
    model = mlflow.spark.load_model(model_uri)

    # 피처 벡터 생성
    features = spark.createDataFrame([(
        total_engagement,
        avg_engagement,
        total_videos,
        unique_viewers,
        growth_7d,
        growth_30d,
        momentum,
        volatility
    )], schema=feature_schema)

    # 예측
    prediction = model.transform(features)
    predicted_tier = int(prediction.select("prediction").first()[0]) + 1

    # 결과 표시
    tier_emoji = {1: "🥇", 2: "🥈", 3: "🥉", 4: "⚪"}
    st.success(f"예측 Tier: {tier_emoji[predicted_tier]} Tier {predicted_tier}")

    if predicted_tier == 1:
        st.balloons()
        st.write("🔥 바이럴 가능성 매우 높음!")
```

---

#### 6️⃣ Pareto Front 모델 비교

**모델 성능 테이블**:
```python
import json

with open("project/artifacts/pareto.json") as f:
    pareto_data = json.load(f)

results_df = pd.DataFrame(pareto_data["results"])
st.dataframe(results_df)
```

**Pareto Front 그래프**:
```python
fig, ax = plt.subplots()

for model in pareto_data["results"]:
    color = 'red' if model in pareto_data["pareto"] else 'blue'
    marker = 'o' if model in pareto_data["pareto"] else 'x'

    ax.scatter(
        model["latency_ms"],
        model["accuracy"],
        c=color,
        marker=marker,
        s=100,
        label=model["model"]
    )

ax.set_xlabel("Inference Latency (ms)")
ax.set_ylabel("Accuracy")
ax.set_title("Pareto Front: Accuracy vs Latency")
ax.legend()
st.pyplot(fig)
```

---

## 6. 실행 예시

### 🚀 전체 파이프라인 실행

#### Step 1: 프로젝트 초기화
```bash
# 가상환경 활성화
source .venv/bin/activate

# 디렉토리 생성
python -m video_social_rtp.cli scaffold
```

#### Step 2: 데이터 수집 (Day 1-30)
```bash
# 매일 2회 실행 (오전 9시, 오후 3시)
python -m video_social_rtp.cli fetch --query "NewJeans" --region-code KR
python -m video_social_rtp.cli fetch --query "BTS official" --region-code KR
python -m video_social_rtp.cli fetch --query "BLACKPINK" --region-code KR
```

#### Step 3: Bronze 처리 (매일)
```bash
python -m video_social_rtp.cli bronze
```
**로그 확인**:
```
INFO bronze_bloom_loaded size_bits=4790400 hash_count=7 count=12450
INFO bronze_appended_rows=49
```

#### Step 4: Silver 집계 (매일)
```bash
python -m video_social_rtp.cli silver --once
```
**로그 확인**:
```
INFO silver_streaming_started watermark=10 minutes window=1 hour
INFO silver_batch_completed rows_written=156
```

#### Step 5: Gold 피처 생성 (매일)
```bash
python -m video_social_rtp.cli gold --top-pct 0.9
```
**출력 예시**:
```json
{
  "gold_rows": 3,
  "tier_distribution": {"1": 1, "2": 0, "3": 0, "4": 2},
  "cutoffs": {"tier1": 0.90, "tier2": 0.75, "tier3": 0.40}
}
```

#### Step 6: 모델 학습 (주 1회, 일요일)
```bash
# MLflow 활성화 (중요!)
python -m video_social_rtp.cli train
```
**로그 확인**:
```
INFO mlflow_experiment=train_pareto tracking_uri=file://project/artifacts/mlruns
INFO model=LogisticRegression accuracy=0.85 f1=0.83 latency_ms=5.2
INFO model=RandomForest accuracy=0.92 f1=0.90 latency_ms=15.3
INFO pareto_models=1 saved_to=project/artifacts/pareto.json
```

#### Step 7: 대시보드 실행
```bash
python -m video_social_rtp.cli ui --port 8501
```

---

### 📋 자동화 스크립트 (Cron 예시)

#### daily_pipeline.sh
```bash
#!/bin/bash
cd /home/student_15030/Bigdata_Proj
source .venv/bin/activate

# 데이터 수집
python -m video_social_rtp.cli fetch --query "NewJeans" --region-code KR
python -m video_social_rtp.cli fetch --query "BTS official" --region-code KR

# 처리
python -m video_social_rtp.cli bronze
python -m video_social_rtp.cli silver --once
python -m video_social_rtp.cli gold --top-pct 0.9

echo "Daily pipeline completed at $(date)"
```

#### weekly_train.sh
```bash
#!/bin/bash
cd /home/student_15030/Bigdata_Proj
source .venv/bin/activate

# 모델 재학습 (MLflow 활성화)
python -m video_social_rtp.cli train

echo "Weekly training completed at $(date)"
```

#### Crontab 설정
```bash
# 매일 오전 9시, 오후 3시 파이프라인 실행
0 9,15 * * * /home/student_15030/Bigdata_Proj/daily_pipeline.sh

# 매주 일요일 오전 10시 모델 재학습
0 10 * * 0 /home/student_15030/Bigdata_Proj/weekly_train.sh
```

---

## 7. 비즈니스 활용

### 💼 Use Case 1: 마케팅 타이밍 최적화

**시나리오**: 신곡 발매 타이밍 결정

**분석**:
```python
# NEWJEANS 최근 트렌드
growth_7d = +45%
momentum = +30  # 급상승
trend_direction = "RISING"
```

**인사이트**:
- 현재 성장 추세 강함 → **즉시 신곡 발매 권장**
- 예상 Tier: 1 (바이럴 가능성 85%)

---

### 💼 Use Case 2: 경쟁사 벤치마킹

**시나리오**: BLACKPINK vs BTS 비교

| 지표 | BLACKPINK | BTS |
|------|-----------|-----|
| Total Engagement | 926 | 281 |
| Tier | 1 | 4 |
| Growth Rate 7d | -2% | -5% |
| Trend | STEADY | FALLING |

**인사이트**:
- BLACKPINK: 성숙기 안정적 인기 유지
- BTS: 하락 추세 → 컴백 전략 필요

---

### 💼 Use Case 3: 신인 발굴

**시나리오**: 떠오르는 신인 아티스트 조기 발견

**쿼리**:
```python
rising_stars = df[
    (df['tier'] >= 3) &           # 현재 중하위권
    (df['growth_rate_7d'] > 50) & # 급성장 중
    (df['momentum'] > 20)          # 가속도 높음
]
```

**인사이트**:
- "RIIZE" growth_rate_7d = +78%, momentum = +35
- **예측**: 3개월 내 Tier 2 진입 가능성 높음
- **액션**: 조기 투자/협업 검토

---

### 💼 Use Case 4: 콘텐츠 전략 수립

**시나리오**: 어떤 유형의 콘텐츠가 바이럴되는가?

**분석**:
```python
# Tier 1 아티스트 공통점
tier1_artists = df[df['tier'] == 1]

# 평균 피처 비교
avg_videos = tier1_artists['total_videos'].mean()  # 35개
avg_engagement = tier1_artists['avg_engagement'].mean()  # 25.0
```

**인사이트**:
- Tier 1 달성 조건: 월 30+ 영상, 평균 engagement 20+
- **전략**: 고빈도 업로드 + 고퀄리티 유지

---

## 📚 참고 자료

### 알고리즘 상세

- **Reservoir Sampling**: Vitter's Algorithm R (1985)
- **Bloom Filter**: Space-efficient probabilistic data structure
- **HyperLogLog**: Flajolet et al. (2007) cardinality estimation
- **Pareto Front**: Multi-objective optimization (non-dominated sorting)

### 기술 문서

- [PySpark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Delta Lake Documentation](https://docs.delta.io/)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [YouTube Data API v3](https://developers.google.com/youtube/v3)

### 프로젝트 문서

- `docs/00_프로젝트_개요_및_아키텍처.md`
- `docs/01_데이터_수집_및_배치_ETL_설계.md`
- `docs/02_스트리밍_데이터_처리_설계.md`
- `docs/03_피처_엔지니어링_및_라벨링_설계.md`
- `docs/04_모델_학습_및_최적화_설계.md`
- `docs/05_실시간_예측_시스템_설계.md`

---

## ✅ 체크리스트

### 데이터 수집
- [ ] YouTube API 키 발급 및 `.env` 설정
- [ ] Landing 디렉토리 생성 (`scaffold`)
- [ ] 최소 7일 데이터 수집 (Bloom Filter 동작 위해)

### 데이터 처리
- [ ] Bronze: Bloom Filter 정상 동작 확인
- [ ] Silver: Checkpoint 디렉토리 생성 확인
- [ ] Gold: Tier 분포 균형 확인 (4개 Tier 모두 존재)

### 모델 학습
- [ ] **MLflow 활성화** (`--no-mlflow` 사용 금지!)
- [ ] MLflow UI에서 실험 결과 확인
- [ ] Pareto Front 모델 1개 이상 선택 확인

### 시각화
- [ ] Streamlit UI 정상 작동 확인
- [ ] CDF/PDF 차트 렌더링 확인
- [ ] Bloom Filter 중복 체크 테스트

---

**작성자**: Claude Code
**최종 수정**: 2025-10-24
**버전**: 1.0
**문의**: [GitHub Issues](https://github.com/umyunsang/Bigdata_Proj/issues)
