# 00. 프로젝트 개요 및 아키텍처 설계

## 1. 프로젝트 개요

### 1.1 문제 정의
- **현재 상황**: 소셜 비디오 플랫폼에서 발생하는 대용량 실시간 데이터의 효율적 처리 필요
- **핵심 문제**: 
  - YouTube API v3를 통한 대용량 비디오 메타데이터 수집 및 처리
  - 실시간 소셜 미디어 데이터 스트림 처리
  - 다차원 성능 지표를 고려한 모델 최적화
  - 지연 시간 최소화를 통한 실시간 예측 서비스 제공

### 1.2 프로젝트 목표
- **주요 목표**: 소셜 비디오 빅데이터 실시간 처리 플랫폼 구축
- **세부 목표**:
  - 멀티 소스 데이터 수집 및 배치 ETL 파이프라인 구축
  - 스트리밍 데이터 처리 및 실시간 분석 시스템 구현
  - 고급 피처 엔지니어링 및 자동 라벨링 시스템 개발
  - 다목적 최적화를 통한 모델 선택 자동화
  - 실시간 예측 및 시각화 대시보드 제공

## 2. 시스템 아키텍처

### 2.1 전체 시스템 구조도

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Data Sources  │    │  Data Ingestion │    │  Data Processing│
│                 │    │                 │    │                 │
│ • YouTube API   │───▶│ • Reservoir     │───▶│ • Bronze Layer  │
│ • Social Media  │    │   Sampling      │    │ • Silver Layer  │
│ • User Events   │    │ • Bloom Filter  │    │ • Gold Layer    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │                        │
                                ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Analytics     │    │   ML Pipeline   │    │   Real-time     │
│                 │    │                 │    │   Services      │
│ • CDF/PDF       │◀───│ • Multi-model   │◀───│ • Streamlit UI  │
│ • HLL Counting  │    │   Training      │    │ • Prediction API│
│ • Pareto Front  │    │ • Optimization  │    │ • Monitoring    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 2.2 데이터 플로우 아키텍처

#### 2.2.1 데이터 수집 계층 (Data Ingestion Layer)
- **YouTube API v3 연동**: 비디오 메타데이터, 통계, 댓글 수집
- **Reservoir Sampling**: 대용량 데이터 중 대표 샘플 추출
- **Bloom Filter**: 중복 데이터 사전 필터링

#### 2.2.2 데이터 처리 계층 (Data Processing Layer)
- **Bronze Layer**: 원본 데이터 보존 및 스키마 고정
- **Silver Layer**: 데이터 정제 및 구조화
- **Gold Layer**: 피처 엔지니어링 및 라벨링

#### 2.2.3 분석 및 ML 계층 (Analytics & ML Layer)
- **실시간 분석**: Sliding Window, Watermark 기반 실시간 집계
- **피처 엔지니어링**: HyperLogLog, CDF/PDF 기반 라벨링
- **모델 최적화**: Pareto Front 기반 다목적 최적화

#### 2.2.4 서비스 계층 (Service Layer)
- **실시간 예측**: 스트리밍 데이터 기반 실시간 예측
- **시각화**: Streamlit 기반 대시보드
- **API 서비스**: RESTful API 제공

## 3. 기술 스택

### 3.1 핵심 기술
- **Apache Spark**: 분산 데이터 처리 엔진
- **Delta Lake**: ACID 트랜잭션 지원 데이터 레이크
- **Python**: 주요 개발 언어
- **Streamlit**: 웹 기반 대시보드

### 3.2 데이터 처리 기술
- **Reservoir Sampling**: Vitter's Algorithm R
- **Bloom Filter**: 중복 데이터 필터링
- **HyperLogLog**: 근사 유니크 카운팅
- **Sliding Window**: 실시간 집계
- **Watermark**: 지연 이벤트 처리

### 3.3 ML/AI 기술
- **Pareto Front**: 다목적 최적화
- **CDF/PDF**: 통계적 라벨링
- **Multi-model Training**: 다양한 알고리즘 비교

## 4. 데이터 모델

### 4.1 Bronze Layer 스키마
```json
{
  "video_id": "string",
  "title": "string", 
  "channel_id": "string",
  "published_at": "timestamp",
  "view_count": "long",
  "like_count": "long",
  "comment_count": "long",
  "duration": "long",
  "category_id": "int",
  "ingest_timestamp": "timestamp"
}
```

### 4.2 Silver Layer 스키마
```json
{
  "video_id": "string",
  "engagement_score": "double",
  "trending_score": "double", 
  "social_metrics": {
    "unique_viewers": "long",
    "engagement_rate": "double",
    "viral_coefficient": "double"
  },
  "processing_timestamp": "timestamp"
}
```

### 4.3 Gold Layer 스키마
```json
{
  "video_id": "string",
  "features": {
    "engagement_24h": "double",
    "view_velocity": "double",
    "social_sentiment": "double",
    "content_quality_score": "double"
  },
  "labels": {
    "is_trending": "boolean",
    "performance_tier": "string",
    "prediction_confidence": "double"
  },
  "prediction_timestamp": "timestamp"
}
```

## 5. 성능 요구사항

### 5.1 처리 성능
- **데이터 수집**: 초당 10,000개 이벤트 처리
- **실시간 분석**: 1초 이내 지연 시간
- **배치 처리**: 시간당 1TB 데이터 처리

### 5.2 확장성
- **수평 확장**: Spark 클러스터 기반 자동 스케일링
- **데이터 파티셔닝**: 시간 기반 파티셔닝
- **캐싱**: Redis 기반 실시간 캐싱

### 5.3 가용성
- **장애 복구**: Delta Lake 기반 ACID 트랜잭션
- **데이터 백업**: 자동 백업 및 복구
- **모니터링**: 실시간 시스템 상태 모니터링

## 6. 보안 및 규정 준수

### 6.1 데이터 보안
- **API 키 관리**: 환경 변수 기반 보안 관리
- **데이터 암호화**: 전송 및 저장 시 암호화
- **접근 제어**: 역할 기반 접근 제어 (RBAC)

### 6.2 개인정보 보호
- **데이터 익명화**: 개인 식별 정보 제거
- **GDPR 준수**: 유럽 개인정보보호법 준수
- **데이터 보존**: 정책 기반 데이터 보존

## 7. 모니터링 및 로깅

### 7.1 시스템 모니터링
- **메트릭 수집**: Prometheus 기반 메트릭 수집
- **알림 시스템**: 임계값 기반 자동 알림
- **대시보드**: Grafana 기반 모니터링 대시보드

### 7.2 로깅 전략
- **구조화된 로깅**: JSON 형태 로그 출력
- **로그 레벨**: DEBUG, INFO, WARN, ERROR
- **로그 보존**: 30일 로그 보존 정책

## 8. 배포 및 운영

### 8.1 배포 전략
- **컨테이너화**: Docker 기반 컨테이너 배포
- **CI/CD**: GitHub Actions 기반 자동 배포
- **환경 분리**: 개발, 스테이징, 프로덕션 환경 분리

### 8.2 운영 관리
- **자동 스케일링**: 부하 기반 자동 스케일링
- **헬스 체크**: 서비스 상태 자동 확인
- **백업 복구**: 정기 백업 및 복구 테스트

---

**다음 문서**: [01_데이터_수집_및_배치_ETL_설계.md](./01_데이터_수집_및_배치_ETL_설계.md)

