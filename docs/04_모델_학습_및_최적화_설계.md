# 04. 모델 학습 및 최적화 설계

## 1. 개요

### 1.1 목표
- 다중 알고리즘 벤치마킹을 통한 최적 모델 선택
- Pareto Front 기반 다목적 최적화
- 모델 성능 지표 및 비용 분석
- 자동화된 모델 선택 및 배포 파이프라인

### 1.2 핵심 요구사항
- **성능**: 높은 예측 정확도 (AUC > 0.85)
- **지연시간**: 실시간 추론 100ms 이내
- **해석가능성**: 모델 결정 과정 설명 가능
- **확장성**: 다양한 알고리즘 지원 및 비교

## 2. 모델 학습 아키텍처

### 2.1 전체 학습 파이프라인

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Feature Data  │    │  Model Training │    │   Optimization  │
│                 │    │                 │    │                 │
│ • Gold Layer    │───▶│ • Multi-Algo    │───▶│ • Pareto Front  │
│ • Labels        │    │ • Hyperparams   │    │ • Best Model    │
│ • Validation    │    │ • Cross-Valid   │    │ • Deployment   │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │  Model Registry │
                       │                 │
                       │ • Versioning    │
                       │ • Metadata      │
                       │ • Performance   │
                       └─────────────────┘
```

### 2.2 모델 카테고리

#### 2.2.1 전통적 ML 알고리즘
- **선형 모델**: 로지스틱 회귀, 릿지 회귀
- **트리 기반**: 랜덤 포레스트, XGBoost, LightGBM
- **앙상블**: Voting, Bagging, Stacking

#### 2.2.2 딥러닝 모델
- **신경망**: MLP, CNN, RNN
- **고급 모델**: Transformer, GNN

#### 2.2.3 특화 모델
- **시계열**: ARIMA, LSTM, Prophet
- **추천**: 협업 필터링, 딥러닝 기반

## 3. 다중 알고리즘 벤치마킹

### 3.1 알고리즘 비교 프레임워크

#### 3.1.1 모델 정의
```python
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
import xgboost as xgb
import lightgbm as lgb

class ModelBenchmark:
    def __init__(self):
        self.models = {
            "logistic_regression": LogisticRegression(random_state=42),
            "random_forest": RandomForestClassifier(n_estimators=100, random_state=42),
            "gradient_boosting": GradientBoostingClassifier(random_state=42),
            "xgboost": xgb.XGBClassifier(random_state=42),
            "lightgbm": lgb.LGBMClassifier(random_state=42),
            "svm": SVC(probability=True, random_state=42)
        }
        self.results = {}
    
    def train_and_evaluate(self, X_train, y_train, X_test, y_test):
        """모든 모델 학습 및 평가"""
        for name, model in self.models.items():
            print(f"Training {name}...")
            
            # 모델 학습
            model.fit(X_train, y_train)
            
            # 예측
            y_pred = model.predict(X_test)
            y_pred_proba = model.predict_proba(X_test)[:, 1]
            
            # 성능 지표 계산
            metrics = self._calculate_metrics(y_test, y_pred, y_pred_proba)
            self.results[name] = metrics
            
        return self.results
```

#### 3.1.2 성능 지표 계산
```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import time

def _calculate_metrics(self, y_true, y_pred, y_pred_proba):
    """성능 지표 계산"""
    metrics = {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred),
        "recall": recall_score(y_true, y_pred),
        "f1_score": f1_score(y_true, y_pred),
        "auc": roc_auc_score(y_true, y_pred_proba)
    }
    return metrics

def _measure_inference_time(self, model, X_test):
    """추론 시간 측정"""
    start_time = time.time()
    _ = model.predict(X_test)
    end_time = time.time()
    return (end_time - start_time) * 1000  # ms 단위
```

### 3.2 하이퍼파라미터 최적화

#### 3.2.1 그리드 서치
```python
from sklearn.model_selection import GridSearchCV

class HyperparameterOptimizer:
    def __init__(self):
        self.param_grids = {
            "random_forest": {
                "n_estimators": [50, 100, 200],
                "max_depth": [10, 20, None],
                "min_samples_split": [2, 5, 10]
            },
            "xgboost": {
                "n_estimators": [100, 200, 300],
                "max_depth": [3, 6, 9],
                "learning_rate": [0.01, 0.1, 0.2]
            },
            "lightgbm": {
                "n_estimators": [100, 200, 300],
                "max_depth": [3, 6, 9],
                "learning_rate": [0.01, 0.1, 0.2]
            }
        }
    
    def optimize_hyperparameters(self, model_name, X_train, y_train, cv=5):
        """하이퍼파라미터 최적화"""
        if model_name not in self.param_grids:
            raise ValueError(f"Unknown model: {model_name}")
        
        model = self.models[model_name]
        param_grid = self.param_grids[model_name]
        
        grid_search = GridSearchCV(
            model, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1
        )
        grid_search.fit(X_train, y_train)
        
        return grid_search.best_estimator_, grid_search.best_params_
```

#### 3.2.2 베이지안 최적화
```python
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args

class BayesianOptimizer:
    def __init__(self, model_class, param_space):
        self.model_class = model_class
        self.param_space = param_space
        self.best_score = -np.inf
        self.best_params = None
    
    def objective(self, params):
        """목적 함수 (최대화를 위해 음수 반환)"""
        model = self.model_class(**params)
        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')
        score = scores.mean()
        
        if score > self.best_score:
            self.best_score = score
            self.best_params = params
        
        return -score  # 최소화를 위해 음수
    
    def optimize(self, n_calls=50):
        """베이지안 최적화 실행"""
        result = gp_minimize(
            self.objective,
            self.param_space,
            n_calls=n_calls,
            random_state=42
        )
        return result
```

## 4. Pareto Front 최적화

### 4.1 다목적 최적화 개요

#### 4.1.1 목적 함수 정의
```python
class MultiObjectiveOptimizer:
    def __init__(self):
        self.objectives = {
            "accuracy": self._maximize_accuracy,
            "speed": self._minimize_inference_time,
            "complexity": self._minimize_model_complexity,
            "interpretability": self._maximize_interpretability
        }
        self.weights = {
            "accuracy": 0.4,
            "speed": 0.3,
            "complexity": 0.2,
            "interpretability": 0.1
        }
    
    def evaluate_model(self, model, X_test, y_test):
        """모델 다목적 평가"""
        # 정확도
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        # 추론 시간
        inference_time = self._measure_inference_time(model, X_test)
        
        # 모델 복잡도
        complexity = self._calculate_model_complexity(model)
        
        # 해석가능성
        interpretability = self._calculate_interpretability(model)
        
        return {
            "accuracy": accuracy,
            "inference_time": inference_time,
            "complexity": complexity,
            "interpretability": interpretability
        }
```

#### 4.1.2 Pareto Front 계산
```python
import numpy as np
from scipy.spatial.distance import pdist, squareform

class ParetoFrontCalculator:
    def __init__(self):
        self.pareto_front = []
        self.dominated_solutions = []
    
    def calculate_pareto_front(self, solutions):
        """Pareto Front 계산"""
        self.pareto_front = []
        self.dominated_solutions = []
        
        for i, solution in enumerate(solutions):
            is_dominated = False
            
            for j, other_solution in enumerate(solutions):
                if i != j and self._dominates(other_solution, solution):
                    is_dominated = True
                    break
            
            if not is_dominated:
                self.pareto_front.append(solution)
            else:
                self.dominated_solutions.append(solution)
        
        return self.pareto_front
    
    def _dominates(self, solution1, solution2):
        """solution1이 solution2를 지배하는지 확인"""
        # 모든 목적에서 solution1이 solution2보다 좋거나 같고
        # 최소 하나의 목적에서 더 좋아야 함
        better_or_equal = all(s1 >= s2 for s1, s2 in zip(solution1, solution2))
        strictly_better = any(s1 > s2 for s1, s2 in zip(solution1, solution2))
        
        return better_or_equal and strictly_better
```

### 4.2 Pareto Front 시각화

#### 4.2.1 2D Pareto Front
```python
import matplotlib.pyplot as plt

def plot_2d_pareto_front(solutions, x_metric, y_metric, title="Pareto Front"):
    """2D Pareto Front 시각화"""
    pareto_calculator = ParetoFrontCalculator()
    pareto_front = pareto_calculator.calculate_pareto_front(solutions)
    
    # 모든 솔루션
    x_all = [sol[x_metric] for sol in solutions]
    y_all = [sol[y_metric] for sol in solutions]
    
    # Pareto Front 솔루션
    x_pareto = [sol[x_metric] for sol in pareto_front]
    y_pareto = [sol[y_metric] for sol in pareto_front]
    
    plt.figure(figsize=(10, 6))
    plt.scatter(x_all, y_all, alpha=0.6, label="All Solutions")
    plt.scatter(x_pareto, y_pareto, color='red', s=100, label="Pareto Front")
    plt.xlabel(x_metric)
    plt.ylabel(y_metric)
    plt.title(title)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()
```

#### 4.2.2 3D Pareto Front
```python
from mpl_toolkits.mplot3d import Axes3D

def plot_3d_pareto_front(solutions, x_metric, y_metric, z_metric):
    """3D Pareto Front 시각화"""
    pareto_calculator = ParetoFrontCalculator()
    pareto_front = pareto_calculator.calculate_pareto_front(solutions)
    
    fig = plt.figure(figsize=(12, 8))
    ax = fig.add_subplot(111, projection='3d')
    
    # 모든 솔루션
    x_all = [sol[x_metric] for sol in solutions]
    y_all = [sol[y_metric] for sol in solutions]
    z_all = [sol[z_metric] for sol in solutions]
    
    # Pareto Front 솔루션
    x_pareto = [sol[x_metric] for sol in pareto_front]
    y_pareto = [sol[y_metric] for sol in pareto_front]
    z_pareto = [sol[z_metric] for sol in pareto_front]
    
    ax.scatter(x_all, y_all, z_all, alpha=0.6, label="All Solutions")
    ax.scatter(x_pareto, y_pareto, z_pareto, color='red', s=100, label="Pareto Front")
    
    ax.set_xlabel(x_metric)
    ax.set_ylabel(y_metric)
    ax.set_zlabel(z_metric)
    ax.legend()
    plt.show()
```

## 5. 모델 성능 분석

### 5.1 성능 지표 체계

#### 5.1.1 분류 성능 지표
```python
class ClassificationMetrics:
    def __init__(self):
        self.metrics = {}
    
    def calculate_all_metrics(self, y_true, y_pred, y_pred_proba):
        """모든 분류 지표 계산"""
        metrics = {
            # 기본 지표
            "accuracy": accuracy_score(y_true, y_pred),
            "precision": precision_score(y_true, y_pred),
            "recall": recall_score(y_true, y_pred),
            "f1_score": f1_score(y_true, y_pred),
            "auc": roc_auc_score(y_true, y_pred_proba),
            
            # 고급 지표
            "precision_recall_auc": average_precision_score(y_true, y_pred_proba),
            "log_loss": log_loss(y_true, y_pred_proba),
            "brier_score": brier_score_loss(y_true, y_pred_proba)
        }
        
        # 클래스별 지표
        metrics.update(self._calculate_class_metrics(y_true, y_pred))
        
        return metrics
    
    def _calculate_class_metrics(self, y_true, y_pred):
        """클래스별 지표 계산"""
        from sklearn.metrics import classification_report
        
        report = classification_report(y_true, y_pred, output_dict=True)
        
        return {
            "class_0_precision": report["0"]["precision"],
            "class_0_recall": report["0"]["recall"],
            "class_0_f1": report["0"]["f1-score"],
            "class_1_precision": report["1"]["precision"],
            "class_1_recall": report["1"]["recall"],
            "class_1_f1": report["1"]["f1-score"]
        }
```

#### 5.1.2 비용 기반 지표
```python
class CostBasedMetrics:
    def __init__(self, false_positive_cost=1.0, false_negative_cost=5.0):
        self.fp_cost = false_positive_cost
        self.fn_cost = false_negative_cost
    
    def calculate_cost_metrics(self, y_true, y_pred):
        """비용 기반 지표 계산"""
        from sklearn.metrics import confusion_matrix
        
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
        
        total_cost = fp * self.fp_cost + fn * self.fn_cost
        max_cost = (fp + fn) * max(self.fp_cost, self.fn_cost)
        cost_ratio = total_cost / max_cost if max_cost > 0 else 0
        
        return {
            "total_cost": total_cost,
            "cost_ratio": cost_ratio,
            "false_positive_cost": fp * self.fp_cost,
            "false_negative_cost": fn * self.fn_cost
        }
```

### 5.2 모델 해석가능성

#### 5.2.1 피처 중요도 분석
```python
class ModelInterpretability:
    def __init__(self):
        self.feature_importance = {}
        self.shap_values = None
    
    def analyze_feature_importance(self, model, feature_names):
        """피처 중요도 분석"""
        if hasattr(model, 'feature_importances_'):
            importance = model.feature_importances_
            self.feature_importance = dict(zip(feature_names, importance))
        elif hasattr(model, 'coef_'):
            importance = np.abs(model.coef_[0])
            self.feature_importance = dict(zip(feature_names, importance))
        
        return self.feature_importance
    
    def calculate_shap_values(self, model, X_test):
        """SHAP 값 계산"""
        import shap
        
        if hasattr(model, 'predict_proba'):
            explainer = shap.TreeExplainer(model)
            self.shap_values = explainer.shap_values(X_test)
        else:
            explainer = shap.LinearExplainer(model, X_test)
            self.shap_values = explainer.shap_values(X_test)
        
        return self.shap_values
```

#### 5.2.2 모델 설명 생성
```python
def generate_model_explanation(model, X_test, y_pred, feature_names):
    """모델 설명 생성"""
    explanation = {
        "model_type": type(model).__name__,
        "feature_count": len(feature_names),
        "prediction_confidence": np.mean(np.max(model.predict_proba(X_test), axis=1)),
        "feature_importance": analyze_feature_importance(model, feature_names)
    }
    
    # SHAP 기반 설명
    if hasattr(model, 'predict_proba'):
        shap_values = calculate_shap_values(model, X_test)
        explanation["shap_summary"] = shap.summary_plot(shap_values, X_test, feature_names=feature_names)
    
    return explanation
```

## 6. 모델 레지스트리

### 6.1 모델 버전 관리

#### 6.1.1 모델 메타데이터
```python
class ModelMetadata:
    def __init__(self, model_name, version, model_type):
        self.model_name = model_name
        self.version = version
        self.model_type = model_type
        self.created_at = datetime.now()
        self.metrics = {}
        self.hyperparameters = {}
        self.feature_list = []
        self.training_data_hash = None
    
    def add_metrics(self, metrics_dict):
        """성능 지표 추가"""
        self.metrics.update(metrics_dict)
    
    def add_hyperparameters(self, hyperparams_dict):
        """하이퍼파라미터 추가"""
        self.hyperparameters.update(hyperparams_dict)
    
    def set_feature_list(self, features):
        """피처 리스트 설정"""
        self.feature_list = features
    
    def to_dict(self):
        """딕셔너리로 변환"""
        return {
            "model_name": self.model_name,
            "version": self.version,
            "model_type": self.model_type,
            "created_at": self.created_at.isoformat(),
            "metrics": self.metrics,
            "hyperparameters": self.hyperparameters,
            "feature_list": self.feature_list,
            "training_data_hash": self.training_data_hash
        }
```

#### 6.1.2 모델 저장 및 로드
```python
import joblib
import hashlib

class ModelRegistry:
    def __init__(self, registry_path: str):
        self.registry_path = registry_path
        self.models = {}
        self.metadata = {}
    
    def save_model(self, model, metadata: ModelMetadata):
        """모델 저장"""
        model_path = f"{self.registry_path}/{metadata.model_name}_v{metadata.version}"
        
        # 모델 저장
        joblib.dump(model, f"{model_path}/model.pkl")
        
        # 메타데이터 저장
        with open(f"{model_path}/metadata.json", "w") as f:
            json.dump(metadata.to_dict(), f, indent=2)
        
        # 레지스트리 업데이트
        self.models[f"{metadata.model_name}_v{metadata.version}"] = model_path
        self.metadata[f"{metadata.model_name}_v{metadata.version}"] = metadata
    
    def load_model(self, model_name, version):
        """모델 로드"""
        model_key = f"{model_name}_v{version}"
        if model_key not in self.models:
            raise ValueError(f"Model {model_key} not found")
        
        model_path = self.models[model_key]
        model = joblib.load(f"{model_path}/model.pkl")
        
        return model, self.metadata[model_key]
    
    def list_models(self):
        """모델 목록 조회"""
        return list(self.models.keys())
```

### 6.2 모델 비교 및 선택

#### 6.2.1 모델 성능 비교
```python
class ModelComparator:
    def __init__(self, registry: ModelRegistry):
        self.registry = registry
    
    def compare_models(self, model_list):
        """모델 성능 비교"""
        comparison_results = {}
        
        for model_name in model_list:
            model, metadata = self.registry.load_model(model_name.split('_v')[0], 
                                                     model_name.split('_v')[1])
            
            comparison_results[model_name] = {
                "metrics": metadata.metrics,
                "hyperparameters": metadata.hyperparameters,
                "feature_count": len(metadata.feature_list),
                "created_at": metadata.created_at
            }
        
        return comparison_results
    
    def select_best_model(self, metric="auc", ascending=False):
        """최고 성능 모델 선택"""
        all_models = self.registry.list_models()
        comparison = self.compare_models(all_models)
        
        # 메트릭 기준 정렬
        sorted_models = sorted(comparison.items(), 
                            key=lambda x: x[1]["metrics"].get(metric, 0), 
                            reverse=not ascending)
        
        return sorted_models[0][0]  # 최고 성능 모델명
```

## 7. 자동화된 모델 선택

### 7.1 모델 선택 전략

#### 7.1.1 규칙 기반 선택
```python
class RuleBasedModelSelector:
    def __init__(self):
        self.rules = {
            "high_accuracy": lambda metrics: metrics.get("auc", 0) > 0.85,
            "fast_inference": lambda metrics: metrics.get("inference_time", float('inf')) < 100,
            "low_complexity": lambda metrics: metrics.get("complexity", float('inf')) < 0.5,
            "high_interpretability": lambda metrics: metrics.get("interpretability", 0) > 0.7
        }
    
    def select_model(self, model_comparison):
        """규칙 기반 모델 선택"""
        qualified_models = []
        
        for model_name, metrics in model_comparison.items():
            if all(rule(metrics) for rule in self.rules.values()):
                qualified_models.append((model_name, metrics))
        
        if not qualified_models:
            # 규칙을 만족하는 모델이 없으면 가장 높은 AUC 선택
            return max(model_comparison.items(), key=lambda x: x[1].get("auc", 0))
        
        # 규칙을 만족하는 모델 중에서 가장 높은 AUC 선택
        return max(qualified_models, key=lambda x: x[1].get("auc", 0))
```

#### 7.1.2 Pareto Front 기반 선택
```python
class ParetoBasedModelSelector:
    def __init__(self, objectives):
        self.objectives = objectives
        self.pareto_calculator = ParetoFrontCalculator()
    
    def select_model(self, model_comparison):
        """Pareto Front 기반 모델 선택"""
        # 솔루션 벡터 생성
        solutions = []
        model_names = []
        
        for model_name, metrics in model_comparison.items():
            solution = [metrics.get(obj, 0) for obj in self.objectives]
            solutions.append(solution)
            model_names.append(model_name)
        
        # Pareto Front 계산
        pareto_front = self.pareto_calculator.calculate_pareto_front(solutions)
        
        # Pareto Front에서 가장 균형잡힌 모델 선택
        if pareto_front:
            # 각 솔루션의 목적 함수 가중합 계산
            weighted_scores = []
            for solution in pareto_front:
                score = sum(sol * weight for sol, weight in zip(solution, [0.4, 0.3, 0.2, 0.1]))
                weighted_scores.append(score)
            
            best_idx = np.argmax(weighted_scores)
            best_solution = pareto_front[best_idx]
            best_model_idx = solutions.index(best_solution)
            return model_names[best_model_idx]
        
        return None
```

## 8. 모델 배포 및 모니터링

### 8.1 모델 배포

#### 8.1.1 A/B 테스트
```python
class ABTestManager:
    def __init__(self):
        self.active_tests = {}
        self.test_results = {}
    
    def start_ab_test(self, test_name, model_a, model_b, traffic_split=0.5):
        """A/B 테스트 시작"""
        self.active_tests[test_name] = {
            "model_a": model_a,
            "model_b": model_b,
            "traffic_split": traffic_split,
            "start_time": datetime.now(),
            "results": {"model_a": [], "model_b": []}
        }
    
    def route_traffic(self, test_name, user_id, features):
        """트래픽 라우팅"""
        if test_name not in self.active_tests:
            return None
        
        test = self.active_tests[test_name]
        hash_value = hash(f"{user_id}_{test_name}") % 100
        
        if hash_value < test["traffic_split"] * 100:
            model = test["model_a"]
            group = "model_a"
        else:
            model = test["model_b"]
            group = "model_b"
        
        prediction = model.predict([features])[0]
        confidence = model.predict_proba([features])[0].max()
        
        return {
            "prediction": prediction,
            "confidence": confidence,
            "group": group,
            "model": model
        }
```

#### 8.1.2 모델 성능 모니터링
```python
class ModelPerformanceMonitor:
    def __init__(self):
        self.performance_history = {}
        self.alerts = []
    
    def monitor_model_performance(self, model_name, predictions, actuals):
        """모델 성능 모니터링"""
        current_metrics = self._calculate_current_metrics(predictions, actuals)
        
        if model_name not in self.performance_history:
            self.performance_history[model_name] = []
        
        self.performance_history[model_name].append({
            "timestamp": datetime.now(),
            "metrics": current_metrics
        })
        
        # 성능 저하 감지
        self._detect_performance_degradation(model_name, current_metrics)
        
        return current_metrics
    
    def _detect_performance_degradation(self, model_name, current_metrics):
        """성능 저하 감지"""
        if len(self.performance_history[model_name]) < 10:
            return
        
        # 최근 10개 성능과 이전 10개 성능 비교
        recent_metrics = [entry["metrics"] for entry in self.performance_history[model_name][-10:]]
        previous_metrics = [entry["metrics"] for entry in self.performance_history[model_name][-20:-10]]
        
        recent_auc = np.mean([m["auc"] for m in recent_metrics])
        previous_auc = np.mean([m["auc"] for m in previous_metrics])
        
        if recent_auc < previous_auc * 0.95:  # 5% 이상 성능 저하
            alert = {
                "model_name": model_name,
                "alert_type": "performance_degradation",
                "severity": "high",
                "message": f"Model {model_name} performance degraded by {((previous_auc - recent_auc) / previous_auc * 100):.2f}%",
                "timestamp": datetime.now()
            }
            self.alerts.append(alert)
```

---

**이전 문서**: [03_피처_엔지니어링_및_라벨링_설계.md](./03_피처_엔지니어링_및_라벨링_설계.md)  
**다음 문서**: [05_실시간_예측_시스템_설계.md](./05_실시간_예측_시스템_설계.md)

