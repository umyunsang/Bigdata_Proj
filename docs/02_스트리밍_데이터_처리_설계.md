# 02. 스트리밍 데이터 처리 설계

## 1. 개요

### 1.1 목표
- 실시간 스트리밍 데이터 처리 파이프라인 구축
- Sliding Window와 Watermark를 활용한 지연 이벤트 처리
- Silver Layer 데이터 정제 및 구조화
- 실시간 집계 및 분석 기능 제공

### 1.2 핵심 요구사항
- **처리 지연시간**: 1초 이내 실시간 처리
- **데이터 정확성**: 99.9% 이상 정확한 집계 결과
- **확장성**: 수평 확장 가능한 스트리밍 아키텍처
- **장애 복구**: 체크포인트 기반 자동 복구

## 2. 스트리밍 아키텍처 설계

### 2.1 전체 스트리밍 파이프라인

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Data Sources  │    │  Stream Processing│   │   Output Sinks  │
│                 │    │                 │    │                 │
│ • Bronze Layer  │───▶│ • File Streaming │───▶│ • Silver Layer  │
│ • Real-time     │    │ • Watermark     │    │ • Analytics     │
│   Events        │    │ • Sliding Window│    │ • Monitoring    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │   State Store   │
                       │                 │
                       │ • Checkpoints   │
                       │ • State Tables  │
                       │ • Recovery      │
                       └─────────────────┘
```

### 2.2 스트리밍 처리 계층

#### 2.2.1 Source Layer
- **File Streaming Source**: Bronze Layer 파일 모니터링
- **Kafka Source**: 실시간 이벤트 스트림 (선택사항)
- **Custom Source**: API 기반 실시간 데이터 수집

#### 2.2.2 Processing Layer
- **Watermark Processing**: 지연 이벤트 처리
- **Window Operations**: 시간 기반 집계
- **State Management**: 중간 상태 저장 및 관리

#### 2.2.3 Sink Layer
- **Delta Lake Sink**: Silver Layer 저장
- **Console Sink**: 실시간 모니터링
- **Database Sink**: 관계형 데이터베이스 저장

## 3. Watermark 설계

### 3.1 Watermark 개념

#### 3.1.1 기본 원리
- **이벤트 시간**: 데이터가 실제 발생한 시간
- **처리 시간**: 데이터가 처리 시스템에 도착한 시간
- **Watermark**: 지연 이벤트 허용 임계값

#### 3.1.2 Watermark 설정
```python
# Watermark 설정 예시
watermark_expr = "event_timestamp - interval '10 minutes'"

streaming_df = spark \
    .readStream \
    .format("delta") \
    .option("path", "data/bronze/videos") \
    .load() \
    .withWatermark("event_timestamp", "10 minutes")
```

### 3.2 Watermark 전략

#### 3.2.1 고정 지연 전략
```python
class FixedDelayWatermark:
    def __init__(self, delay_minutes: int = 10):
        self.delay_minutes = delay_minutes
        
    def get_watermark(self, current_time: datetime) -> datetime:
        return current_time - timedelta(minutes=self.delay_minutes)
```

#### 3.2.2 적응형 지연 전략
```python
class AdaptiveWatermark:
    def __init__(self, base_delay: int = 5, max_delay: int = 30):
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.current_delay = base_delay
        
    def update_delay(self, late_events_ratio: float):
        if late_events_ratio > 0.1:  # 10% 이상 지연 이벤트
            self.current_delay = min(self.current_delay + 1, self.max_delay)
        elif late_events_ratio < 0.01:  # 1% 미만 지연 이벤트
            self.current_delay = max(self.current_delay - 1, self.base_delay)
```

## 4. Sliding Window 설계

### 4.1 Window 타입

#### 4.1.1 Tumbling Window
```python
# 1시간 고정 윈도우
tumbling_window = df \
    .groupBy(window(col("event_timestamp"), "1 hour")) \
    .agg(
        count("video_id").alias("video_count"),
        sum("view_count").alias("total_views"),
        avg("engagement_score").alias("avg_engagement")
    )
```

#### 4.1.2 Sliding Window
```python
# 1시간 윈도우, 5분 슬라이드
sliding_window = df \
    .groupBy(window(col("event_timestamp"), "1 hour", "5 minutes")) \
    .agg(
        count("video_id").alias("video_count"),
        sum("view_count").alias("total_views"),
        avg("engagement_score").alias("avg_engagement")
    )
```

#### 4.1.3 Session Window
```python
# 세션 기반 윈도우 (30분 비활성 시 세션 종료)
session_window = df \
    .groupBy(session_window(col("event_timestamp"), "30 minutes")) \
    .agg(
        count("video_id").alias("session_video_count"),
        sum("view_count").alias("session_total_views")
    )
```

### 4.2 Window 집계 함수

#### 4.2.1 기본 집계 함수
```python
def create_window_aggregations():
    return {
        # 카운트 집계
        "video_count": count("video_id"),
        "unique_channels": countDistinct("channel_id"),
        
        # 수치 집계
        "total_views": sum("view_count"),
        "avg_engagement": avg("engagement_score"),
        "max_views": max("view_count"),
        "min_views": min("view_count"),
        
        # 통계 집계
        "std_engagement": stddev("engagement_score"),
        "percentile_90_views": expr("percentile_approx(view_count, 0.9)")
    }
```

#### 4.2.2 사용자 정의 집계 함수
```python
class EngagementTrendAggregator:
    def __init__(self):
        self.buffer = []
        
    def update(self, engagement_score: float):
        self.buffer.append(engagement_score)
        if len(self.buffer) > 100:  # 최대 100개 값 유지
            self.buffer.pop(0)
    
    def evaluate(self):
        if len(self.buffer) < 2:
            return 0.0
        
        # 선형 회귀를 통한 트렌드 계산
        x = list(range(len(self.buffer)))
        y = self.buffer
        
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(x[i] ** 2 for i in range(n))
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)
        return slope
```

## 5. 상태 관리 설계

### 5.1 상태 저장소

#### 5.1.1 메모리 상태 저장소
```python
class InMemoryStateStore:
    def __init__(self):
        self.state = {}
        
    def get_state(self, key: str):
        return self.state.get(key)
        
    def update_state(self, key: str, value):
        self.state[key] = value
        
    def clear_state(self, key: str):
        if key in self.state:
            del self.state[key]
```

#### 5.1.2 영구 상태 저장소
```python
class PersistentStateStore:
    def __init__(self, checkpoint_path: str):
        self.checkpoint_path = checkpoint_path
        self.state = self._load_state()
        
    def _load_state(self):
        if os.path.exists(self.checkpoint_path):
            with open(self.checkpoint_path, 'rb') as f:
                return pickle.load(f)
        return {}
        
    def save_state(self):
        with open(self.checkpoint_path, 'wb') as f:
            pickle.dump(self.state, f)
```

### 5.2 상태 복구

#### 5.2.1 체크포인트 기반 복구
```python
def setup_checkpointing(spark, checkpoint_path: str):
    """체크포인트 설정"""
    spark.conf.set("spark.sql.streaming.checkpointLocation", checkpoint_path)
    spark.conf.set("spark.sql.streaming.stateStore.providerClass", 
                  "org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider")
```

#### 5.2.2 상태 스키마 관리
```python
# 상태 스키마 정의
state_schema = StructType([
    StructField("window_start", TimestampType(), False),
    StructField("window_end", TimestampType(), False),
    StructField("video_count", LongType(), True),
    StructField("total_views", LongType(), True),
    StructField("avg_engagement", DoubleType(), True),
    StructField("last_updated", TimestampType(), False)
])
```

## 6. 실시간 집계 설계

### 6.1 집계 메트릭

#### 6.1.1 기본 메트릭
```python
def create_basic_metrics():
    return {
        # 비디오 메트릭
        "video_count": count("video_id"),
        "unique_videos": countDistinct("video_id"),
        "unique_channels": countDistinct("channel_id"),
        
        # 조회수 메트릭
        "total_views": sum("view_count"),
        "avg_views": avg("view_count"),
        "max_views": max("view_count"),
        
        # 참여도 메트릭
        "total_likes": sum("like_count"),
        "total_comments": sum("comment_count"),
        "engagement_rate": avg("engagement_score"),
        
        # 시간 메트릭
        "avg_duration": avg("duration_seconds"),
        "trending_videos": count(when(col("view_count") > 100000, 1))
    }
```

#### 6.1.2 고급 메트릭
```python
def create_advanced_metrics():
    return {
        # 성장률 메트릭
        "view_velocity": expr("(current_views - previous_views) / previous_views"),
        "engagement_velocity": expr("(current_engagement - previous_engagement) / previous_engagement"),
        
        # 분포 메트릭
        "view_percentile_90": expr("percentile_approx(view_count, 0.9)"),
        "view_percentile_95": expr("percentile_approx(view_count, 0.95)"),
        "view_percentile_99": expr("percentile_approx(view_count, 0.99)"),
        
        # 상관관계 메트릭
        "views_likes_correlation": corr("view_count", "like_count"),
        "views_comments_correlation": corr("view_count", "comment_count")
    }
```

### 6.2 실시간 알림 시스템

#### 6.2.1 임계값 기반 알림
```python
class ThresholdAlert:
    def __init__(self, metric_name: str, threshold: float, operator: str = ">"):
        self.metric_name = metric_name
        self.threshold = threshold
        self.operator = operator
        
    def check_alert(self, current_value: float) -> bool:
        if self.operator == ">":
            return current_value > self.threshold
        elif self.operator == "<":
            return current_value < self.threshold
        elif self.operator == ">=":
            return current_value >= self.threshold
        elif self.operator == "<=":
            return current_value <= self.threshold
        return False
```

#### 6.2.2 트렌드 기반 알림
```python
class TrendAlert:
    def __init__(self, metric_name: str, change_threshold: float):
        self.metric_name = metric_name
        self.change_threshold = change_threshold
        self.previous_values = []
        
    def check_trend_alert(self, current_value: float) -> bool:
        if len(self.previous_values) < 2:
            self.previous_values.append(current_value)
            return False
            
        # 최근 3개 값의 평균과 현재 값 비교
        recent_avg = sum(self.previous_values[-3:]) / len(self.previous_values[-3:])
        change_ratio = (current_value - recent_avg) / recent_avg
        
        self.previous_values.append(current_value)
        if len(self.previous_values) > 10:
            self.previous_values.pop(0)
            
        return abs(change_ratio) > self.change_threshold
```

## 7. 에러 처리 및 복구

### 7.1 에러 처리 전략

#### 7.1.1 재시도 메커니즘
```python
class RetryMechanism:
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        
    def execute_with_retry(self, func, *args, **kwargs):
        for attempt in range(self.max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise e
                delay = self.base_delay * (2 ** attempt)  # 지수 백오프
                time.sleep(delay)
```

#### 7.1.2 데드 레터 큐
```python
class DeadLetterQueue:
    def __init__(self, dlq_path: str):
        self.dlq_path = dlq_path
        
    def send_to_dlq(self, failed_record, error_message: str):
        dlq_record = {
            "original_record": failed_record,
            "error_message": error_message,
            "timestamp": datetime.now(),
            "retry_count": 0
        }
        
        # DLQ에 기록 저장
        with open(f"{self.dlq_path}/dlq_{int(time.time())}.json", "a") as f:
            f.write(json.dumps(dlq_record) + "\n")
```

### 7.2 데이터 일관성 보장

#### 7.2.1 Exactly-Once 처리
```python
def setup_exactly_once_processing(spark):
    """Exactly-Once 처리 설정"""
    spark.conf.set("spark.sql.streaming.checkpointLocation", "/checkpoint/path")
    spark.conf.set("spark.sql.streaming.stateStore.providerClass", 
                  "org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider")
    spark.conf.set("spark.sql.streaming.forceDeleteTempCheckpointLocation", "true")
```

#### 7.2.2 중복 제거
```python
def deduplicate_stream(df, id_column: str, window_duration: str = "1 hour"):
    """스트림 중복 제거"""
    return df \
        .withWatermark("event_timestamp", "10 minutes") \
        .dropDuplicates([id_column, "event_timestamp"]) \
        .groupBy(window(col("event_timestamp"), window_duration), col(id_column)) \
        .agg(first("*").alias("deduplicated_record"))
```

## 8. 성능 최적화

### 8.1 파티셔닝 전략

#### 8.1.1 시간 기반 파티셔닝
```python
def partition_by_time(df, partition_column: str = "event_timestamp"):
    """시간 기반 파티셔닝"""
    return df \
        .withColumn("year", year(col(partition_column))) \
        .withColumn("month", month(col(partition_column))) \
        .withColumn("day", dayofmonth(col(partition_column))) \
        .withColumn("hour", hour(col(partition_column)))
```

#### 8.1.2 카테고리 기반 파티셔닝
```python
def partition_by_category(df):
    """카테고리 기반 파티셔닝"""
    return df \
        .withColumn("category_partition", 
                   when(col("category_id").isNull(), "unknown")
                   .otherwise(col("category_id")))
```

### 8.2 캐싱 전략

#### 8.2.1 브로드캐스트 조인
```python
def broadcast_join_large_small(large_df, small_df, join_key: str):
    """브로드캐스트 조인"""
    small_df_broadcast = broadcast(small_df)
    return large_df.join(small_df_broadcast, join_key, "left")
```

#### 8.2.2 상태 캐싱
```python
class StateCache:
    def __init__(self, cache_size: int = 1000):
        self.cache_size = cache_size
        self.cache = {}
        self.access_order = []
        
    def get(self, key: str):
        if key in self.cache:
            self.access_order.remove(key)
            self.access_order.append(key)
            return self.cache[key]
        return None
        
    def put(self, key: str, value):
        if len(self.cache) >= self.cache_size:
            # LRU 제거
            oldest_key = self.access_order.pop(0)
            del self.cache[oldest_key]
        
        self.cache[key] = value
        self.access_order.append(key)
```

## 9. 모니터링 및 메트릭

### 9.1 스트리밍 메트릭

#### 9.1.1 처리량 메트릭
```python
def create_throughput_metrics():
    return {
        "records_per_second": count("video_id") / 60,  # 분당 레코드 수
        "bytes_per_second": sum("record_size") / 60,  # 분당 바이트 수
        "processing_latency": avg("processing_time"),   # 평균 처리 지연시간
        "backlog_size": count("pending_records")      # 백로그 크기
    }
```

#### 9.1.2 품질 메트릭
```python
def create_quality_metrics():
    return {
        "error_rate": count(when(col("error").isNotNull(), 1)) / count("*"),
        "duplicate_rate": count(when(col("is_duplicate"), 1)) / count("*"),
        "null_rate": count(when(col("video_id").isNull(), 1)) / count("*"),
        "data_freshness": avg("current_timestamp - event_timestamp")
    }
```

### 9.2 알림 설정

#### 9.2.1 임계값 알림
```python
class StreamingAlertManager:
    def __init__(self):
        self.alerts = []
        
    def add_alert(self, metric_name: str, threshold: float, operator: str):
        alert = {
            "metric": metric_name,
            "threshold": threshold,
            "operator": operator,
            "enabled": True
        }
        self.alerts.append(alert)
        
    def check_alerts(self, metrics: dict):
        triggered_alerts = []
        for alert in self.alerts:
            if alert["enabled"] and alert["metric"] in metrics:
                current_value = metrics[alert["metric"]]
                if self._evaluate_condition(current_value, alert["threshold"], alert["operator"]):
                    triggered_alerts.append(alert)
        return triggered_alerts
```

---

**이전 문서**: [01_데이터_수집_및_배치_ETL_설계.md](./01_데이터_수집_및_배치_ETL_설계.md)  
**다음 문서**: [03_피처_엔지니어링_및_라벨링_설계.md](./03_피처_엔지니어링_및_라벨링_설계.md)
