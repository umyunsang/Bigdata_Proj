# 소셜 비디오 빅데이터 실시간 처리 플랫폼 설계 보고서

## 1. 문제 정의·목표

### 1.1 문제 정의

현재 소셜 비디오 플랫폼에서는 다음과 같은 핵심 문제들이 존재합니다:

**데이터 처리의 복잡성**
- YouTube API v3를 통한 대용량 비디오 메타데이터 수집의 어려움
- 실시간 소셜 미디어 데이터 스트림의 효율적 처리 필요성
- 다차원 성능 지표를 고려한 모델 최적화의 복잡성
- 지연 시간 최소화를 통한 실시간 예측 서비스 제공의 기술적 도전

**기존 시스템의 한계**
- 배치 처리 중심의 데이터 파이프라인으로 인한 실시간성 부족
- 단일 알고리즘 기반 모델 선택으로 인한 성능 최적화 한계
- 피처 엔지니어링의 수동적 접근으로 인한 확장성 제약
- 사용자 친화적 인터페이스 부재로 인한 접근성 문제

### 1.2 프로젝트 목표

**주요 목표**
소셜 비디오 빅데이터 실시간 처리 플랫폼을 구축하여 대용량 비디오 데이터의 효율적 수집, 처리, 분석, 예측을 통합적으로 지원하는 시스템 개발

**세부 목표**
1. **멀티 소스 데이터 수집 및 배치 ETL 파이프라인 구축**
   - YouTube API v3 연동을 통한 대용량 비디오 메타데이터 수집
   - Reservoir Sampling을 활용한 효율적인 데이터 샘플링
   - Bloom Filter 기반 중복 데이터 필터링 시스템

2. **스트리밍 데이터 처리 및 실시간 분석 시스템 구현**
   - Sliding Window와 Watermark를 활용한 지연 이벤트 처리
   - 실시간 집계 및 분석 기능 제공
   - 체크포인트 기반 자동 복구 시스템

3. **고급 피처 엔지니어링 및 자동 라벨링 시스템 개발**
   - HyperLogLog를 활용한 근사 유니크 카운팅
   - CDF/PDF 기반 동적 라벨링 시스템
   - 피처 스토어 및 선형성 관리

4. **다목적 최적화를 통한 모델 선택 자동화**
   - 다중 알고리즘 벤치마킹을 통한 최적 모델 선택
   - Pareto Front 기반 다목적 최적화
   - 자동화된 모델 선택 및 배포 파이프라인

5. **실시간 예측 및 시각화 대시보드 제공**
   - Streamlit 기반 사용자 친화적 대시보드
   - CDF/PDF 시각화를 통한 예측 결과 해석
   - FastAPI 기반 고성능 예측 서비스

## 2. 설계/알고리즘

### 2.1 전체 시스템 아키텍처

**시스템 구조도**
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Data Sources  │    │  Data Ingestion │    │  Data Processing│
│                 │    │                 │    │                 │
│ • YouTube API   │───▶│ • Reservoir     │───▶│ • Bronze Layer  │
│ • Social Media  │    │   Sampling      │    │ • Silver Layer  │
│ • User Events   │    │ • Bloom Filter  │    │ • Gold Layer    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │                        │
                                ▼                        ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Analytics     │    │   ML Pipeline   │    │   Real-time     │
│                 │    │                 │    │   Services      │
│ • CDF/PDF       │◀───│ • Multi-model   │◀───│ • Streamlit UI  │
│ • HLL Counting  │    │   Training      │    │ • Prediction API│
│ • Pareto Front  │    │ • Optimization  │    │ • Monitoring    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### 2.2 핵심 알고리즘 설계

#### 2.2.1 Reservoir Sampling (Vitter's Algorithm R)

**선택 이유**
- **메모리 효율성**: O(k) 메모리 사용으로 대용량 데이터 처리 가능
- **균등 분포**: 각 아이템이 동일한 확률로 선택되어 대표성 보장
- **스트리밍 처리**: 데이터 스트림에서 실시간 샘플링 가능

**대안 비교**
- **단순 랜덤 샘플링**: 전체 데이터를 메모리에 로드해야 하므로 대용량 데이터 처리 불가
- **시스템 샘플링**: 고정된 간격으로 샘플링하므로 데이터 분포에 따른 편향 발생 가능
- **Reservoir Sampling**: 메모리 효율성과 균등 분포를 동시에 만족하는 최적 솔루션

**알고리즘 구현**
```python
class ReservoirSampler:
    def __init__(self, k: int):
        self.k = k  # 샘플 크기
        self.reservoir = []
        self.n = 0  # 전체 데이터 수
        
    def add_item(self, item):
        self.n += 1
        if len(self.reservoir) < self.k:
            self.reservoir.append(item)
        else:
            # 확률 k/n으로 교체
            j = random.randint(0, self.n - 1)
            if j < self.k:
                self.reservoir[j] = item
```

#### 2.2.2 Bloom Filter

**선택 이유**
- **공간 효율성**: 해시 테이블 대비 메모리 사용량 대폭 감소
- **빠른 조회**: O(k) 시간 복잡도로 중복 검사 수행
- **확률적 구조**: False Positive는 허용하지만 False Negative는 없음

**대안 비교**
- **해시 테이블**: 정확한 중복 검사 가능하지만 메모리 사용량이 큼
- **트리 구조**: 정렬된 데이터에서 효율적이지만 삽입/삭제 비용이 높음
- **Bloom Filter**: 공간 효율성과 빠른 조회를 동시에 만족하는 최적 솔루션

#### 2.2.3 HyperLogLog (HLL)

**선택 이유**
- **메모리 효율성**: O(log log n) 메모리로 대용량 유니크 카운팅 가능
- **정확도**: 상당히 높은 정확도로 근사 유니크 카운팅 수행
- **병합 가능**: 여러 HLL 구조를 병합하여 전체 카디널리티 계산 가능

**대안 비교**
- **정확한 카운팅**: 메모리 사용량이 데이터 크기에 비례하여 대용량 데이터 처리 불가
- **Linear Counting**: 작은 카디널리티에서는 정확하지만 큰 카디널리티에서는 비효율적
- **HyperLogLog**: 메모리 효율성과 정확도를 동시에 만족하는 최적 솔루션

#### 2.2.4 Pareto Front 최적화

**선택 이유**
- **다목적 최적화**: 성능, 지연시간, 해석가능성 등 상충하는 목표들을 동시에 고려
- **객관적 선택**: 주관적 가중치 없이 최적 솔루션 집합 도출
- **확장성**: 새로운 목표 함수 추가 시 기존 결과 재활용 가능

**대안 비교**
- **가중합 최적화**: 주관적 가중치 설정이 필요하여 객관성 부족
- **단일 목표 최적화**: 하나의 목표만 고려하여 다른 중요한 목표들 무시
- **Pareto Front**: 객관적이고 포괄적인 다목적 최적화를 제공하는 최적 솔루션

### 2.3 데이터 처리 계층 설계

#### 2.3.1 Bronze Layer (원본 데이터 보존)
- **목적**: 원본 데이터의 완전한 보존 및 스키마 고정
- **특징**: ACID 트랜잭션 지원, 스키마 진화 지원
- **기술**: Delta Lake 기반 데이터 레이크

#### 2.3.2 Silver Layer (데이터 정제)
- **목적**: 데이터 정제 및 구조화
- **특징**: 실시간 스트리밍 처리, Watermark 기반 지연 이벤트 처리
- **기술**: Apache Spark Structured Streaming

#### 2.3.3 Gold Layer (피처 및 라벨)
- **목적**: ML 모델용 피처 엔지니어링 및 라벨링
- **특징**: 고급 피처 생성, 동적 라벨링
- **기술**: 피처 스토어, CDF/PDF 기반 라벨링

### 2.4 실시간 처리 아키텍처

#### 2.4.1 Watermark 기반 지연 이벤트 처리
- **고정 지연 전략**: 10분 고정 지연으로 안정적인 처리
- **적응형 지연 전략**: 지연 이벤트 비율에 따른 동적 조정

#### 2.4.2 Sliding Window 집계
- **Tumbling Window**: 1시간 고정 윈도우
- **Sliding Window**: 1시간 윈도우, 5분 슬라이드
- **Session Window**: 30분 비활성 시 세션 종료

## 3. 고찰

### 3.1 시스템의 장점

**확장성**
- Apache Spark 기반 분산 처리로 수평 확장 가능
- 마이크로서비스 아키텍처로 독립적 서비스 확장
- 클라우드 네이티브 설계로 자동 스케일링 지원

**성능**
- Reservoir Sampling으로 메모리 효율적인 대용량 데이터 처리
- Bloom Filter로 빠른 중복 검사
- HyperLogLog로 메모리 효율적인 유니크 카운팅
- Redis 캐싱으로 실시간 응답 성능 향상

**정확성**
- Delta Lake 기반 ACID 트랜잭션으로 데이터 일관성 보장
- Watermark 기반 정확한 지연 이벤트 처리
- 체크포인트 기반 장애 복구

**사용자 경험**
- Streamlit 기반 직관적인 대시보드
- CDF/PDF 시각화로 예측 결과 해석 용이
- FastAPI 기반 고성능 RESTful API

### 3.2 시스템의 한계

**데이터 품질 의존성**
- YouTube API 데이터 품질에 의존적
- API 제한으로 인한 데이터 수집 제약
- 외부 데이터 소스의 가용성에 따른 영향

**복잡성**
- 다층 아키텍처로 인한 운영 복잡성
- 여러 기술 스택 통합으로 인한 학습 곡선
- 실시간 처리 시스템의 디버깅 어려움

**비용**
- 대용량 데이터 처리로 인한 인프라 비용
- 실시간 처리로 인한 높은 컴퓨팅 비용
- 모니터링 및 로깅 시스템 운영 비용

### 3.3 개선 방안

**단기 개선사항**
1. **데이터 품질 향상**
   - 다중 데이터 소스 통합 (TikTok, Instagram 등)
   - 데이터 검증 규칙 강화
   - 품질 메트릭 자동 모니터링

2. **성능 최적화**
   - 쿼리 최적화 및 인덱싱 전략 개선
   - 캐싱 전략 고도화
   - 배치 처리와 스트리밍 처리의 하이브리드 접근

3. **사용자 경험 개선**
   - 대시보드 성능 최적화
   - 모바일 반응형 디자인
   - 개인화된 알림 시스템

**장기 개선사항**
1. **AI/ML 고도화**
   - 딥러닝 모델 도입 (Transformer, GNN)
   - 자동 피처 엔지니어링
   - 강화학습 기반 모델 선택

2. **아키텍처 진화**
   - 이벤트 소싱 패턴 도입
   - CQRS 패턴 적용
   - 서버리스 아키텍처 전환

3. **데이터 거버넌스**
   - 데이터 계보 추적 시스템
   - 개인정보보호 규정 준수 강화
   - 데이터 보안 정책 자동화

### 3.4 향후 연구 방향

**기술적 연구**
- 실시간 머신러닝 파이프라인 최적화
- 분산 시스템에서의 일관성 보장 방법론
- 대용량 스트리밍 데이터의 효율적 처리 알고리즘

**비즈니스 연구**
- 사용자 행동 패턴 분석을 통한 개인화 서비스
- 크로스 플랫폼 데이터 통합 전략
- 실시간 추천 시스템 성능 평가 방법론

## 4. 참고문헌·라이선스

### 4.1 참고문헌

1. **Reservoir Sampling**
   - Vitter, J. S. (1985). "Random sampling with a reservoir." ACM Transactions on Mathematical Software, 11(1), 37-57.

2. **Bloom Filter**
   - Bloom, B. H. (1970). "Space/time trade-offs in hash coding with allowable errors." Communications of the ACM, 13(7), 422-426.

3. **HyperLogLog**
   - Flajolet, P., Fusy, É., Gandouet, O., & Meunier, F. (2007). "HyperLogLog: the analysis of a near-optimal cardinality estimation algorithm." In Proceedings of the 2007 conference on analysis of algorithms (pp. 127-146).

4. **Apache Spark**
   - Zaharia, M., et al. (2016). "Apache Spark: a unified engine for big data processing." Communications of the ACM, 59(11), 56-65.

5. **Delta Lake**
   - Armbrust, M., et al. (2020). "Delta Lake: High-Performance ACID Table Storage over Cloud Object Stores." Proceedings of the VLDB Endowment, 13(12), 3411-3424.

6. **Pareto Front Optimization**
   - Deb, K., et al. (2002). "A fast and elitist multiobjective genetic algorithm: NSGA-II." IEEE transactions on evolutionary computation, 6(2), 182-197.

### 4.2 오픈소스 라이선스

**Apache Spark**
- 라이선스: Apache License 2.0
- 사용 목적: 분산 데이터 처리 엔진
- 라이선스 조건: 상업적 사용 가능, 수정 및 배포 가능

**Delta Lake**
- 라이선스: Apache License 2.0
- 사용 목적: ACID 트랜잭션 지원 데이터 레이크
- 라이선스 조건: 상업적 사용 가능, 수정 및 배포 가능

**Streamlit**
- 라이선스: Apache License 2.0
- 사용 목적: 웹 기반 대시보드
- 라이선스 조건: 상업적 사용 가능, 수정 및 배포 가능

**FastAPI**
- 라이선스: MIT License
- 사용 목적: 고성능 API 서버
- 라이선스 조건: 상업적 사용 가능, 수정 및 배포 가능

**Redis**
- 라이선스: BSD License
- 사용 목적: 인메모리 데이터베이스
- 라이선스 조건: 상업적 사용 가능, 수정 및 배포 가능

### 4.3 AI 활용 내역

**AI 도구 활용**
- **Claude Sonnet 4**: 설계 문서 작성 및 코드 생성 지원
- **GitHub Copilot**: 코드 자동 완성 및 리팩토링 지원
- **ChatGPT**: 알고리즘 개념 검증 및 최적화 방안 도출

**사용 프롬프트 예시**
- "Reservoir Sampling 알고리즘의 메모리 효율성을 설명하고 대안과 비교해주세요"
- "HyperLogLog 알고리즘의 정확도와 메모리 사용량을 분석해주세요"
- "Pareto Front 최적화를 다목적 모델 선택에 적용하는 방법을 설계해주세요"

**AI 활용 범위**
- 아이디어 보조 및 개념 검증
- 코드 구조 설계 및 최적화
- 문서 작성 및 기술적 설명
- 알고리즘 비교 및 선택 근거 도출

---

**보고서 작성일**: 2025년 1월 24일  
**작성자**: [학번] [이름]  
**과목**: 빅데이터 분석  
**제출 마감**: 2025년 12월 19일 23:59
